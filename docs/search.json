[
  {
    "objectID": "projects.html#project-2",
    "href": "projects.html#project-2",
    "title": "Projects",
    "section": "Project 2",
    "text": "Project 2"
  },
  {
    "objectID": "projects.html#project-3",
    "href": "projects.html#project-3",
    "title": "Projects",
    "section": "Project 3",
    "text": "Project 3"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Giới thiệu",
    "section": "",
    "text": "Trong quản lí chuỗi cung ứng, thuật ngữ Demand Planning là một trong những hoạt động quan trọng mà các nhà quản lí và doanh nghiệp cần quan tâm sâu sắc. Về định nghĩa, theo (Vilas, n.d.) “Demand Planning là một quá trình quản lý chuỗi cung ứng nhằm dự báo nhu cầu về sản phẩm để đảm bảo chúng có thể được cung cấp và làm hài lòng khách hàng. Mục tiêu của Demand planning là đạt được sự cân bằng trong việc có đủ lượng hàng tồn kho để đáp ứng nhu cầu của khách hàng mà không bị thiếu hoặc thừa. Để có thể dự báo được nhu cầu mua hàng, nhà Hoạch định nhu cầu cần thu thập và phân tích dữ liệu từ nhiều nguồn khác nhau như: hàng tồn kho, nhà cung ứng, kho, khách hàng,…”.\n\n\n\nHình 1: Định nghĩa về Demand Planning\n\n\n\n\n\nViệc dự đoán trước nhu cầu của khách hàng sẽ giúp doanh nghiệp chuẩn bị tốt hơn về hàng hóa, dịch vụ và chiếm được lòng tin của khách hàng. Ngoài ra, việc chuẩn bị sớm cũng tránh các hiện tượng như out-stock, tranh chấp hoặc tệ hơn đứt gãy chuỗi cung ứng và ảnh hưởng nặng nề tới kết quả kinh doanh của công ty.\nỞ vị trí nhân viên, bạn có thể ứng tuyển vị trí Demand Planner để có thể làm việc về Demand Planning. Còn ở vị trí cấp cao hơn sẽ là Supply Chain Planner - là người có thể xử lí luôn cả 4 vấn đề như sau:\n\nDemand planning: Dự đoán nhu cầu khách hàng bao nhiêu.\nSupply planning: Lên kế hoạch phân phối, tồn kho.\nProdcution planning: Chuẩn bị nguyên vật liệu để sản xuất ở nhà máy. Thông thường hoạt động này chỉ xảy ra ở công ti lớn có cả chuỗi cung ứng từ nhà máy đến nhà kho và có thể cả cửa hàng.\nFulfillment planning: Hoạt động này cũng giống Supply planning nhưng ở mức độ cao cấp hơn. Việc lên kế hoạch còn đòi hỏi phải thỏa mãn các nhu cầu khác của khách hàng như: hàng hóa đúng số lượng, đúng sản phẩm và nhận hàng với thời gian ngắn nhất.\n\n\n\n\nHình 2: Các chức năng chính của Supply Chain Planner\n\n\nỞ phần bài tập này, chúng ta sẽ học về cách sử dụng R trong việc phân tích và dự đoán dữ liệu bằng 2 cách: mô hình ARIMA và Machine Learning.\nBài tập này dựa vào bộ dữ liệu từ (FelixZhao 2017) của Frank Corrigan. Nếu bí ý tưởng, bạn có thể kham khảo thêm phần phân tích của anh ấy thông qua bài blog (Frank 2019)."
  },
  {
    "objectID": "EnsembleML.html",
    "href": "EnsembleML.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Theo (Topdev, n.d.), Machine learning (ML) hay máy học là “một nhánh của trí tuệ nhân tạo (AI), nó là một lĩnh vực nghiên cứu cho phép máy tính có khả năng cải thiện chính bản thân chúng dựa trên dữ liệu mẫu (training data) hoặc dựa vào kinh nghiệm (những gì đã được học). Machine learning có thể tự dự đoán hoặc đưa ra quyết định mà không cần được lập trình cụ thể.”\nPhương pháp Machine Learning từng “gây bão” trong giới khoa học khi ra mắt vì khả năng xây dựng mô hình nhanh chóng và sự chuẩn xác của mô hình trong việc dự đoán và phân loại kết quả. Với sự phát triển của khoa học, lượng lớn dữ liệu được thu thập hay được gọi là Big Data đòi hỏi nhu cầu tính toán nhanh chóng và công cụ mạnh. Các phương pháp khoa học truyền thống lại không làm tốt việc này bằng Machine Learning.\nNgoài ra, khác với các mô hình truyền thống đòi hỏi nhiều về đáp ứng giả định và quy tắc rắc rối, Machine Learning giúp con người nhanh chóng đưa ra quyết định và có thể tự cải thiện performance của mình bằng học máy mà không cần người dùng phải tương tác nhiều.\n\n\n\nTrong machine learning tồn tại định lý “không có bữa trưa miễn phí” (No free lunch theorem), tức là không tồn tại một thuật toán mà tốt cho mọi ứng dụng và mọi tập dữ liệu. Vì ML có nhiều thuật toán khác nhau và tùy vào đặc tính của bộ dữ liệu mà thuật toán ML sẽ tính ra kết quả khác nhau. Muốn tìm ra thuật toán phù hợp, người sử dụng phải cần nhiều thời gian để test và điều chỉnh hệ số (tuning hyperparameters) để đạt độ chính xác cao.\nVà thuật toán Ensemble ML có thể giúp người dùng giảm thời gian trong việc testing bằng cách kết hợp các mô hình này với nhau. Theo (Cuong Sai 2020),“Ý tưởng của việc combine các mô hình khác nhau xuất phát từ một suy nghĩ hợp lý là: các mô hình khác nhau có khả năng khác nhau, có thể thực hiện tốt nhất các loại công việc khác nhau (subtasks), khi kết hợp các mô hình này với nhau một cách hợp lý thì sẽ tạo thành một mô hình kết hợp (combined model) mạnh có khả năng cải thiện hiệu suât tổng thể (overall performance) so với việc chỉ dùng các mô hình một cách đơn lẻ.”\nThuật toán Ensemble ML chia thành 3 loại:\n\nBagging: chia bộ dữ liệu thành subsamples và xây dựng thành model cùng kiểu với nhau để đưa ra dự đoán.\nBoosting: cũng chia dữ liệu thành subsamples nhưng việc xây dựng mô hình không diễn ra cùng lúc như bagging mà là theo chuỗi nối tiếp nhau.\n\nBạn có thể tưởng tượng như hình dưới đây:\n\n\n\nHình 6: Bagging vs Boosting method.\n\n\n\nStacking xây dựng các mô hình khác loại từ training data và một mô hình supervisor model. Sau đó, mô hình này sẽ kết hợp các kết quả dự báo để tìm ra mô hình tốt nhất.\n\n\n\n\nHình 7: Staking method.\n\n\nVậy tiếp theo, chúng ta sẽ thử dùng Ensemble ML trong R để dự đoán.\n\n\n\nMachine Learning làm tốt về mặt performance ở các vấn đề như: phân loại nhãn (Classification), tự học và bổ sung (AI), phân tích lớp ảnh (Neural network),… nhưng ở lĩnh vực dự đoán chuỗi thời gian (Time series forecast), ML lại không tốt bằng các phương pháp thống kê truyền thống."
  },
  {
    "objectID": "EnsembleML.html#dự-đoán-bằng-machine-learning",
    "href": "EnsembleML.html#dự-đoán-bằng-machine-learning",
    "title": "Machine Learning",
    "section": "",
    "text": "Theo (Topdev, n.d.), Machine learning (ML) hay máy học là “một nhánh của trí tuệ nhân tạo (AI), nó là một lĩnh vực nghiên cứu cho phép máy tính có khả năng cải thiện chính bản thân chúng dựa trên dữ liệu mẫu (training data) hoặc dựa vào kinh nghiệm (những gì đã được học). Machine learning có thể tự dự đoán hoặc đưa ra quyết định mà không cần được lập trình cụ thể.”\nPhương pháp Machine Learning từng “gây bão” trong giới khoa học khi ra mắt vì khả năng xây dựng mô hình nhanh chóng và sự chuẩn xác của mô hình trong việc dự đoán và phân loại kết quả. Với sự phát triển của khoa học, lượng lớn dữ liệu được thu thập hay được gọi là Big Data đòi hỏi nhu cầu tính toán nhanh chóng và công cụ mạnh. Các phương pháp khoa học truyền thống lại không làm tốt việc này bằng Machine Learning.\nNgoài ra, khác với các mô hình truyền thống đòi hỏi nhiều về đáp ứng giả định và quy tắc rắc rối, Machine Learning giúp con người nhanh chóng đưa ra quyết định và có thể tự cải thiện performance của mình bằng học máy mà không cần người dùng phải tương tác nhiều.\n\n\n\nTrong machine learning tồn tại định lý “không có bữa trưa miễn phí” (No free lunch theorem), tức là không tồn tại một thuật toán mà tốt cho mọi ứng dụng và mọi tập dữ liệu. Vì ML có nhiều thuật toán khác nhau và tùy vào đặc tính của bộ dữ liệu mà thuật toán ML sẽ tính ra kết quả khác nhau. Muốn tìm ra thuật toán phù hợp, người sử dụng phải cần nhiều thời gian để test và điều chỉnh hệ số (tuning hyperparameters) để đạt độ chính xác cao.\nVà thuật toán Ensemble ML có thể giúp người dùng giảm thời gian trong việc testing bằng cách kết hợp các mô hình này với nhau. Theo (Cuong Sai 2020),“Ý tưởng của việc combine các mô hình khác nhau xuất phát từ một suy nghĩ hợp lý là: các mô hình khác nhau có khả năng khác nhau, có thể thực hiện tốt nhất các loại công việc khác nhau (subtasks), khi kết hợp các mô hình này với nhau một cách hợp lý thì sẽ tạo thành một mô hình kết hợp (combined model) mạnh có khả năng cải thiện hiệu suât tổng thể (overall performance) so với việc chỉ dùng các mô hình một cách đơn lẻ.”\nThuật toán Ensemble ML chia thành 3 loại:\n\nBagging: chia bộ dữ liệu thành subsamples và xây dựng thành model cùng kiểu với nhau để đưa ra dự đoán.\nBoosting: cũng chia dữ liệu thành subsamples nhưng việc xây dựng mô hình không diễn ra cùng lúc như bagging mà là theo chuỗi nối tiếp nhau.\n\nBạn có thể tưởng tượng như hình dưới đây:\n\n\n\nHình 6: Bagging vs Boosting method.\n\n\n\nStacking xây dựng các mô hình khác loại từ training data và một mô hình supervisor model. Sau đó, mô hình này sẽ kết hợp các kết quả dự báo để tìm ra mô hình tốt nhất.\n\n\n\n\nHình 7: Staking method.\n\n\nVậy tiếp theo, chúng ta sẽ thử dùng Ensemble ML trong R để dự đoán.\n\n\n\nMachine Learning làm tốt về mặt performance ở các vấn đề như: phân loại nhãn (Classification), tự học và bổ sung (AI), phân tích lớp ảnh (Neural network),… nhưng ở lĩnh vực dự đoán chuỗi thời gian (Time series forecast), ML lại không tốt bằng các phương pháp thống kê truyền thống."
  },
  {
    "objectID": "EnsembleML.html#thực-hành-trong-r",
    "href": "EnsembleML.html#thực-hành-trong-r",
    "title": "Machine Learning",
    "section": "2 Thực hành trong R:",
    "text": "2 Thực hành trong R:\n\n2.1 Chuẩn bị dữ liệu:\nBạn có thể quay lại trang đầu tiên để lấy dữ liệu gốc và các bước để chỉnh sửa dữ liệu ở Giới thiệu.\nTrong phần này, đối với Machine Learning, ta nên chia bộ dữ liệu thành 3 bộ: training, testing và forecasting dataset. Ngoài ra, ML cần dữ liệu lớn nên ta sẽ tính theo tuần chứ không theo tháng như các phần trước.\n\n\nCode\n#Sum by daily and remove negative value:\nweekly_df&lt;-product_demand %&gt;% \n  select(c(Warehouse,\n           Date,\n           Order_Demand)) %&gt;%\n  mutate(order_date = floor_date(Date, \n                                 unit = 'week', \n                     # setting up week commencing Monday\n                     week_start = getOption(\"lubridate.week.start\", \n                                            1))) %&gt;%\n  group_by(order_date) %&gt;%\n  summarise(Order_Demand = sum(Order_Demand)) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\nGiống ý tưởng của ARIMA, Ensemble ML cũng phân tích mối tương quan giữa giá trị tại thời điểm t với thời điểm t-1, t-2,… Và vì ta đã có dữ liệu tại thời điểm t nên ta cần tính giá trị tại các thời điểm t-1, t-2 bằng hàm lag.\nTrong R, có hàm ts_lags để kiếm tra mức độ tương quan giữa biến hiện tại và các biến trong quá khứ. Mặc định, hàm sẽ tính cho ta trong 12 lags nhưng ta có thể chỉ định bằng đối số: lags = c()\n\n\nCode\nlibrary(TSstudio)\nts_lags(demand_training, lags = c(13, 26, 39, 52))\n\n\n\n\n\n\nDựa vào biểu đồ trên này, ta thấy được mối quan hệ tuyến tính theo hướng tích cực giữa dữ liệu chuỗi và giá trị của nó ở lag 52 (nghĩa là 1 năm sau) và hướng tiêu cực với giá trị của nó ở lag 13.\nDo đó, chúng ta sẽ tạo lại bộ dữ liệu có các biến mới.\n\n\nCode\nmodel_data &lt;- \n  weekly_df %&gt;% \n  mutate(trend       = 1:nrow(weekly_df),\n         trend_sqr   = trend^2,\n         rev_lag_13  = lag(Order_Demand, n = 13),\n         rev_lag_52  = lag(Order_Demand, n = 52),\n         season      = case_when(Order_Demand == 0 ~ 0,\n                                 TRUE ~ 1)\n        ) %&gt;% \n filter(!is.na(rev_lag_52)&!is.na(rev_lag_13)) %&gt;% \n  mutate(class = ifelse(order_date &lt;= n[[2]],\n                        \"train\",\n                        ifelse(order_date &gt; n[[2]]& order_date &lt;= n[[3]],\n                               \"test\",\"forecast\")))\n\n\n\n\n2.2 Xử lí missing value và outliers:\n\n2.2.1 Missing value:\nGía trị NA xuất hiện là do ta đang lấy dữ liệu từ quá khứ thời điểm cách 1 tháng, 2 tháng và 3 tháng. Vì Machine Learning bắt buộc phải có đầy đủ giá trị nên ta có thể sử dụng cách khác để tạo ra giá trị thay thế cho NA. Mình kham khảo được cách này từ (Sauravkaushik8 Kaushik 2019).\n\n\n2.2.2 Outliers:\nNgoài ra, vấn đề về outliers cũng cần được quan tâm. Outlier là các giá trị có vẻ “lệch” hoặc không bình thường so với toàn bộ dữ liệu. Nguyên nhân xuất hiện outlier có thể do các biến cố không lường trước hoặc đơn giản là sai sót trong việc đo lường, tính toán của người thu thập dữ liệu.\nVì mục đích của chúng ta là xây dựng mô hình nên các outliers không giúp ích nhiều. Do đó chúng ta cần loại bỏ nó trước khi mô hình hóa.\n\n\nCode\nlibrary(viridis)\nggplot(model_data,\n       aes(x=Order_Demand,\n           y = as.factor(class),\n           fill = as.factor(class))) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    geom_jitter(color=\"black\", \n                size=0.4, \n                alpha=0.9) +\n    theme_minimal() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11,\n                                hjust=1, \n                                vjust=0.5, \n                                face='bold')\n    ) +\n    ggtitle(\"A boxplot with jitter\") +\n    xlab(\"\")+\n    ylab(\"Dataset\")\n\n\n\n\n\nCác điểm đen lạc lỏng ở ngoài vùng boxplot chính là outliers\n\n\n\nBiểu đồ phân bố của 3 bộ dữ liệu\n\nCách xử lí outliers khá đơn giản. Ở đây mình sử dụng phương pháp IQR hay còn gọi là tứ phân vị. Sau khi xử lí, bạn có thể chạy lại code trên để kiểm tra xem outliers đã được loại bỏ hay chưa.\n\n\n\nHình 8: IQR method.\n\n\n\n\nCode\n# Tính IQR\nq25 &lt;- quantile(model_data$Order_Demand, 0.25)\nq75 &lt;- quantile(model_data$Order_Demand, 0.75)\niqr &lt;- q75 - q25\n\n# thiết lập giới hạn để xác định outliers\nlimit_iqr = 1.5*iqr\nlower_iqr = q25 - limit_iqr\nupper_iqr = q75 + limit_iqr\n\n# Loại bỏ các outliers\nmodel_data &lt;- model_data[-which(model_data$Order_Demand &gt; upper_iqr | model_data$Order_Demand &lt; lower_iqr),]\n\n## Tạo các bộ dữ liệu training,testing và forecasting:\ntrain_data &lt;- \n  model_data %&gt;% \n  filter(class == \"train\")\n\ntest_data &lt;- \n  model_data %&gt;% \n  filter(class == \"test\")\n\nforecast_data &lt;- \n  model_data %&gt;% \n  filter(class == \"forecast\")\n\n\n\n\n\n2.3 Dự đoán:\n\n2.3.1 Mô hình Random Forest:\nĐầu tiên chúng ta sẽ làm việc với thuật toán boosting khá phổ biến là: Random Forest.\nRandom Forest là một phương pháp học máy thuộc loại ensemble learning, được sử dụng chủ yếu cho các bài toán phân loại và hồi quy. Đây là một kỹ thuật mạnh mẽ và phổ biến, được phát triển bởi Leo Breiman vào năm 2001.\nVề ưu Điểm:\n\nKhả Năng Tổng Quát Cao: Random Forest thường có khả năng tổng quát tốt hơn so với các mô hình cây quyết định đơn lẻ, do giảm thiểu overfitting (quá khớp) nhờ vào sự kết hợp của nhiều cây.\nKhả Năng Xử Lý Dữ Liệu Lớn và Nhiều Đặc Trưng: Random Forest có thể xử lý hiệu quả dữ liệu với số lượng lớn các đặc trưng và quan sát.\nKhả Năng Đánh Giá Tầm Quan Trọng Của Các Đặc Trưng: Random Forest cung cấp thông tin về tầm quan trọng của từng đặc trưng trong việc đưa ra dự đoán, giúp ích trong việc chọn lọc và phân tích đặc trưng.\n\nVề nhược Điểm:\n\nKhó Giải Thích: Mặc dù Random Forest có hiệu suất tốt, nhưng các mô hình cây quyết định kết hợp lại có thể khó giải thích và không trực quan bằng các mô hình đơn giản hơn.\nTốn Tài Nguyên Tính Toán: Đặc biệt khi số lượng cây lớn, Random Forest có thể yêu cầu nhiều tài nguyên tính toán và bộ nhớ.\n\nPhân tích thêm về mức độ quan trọng của các biến trong mô hình. Ta thấy biến lag_50 đóng vai trò quan trọng nhất, đúng như dự đoán của ta khi phân tích ở trên về mối tương quan.\n\n\nCode\n## visualise the variable importance \nrft_model %&gt;% \n  h2o.varimp_plot()\n\n\n\n\n\n\n\nCode\npred&lt;- h2o.predict(rft_model, \n                   newdata = as.h2o(train_data)) %&gt;% \n      as_tibble() %&gt;% \n  mutate(actual = train_data$Order_Demand,\n         date = train_data$order_date)\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n\nCode\nlibrary(plotly)\npred %&gt;% \n  plot_ly() %&gt;% \n    add_lines(x = ~ date, y = ~ actual, name = 'Actual') %&gt;% \n    add_lines(x = ~ date, y = ~ predict, name = 'Random Forest', \n              line = list(dash = 'dot'))\n\n\n\n\n\n\nKhi dùng dữ liệu của bộ Training data, ML dự đoán lại gần như sát với dữ liệu thực tế. Nhưng khi có dữ liệu mới vào Machine Learning không dự đoán tốt được. Ví dụ như dưới đây.\n\n\nCode\nplot_f(rft_model)\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\n\n\n\n\n\n\n\n\n2.3.2 Mô hình GLM:\nChúng ta thử thêm 1 số mô hình khác của ML. Ở dưới đây là mô hình Geleralised linear model sử dụng phương pháp OSL để tính toán.\n\n\nCode\nplot_f(glm_model)\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\n\n\n\n\n\n\n\n\n2.3.3 Mô hình Auto ML:\nTrong gói package {h2o} của R có mô hình “Auto Machine Learning” (AutoML) có thể tự động hóa quy trình đào tạo mô hình học máy được giám sát (supervised ML). AutoML tìm thấy mô hình tốt nhất, đưa ra khung đào tạo và phản hồi, đồng thời trả về đối tượng H2OAutoML, chứa bảng xếp hạng gồm tất cả các mô hình đã được đào tạo trong quy trình, được xếp hạng theo chỉ số hiệu suất mô hình mặc định.\n\n\nCode\nplot_f(automl_model)\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\n\n\n\n\n\n\n\n\n2.3.4 Mô hình Boosting:\nTiếp đó, chúng ta sẽ thử với thuật toán boosting khá phổ biến là: Stochastic Gradient Boosting.\nStochastic Gradient Boosting: Là một biến thể của gradient boosting, kết hợp các yếu tố ngẫu nhiên trong quá trình huấn luyện để cải thiện tính chính xác và khả năng tổng quát của mô hình. Thay vì sử dụng toàn bộ dữ liệu huấn luyện để xây dựng mỗi mô hình trong chuỗi, Stochastic Gradient Boosting chỉ sử dụng một mẫu ngẫu nhiên (subsample) của dữ liệu. Mỗi mô hình mới được huấn luyện để sửa chữa các sai số của các mô hình trước đó.\nMục tiêu là giảm thiểu hàm mất mát (loss function) bằng cách sử dụng gradient descent.\n\n\nCode\nlibrary(caret)\n# Tạo một đối tượng control cho cross-validation\nfitControl &lt;- trainControl(method=\"repeatedcv\", \n                        number=10, \n                        repeats=10)\n# Trong đó\n# method = 'repeatedcv': sử dụng cross-validation với các tham số sau:\n# number = 10 có nhĩa là quá trình cross-validation cần chia dữ liệu gốc thành 10 phần bằng nhau\n# repeats = 10 có nghĩa là quá trình cross-validation cần lặp lại 10 lần\n\n# Stochastic Gradient Boosting\nset.seed(825)\ngbmFit1 &lt;- train(Order_Demand~., \n                 data = train_data %&gt;% \n                   select(-c(order_date,class)), \n                 method = \"gbm\",\n                 trControl = fitControl,\n                 ## This last option is actually one\n                 ## for gbm() that passes through\n                 verbose = FALSE)\n\n\nSau khi đã training model, ta sẽ dùng mô hình đó để dự đoán và so sánh với giá trị thực tế ở testing data. Ta sẽ có kết quả như dưới đây:\nKết quả có vẻ ổn hơn Random Forest nhưng vẫn có 2 outliears vì độ chênh lệch lên đến 100-200%.\n\n\nCode\npredict&lt;-data.frame(\n  Period = test_data$order_date,\n  Predicted = predict(gbmFit1, \n                      newdata = test_data %&gt;% \n                        select(-c(order_date,class))),\n  Observed = test_data$Order_Demand) %&gt;% \n  mutate(Diff = round((Observed - Predicted)/Observed*100,2),\n         Check = ifelse(Diff &lt;= 5 & Diff &gt;= -5, \"Passed\",\"Failed\"))\n\nlibrary(gt)\nlibrary(gtExtras)\ngt(predict %&gt;% \n     count(Check) %&gt;% \n     mutate(Per = round(n/nrow(predict),3))) %&gt;% \n  cols_label(\n    Check = md(\"**Status**\"),\n    n = md(\"**Count**\"),\n    Per = md(\"**Percentage**\")) %&gt;%\n  tab_header(\n    title = md(\"**Evaluating the model's accuracy**\"),\n    subtitle = glue::glue(\"Forecasting from {min(test_data$order_date)} to {max(test_data$order_date)}\")) %&gt;%\n   tab_source_note(\n    source_note = str_glue(\"Smaller 5% means passed\")) %&gt;% \n  gt_theme_538() %&gt;% \n  data_color(columns = c(\"Check\"),\n             method = \"factor\",\n             palette = c(\"red\",\"blue\"))\nggplot(data = predict,\n       aes(x = Period, \n           y = Diff)) + \n  geom_point() +\n  geom_smooth(method = \"lm\")+\n  geom_abline(intercept = 1, \n              slope = 0, color=\"red\", \n              linetype=\"dashed\", \n              size=1)+\n  xlab('Time') +\n  ylab('Difference (%)') +\n  theme_bw()+\n  labs(title = \"Evaluating model builded by GBM method\",\n       subtitle = \"Observed vs Predicted value\",\n       caption = \"The red line is abline Y = 0 means accuracry prediction and the blue line is the linear lines between observed and predicted value.\")\n\n\n\n\n\n\n\n\n  \n    \n      Evaluating the model’s accuracy\n\n    \n    \n      Forecasting from 2014-06-16 to 2015-05-25\n    \n    \n      Status\n\n      Count\n\n      Percentage\n\n    \n  \n  \n    Failed\n27\n0.587\n    Passed\n19\n0.413\n  \n  \n    \n      Smaller 5% means passed"
  },
  {
    "objectID": "EnsembleML.html#tuning-parameters",
    "href": "EnsembleML.html#tuning-parameters",
    "title": "Machine Learning",
    "section": "3 Tuning parameters:",
    "text": "3 Tuning parameters:\nTiêu đề của mục này là keyword mà bạn cần nắm về Machine Learning. Theo nghiên cứu của (Dũng, Nguyễn Chí, n.d.), các thuật toán ML có các tham số mà việc điều chỉnh tham số sẽ ảnh hưởng đến kết quả dự đoán. Vậy chuyên đề tìm ra tham số tối ưu nhất là mục quan trọng khi bạn sử dụng ML.\nVề mặt lý thuyết, có nhiều cách để tìm ra, ở bài này mình sẽ sử dụng 3 cách là:\n\nFull Grid Search.\nRandom Search.\nDefault Search.\n\nVà hầu như không có cách nào tìm ra tham số tối ưu nhất bằng cách thực nghiệm trên một bộ dữ liệu thực tế. Do đó, ở bài này, chúng ta sẽ lược qua cả 3 cách đã nêu trên và so sánh chúng để chọn ra các tối ưu nhất.\nVậy có quá nhiều thuật toán ML vậy, làm sao ta biết được thuật toán nào cần chỉnh tham số nào? Trong R có hàm để chúng ta tự tìm hiểu, đó là getModelInfo. Dưới đây là 1 ví dụ về thuật toán mà ta đã dùng ở trên:\n\n\nCode\ngetModelInfo(\"gbm\")$gbm$parameters\n\n\n          parameter   class                   label\n1           n.trees numeric   # Boosting Iterations\n2 interaction.depth numeric          Max Tree Depth\n3         shrinkage numeric               Shrinkage\n4    n.minobsinnode numeric Min. Terminal Node Size\n\n\nVậy tiếp theo chúng ta sẽ điều chỉnh tham số để tối ưu kết quả của mô hình. Chi tiết ở dưới phần code.\n\nnumber of iterations, i.e. trees, (called n.trees in the gbm function).\ncomplexity of the tree, called interaction.depth learning rate: how quickly the algorithm adapts, called shrinkage.\nthe minimum number of training set samples in a node to commence splitting (n.minobsinnode)\n\nDựa trên hướng dẫn của (Jason Brownlee 2020), ta sẽ thực hành qua cả 3 phương pháp. Code chi tiết dưới đây.\n\n3.0.1 Phương pháp Random Search:\n\n\n\n\n\n\nRandom Search\n\n\n\ncontrol &lt;- trainControl(method=“repeatedcv”, number=10, repeats=3, search=“random”)\nmtry &lt;- sqrt(ncol(train_data))\ngbm_random &lt;- train(Order_Demand~., data = train_data %&gt;% select(-c(order_date,class)), method=“gbm”, tuneLength = 5, trControl = control)\nplot(gbm_random)\n\n\n\n\n3.0.2 Phương pháp Grid Search:\nVới phương pháp Grid Search, ta chỉ cần đổi đối số search = \"grid\" và thêm đối số tuneGrid.\n\n\n\n\n\n\nGrid Search\n\n\n\ncontrol &lt;- trainControl(method=“repeatedcv”, number=10, repeats=3, search=“grid”)\ntunegrid &lt;- expand.grid(.mtry=c(1:5))\ngbm_gridsearch&lt;-train(Order_Demand~., data = train_data %&gt;% select(-c(order_date,class)), method=“gbm”, tuneGrid=tunegrid, trControl = control)\nplot(gbm_gridsearch)\n\n\nCảm ơn các bạn đã ghé thăm và đọc bài viết của mình!!!"
  },
  {
    "objectID": "index.html#định-nghĩa",
    "href": "index.html#định-nghĩa",
    "title": "Giới thiệu",
    "section": "",
    "text": "Trong quản lí chuỗi cung ứng, thuật ngữ Demand Planning là một trong những hoạt động quan trọng mà các nhà quản lí và doanh nghiệp cần quan tâm sâu sắc. Về định nghĩa, theo (Vilas, n.d.) “Demand Planning là một quá trình quản lý chuỗi cung ứng nhằm dự báo nhu cầu về sản phẩm để đảm bảo chúng có thể được cung cấp và làm hài lòng khách hàng. Mục tiêu của Demand planning là đạt được sự cân bằng trong việc có đủ lượng hàng tồn kho để đáp ứng nhu cầu của khách hàng mà không bị thiếu hoặc thừa. Để có thể dự báo được nhu cầu mua hàng, nhà Hoạch định nhu cầu cần thu thập và phân tích dữ liệu từ nhiều nguồn khác nhau như: hàng tồn kho, nhà cung ứng, kho, khách hàng,…”.\n\n\n\nHình 1: Định nghĩa về Demand Planning"
  },
  {
    "objectID": "index.html#lợi-ích-của-demand-planning",
    "href": "index.html#lợi-ích-của-demand-planning",
    "title": "Giới thiệu",
    "section": "",
    "text": "Việc dự đoán trước nhu cầu của khách hàng sẽ giúp doanh nghiệp chuẩn bị tốt hơn về hàng hóa, dịch vụ và chiếm được lòng tin của khách hàng. Ngoài ra, việc chuẩn bị sớm cũng tránh các hiện tượng như out-stock, tranh chấp hoặc tệ hơn đứt gãy chuỗi cung ứng và ảnh hưởng nặng nề tới kết quả kinh doanh của công ty.\nỞ vị trí nhân viên, bạn có thể ứng tuyển vị trí Demand Planner để có thể làm việc về Demand Planning. Còn ở vị trí cấp cao hơn sẽ là Supply Chain Planner - là người có thể xử lí luôn cả 4 vấn đề như sau:\n\nDemand planning: Dự đoán nhu cầu khách hàng bao nhiêu.\nSupply planning: Lên kế hoạch phân phối, tồn kho.\nProdcution planning: Chuẩn bị nguyên vật liệu để sản xuất ở nhà máy. Thông thường hoạt động này chỉ xảy ra ở công ti lớn có cả chuỗi cung ứng từ nhà máy đến nhà kho và có thể cả cửa hàng.\nFulfillment planning: Hoạt động này cũng giống Supply planning nhưng ở mức độ cao cấp hơn. Việc lên kế hoạch còn đòi hỏi phải thỏa mãn các nhu cầu khác của khách hàng như: hàng hóa đúng số lượng, đúng sản phẩm và nhận hàng với thời gian ngắn nhất.\n\n\n\n\nHình 2: Các chức năng chính của Supply Chain Planner\n\n\nỞ phần bài tập này, chúng ta sẽ học về cách sử dụng R trong việc phân tích và dự đoán dữ liệu bằng 2 cách: mô hình ARIMA và Machine Learning.\nBài tập này dựa vào bộ dữ liệu từ (FelixZhao 2017) của Frank Corrigan. Nếu bí ý tưởng, bạn có thể kham khảo thêm phần phân tích của anh ấy thông qua bài blog (Frank 2019)."
  },
  {
    "objectID": "SARIMA.html",
    "href": "SARIMA.html",
    "title": "Mô hình SARIMA",
    "section": "",
    "text": "Bạn có thể quay lại trang đầu tiên để lấy dữ liệu gốc và các bước để chỉnh sửa dữ liệu ở Giới thiệu.\n\n\nTheo nghiên cứu của (JOHN A. MILLER, MOHAMMED ALDOSARI, and NASID HABIB BARNA 2024),họ nhắc đến mô hình SARIMAX có performance tốt hơn ARIMA. Vậy SARIMAX là gì:\n\nĐịnh nghĩa: ARIMA đóng vai trò là nền tảng để lập mô hình dữ liệu không theo mùa (non-seasonal), trong khi SARIMA mở rộng khả năng xử lý các mẫu theo mùa.\nThành phần: SARIMAX cũng xây dựng dựa trên lý thuyết như ARIMA nhưng thêm 2 yếu tố mới là Seasonal và Exogenous variables. Còn mô hình SARMA thì chỉ có thêm yếu tố Seasonal.\n\nThực tế, mô hình mà R đề xuất trên bằng hàm auto.arima() cũng đã bao gồm thành phần seasonal nên ta có thể xem mô hình trên SARIMA.\n\n\n\nHình 5: Stationary and non-stationary series\n\n\nDưới đây là ví dụ về mô hình SARIMA và cách để code trong R.\nGiải thích lại các thông số ta sử dụng sẽ là:\n\n(p,d,q) là bậc AR, mức độ khác biệt - Difference và bậc MA.\n(P,D,Q) là bậc seasonal của mô hình.\n[s] (period arguments) là thông số cho pattern. Ví dụ trong dữ liệu này là dữ liệu của 12 tháng nên period = 12. Bạn có thể gặp dữ liệu theo quý thì period = 3, dữ liệu theo năm thì period = 1.\n\nVậy thì còn mô hình SARIMAX thì khác gì với SARIMA.\n\n\n\nĐể xây dựng mô hình SARIMAX thì ta cần thêm 1 biến khác không phải là biến quá khứ của dữ liệu. Gỉa sử ta tạo thêm 1 biến là thu nhập bình quân của người dân trong khoảng thời gian đó.\n\n\nCode\n# Tạo biến mới thu nhập bình quân:\nincome&lt;-ts(data = runif(nrow(month_df),100,500),\n           frequency = 12,\n           start = c(2012,1))\n\nlibrary(forecast)\nggtsdisplay(income,\n            main = \"Time-series plot of median income\")\n\n\n\n\n\nSau đó ta xây dựng mô hình như các bước cũ:\n\n\nCode\n#Forecast by training model:\nmodel_training2&lt;-Arima(demand_training,,\n             xreg = income[1:length(demand_training)],\n             order = c(3,1,3),\n             seasonal = list(order = c(1,1,0),\n                             period = 12),\n             lambda = NULL,\n             include.constant = TRUE)\n\ncheckresiduals(model_training2,\n               theme = theme_bw())\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(3,1,3)(1,1,0)[12] errors\nQ* = 8.1415, df = 3, p-value = 0.04318\n\nModel df: 7.   Total lags used: 10\n\n\n\n\nCode\ntraining_forecast2&lt;-forecast(model_training2,\n                             xreg = income[39:nrow(month_df)],\n                             h = 21)\n\n#Use chart for presenting the differents:\nplot(training_forecast2,\n      main = str_glue(\"Model ARIMA(2,0,0)\"),\n      xlab = \"Time\",\n      ylab = \"Order Demand\")\nlines(demand_testing, \n      col = \"red\",\n      lwd = \"2\")\nlegend(\"topleft\",\n       legend = c(\"Actual\",\"Forecast\"),\n       col = c(\"red\",\"blue\"),\n       box.lty = 0,\n       lty = 1,\n       cex = 1,\n       lwd = 2)\n\n\n\n\n\nVà sau đó, ta sẽ sử dụng model đó để dự đoán cho tương lai. Nhìn biểu đồ ta dễ dàng kết luận mô hình không tốt. Nguyên do là tương quan giữa biến income và demand_training quá thấp, chỉ số tương quan chỉ có 0.128.\n\n\n\n\n\n\nThực tế, ta thấy mô hình do R đề xuất bằng hàm auto.arima có vẻ “overfitting” - nghĩa là mô hình tốt quá, cover hết các trường hợp nhưng có nguy cơ không cho dự đoán tốt vì dữ liệu trong tương lai biến động.\nVì vậy, ta cần xây dựng cách lựa chọn mô hình theo cách khác. Mình có kham khảo cách này trên How can I select the best SARIMA model.\n\n\nCode\n## List all parameters can be appeared:\nqQ=list()\nfor(i in 1:14) qQ[[i]]=c(i-1,0)\nqQ[[15]]=c(0,1)\nqQ[[16]]=c(1,1)\npP=qQ\n \ndt_params=c()\nfor(i in 1:16){\n  for(j in 1:16){\n     temp=c(pP[[i]][1],1,qQ[[j]][1],pP[[i]][2],1,\n            qQ[[j]][2],12)\n     dt_params=rbind(temp,dt_params)\n   }\n }\ncolnames(dt_params)=c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"T\")\nrownames(dt_params)=1:256\n\n# Build all the models:\nmodels=vector(\"list\",256)\nfor(i in 1:256){\n   try(models[[i]]&lt;-Arima(diff(demand_training,lag = 1),\n                          order = dt_params[i,1:3],\n                          seasonal = list(order=dt_params[i,4:6],\n                                          period=12),\n                     lambda = NULL,\n                     method=\"ML\"))  ## use MLE (maximum likelihood estimation)\n}\n\n\nSau khi đã xây dựng hết các mô hình bằng 256 thông số. Ta sẽ kiểm tra giả thuyết về tính độc lập trong một chuỗi thời gian nhất định (White noise) - nghĩa là kiểm tra phần dư (residuals) của mô hình có phải là random noise không ?\n\n\nCode\n## Applied Ljung-Box Tests:\naa=rep(NA,256)\nfor(i in 1:256){\n   if(length(models[[i]]$residuals)&gt;1){\n     a=Box.test(x = models[[i]]$residuals,\n                lag = 10,\n                type = \"Box-Pierce\")\n     z=prod(1-(a[[\"p.value\"]]&lt;.05))\n     if(z==1) aa[i]=\"Passed\"\n     else aa[i]=\"Failed\"\n   }\n}\n\n## Transfers all these information into 1 table:\ndt_params2=data.frame(dt_params)\ndt_params2$residuals=aa\n\naic=rep(NA,256)\nmodel_names=rep(NA,256)\nfor(i in 1:256){\n   if(length(models[[i]]$aic)&gt;0){\n     aic[i]=models[[i]]$aic\n     model_names[i]=as.character(models[[i]])\n   }\n}\ndt_params2$aic=aic\ndt_params2$model=model_names\n\n\nCuối cùng trình bày bảng 10 model tốt nhất với 2 điều kiện:\n\nChỉ số AIC thấp trong top 10.\nChỉ số p của Ljung-Box Test &lt; 0.05.\n\nVà mô hình cuối cùng được chọn là ARIMA(2,1,0)(0,1,0)[12] với chỉ số AIC là 189.8917.\n\n\nCode\n## Finally plot the table and compared the AIC and BIC value among models:\ngt&lt;-dt_params2[order(dt_params2$aic,decreasing = FALSE),][1:10,] %&gt;%\n     filter(residuals == \"Passed\") %&gt;% ### Just select the models with p &lt; 0.05\n     relocate(model)\n## Just select 10 best models:\n\n\nlibrary(gt)\nlibrary(gtExtras)\n\n\nWarning: package 'gtExtras' was built under R version 4.2.3\n\n\nCode\ngt(gt) %&gt;% \n  cols_align(\n    align = \"left\",\n    columns = \"model\"\n  ) %&gt;% \n    cols_label(\n    model = md(\"**Model**\"),\n    aic = md(\"**AIC value**\")) %&gt;%\n   tab_header(\n    title = md(\"**Ljung–Box test**\"),\n    subtitle = glue::glue(\"Time from {min(training_df$datetime)} to {max(training_df$datetime)}\")) %&gt;%\n   tab_source_note(\n    source_note = \"Null hypothesis: a given time series is independence\") %&gt;% \n  gt_theme_538() %&gt;% \n  gt_highlight_rows(rows = 1, \n                    font_weight = \"normal\")\n\n\n\n\n\n\n  \n    \n      Ljung–Box test\n\n    \n    \n      Time from 2012-01-01 to 2015-03-01\n    \n    \n      Model\n\n      p\n      d\n      q\n      P\n      D\n      Q\n      T\n      residuals\n      AIC value\n\n    \n  \n  \n    ARIMA(2,1,1)(0,1,0)[12]\n2\n1\n1\n0\n1\n0\n12\nPassed\n190.2729\n    ARIMA(2,1,2)(0,1,0)[12]\n2\n1\n2\n0\n1\n0\n12\nPassed\n191.1681\n    ARIMA(3,1,1)(0,1,0)[12]\n3\n1\n1\n0\n1\n0\n12\nPassed\n191.2535\n    ARIMA(2,1,1)(0,1,1)[12]\n2\n1\n1\n0\n1\n1\n12\nPassed\n191.6419\n    ARIMA(3,1,1)(0,1,1)[12]\n3\n1\n1\n0\n1\n1\n12\nPassed\n192.6654\n    ARIMA(4,1,1)(0,1,0)[12]\n4\n1\n1\n0\n1\n0\n12\nPassed\n193.1045\n    ARIMA(2,1,3)(0,1,0)[12]\n2\n1\n3\n0\n1\n0\n12\nPassed\n193.1531\n    ARIMA(3,1,2)(0,1,0)[12]\n3\n1\n2\n0\n1\n0\n12\nPassed\n193.1566\n    ARIMA(2,1,5)(0,1,0)[12]\n2\n1\n5\n0\n1\n0\n12\nPassed\n194.1552\n    ARIMA(2,1,0)(0,1,0)[12]\n2\n1\n0\n0\n1\n0\n12\nPassed\n194.2871\n  \n  \n    \n      Null hypothesis: a given time series is independence\n    \n  \n  \n\n\n\n\n\n\n\nVà cuối cùng là đánh giá mô hình vừa được chọn ARIMA(2,1,0)(0,1,0)[12] với dữ liệu thực tế từ đối tượng demand_testing.\n\n\nCode\n#Forecast by training model:\nmodel_training3&lt;-Arima(diff(demand_training,lag = 1),\n                       order = c(2,1,1),\n                       seasonal = list(order = c(0,1,0),\n                                       period = 12),\n             lambda = NULL)\n\ntraining_forecast3&lt;-forecast(model_training3,\n                             h = 21)\n\n#Use chart for presenting the differents:\nplot(training_forecast3,\n      main = glue::glue(\"Model {gt[['model']][1]}\"),\n      xlab = \"Time\",\n      ylab = \"Order Demand\")\nlines(diff(demand_testing,lag = 1), \n      col = \"red\",\n      lwd = \"2\")\nlegend(\"topleft\",\n       legend = c(\"Actual\",\"Forecast\"),\n       col = c(\"red\",\"blue\"),\n       box.lty = 0,\n       lty = 1,\n       cex = 1,\n       lwd = 2)\n\n\n\n\n\n\n\n\nSau khi đã xây dựng mô hình, ta cần kiểm tra lại các giả thuyết như:\n\nPhần dư không tương quan.\nPhần dư có trung bình là 0.\nphương sai không đổi\nPhần dư có phân phối chuẩn.\n\n\n\nCode\n## Diagnostics the ARRIMA model in a short command:\ncheckresiduals(model_training3,\n               theme = theme_bw())\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,1,1)(0,1,0)[12]\nQ* = 6.3324, df = 5, p-value = 0.2752\n\nModel df: 3.   Total lags used: 8\n\n\nNếu so sánh với mô hình ban đầu theo cách auto.arima thì có vẻ mô hình này tệ hơn. Nhưng có thể ở trong tương lai, mô hình này có thể sẽ tốt hơn chăng.\n\n\nCode\n## Calculating MAE metric:\nsum = 0\nfor (i in 1:21){ \n  sum = abs(diff(demand_testing,lag = 1)[i]-training_forecast3$mean[i])+sum\n} \n\nMAE = sum/21\n\n## Calculating RMSE metric:\nRMSE = sqrt(mean((diff(demand_testing,lag = 1) - training_forecast3$mean)^2))\n\n## Plot the compared results:\ngt(data.frame(Metric = c(\"MAE\",\"RMSE\"),\n              Manual = c(MAE,RMSE),\n              Auto.Arima = c(6.428828,7.534382))) %&gt;% \n  cols_label(\n    Manual = md(\"**Manual method**\"),\n    Auto.Arima = md(\"**Auto.Arima method**\")) %&gt;%\n  cols_align(\n    align = \"center\",\n    columns = \"Manual\"\n  ) %&gt;% \n  cols_align(\n    align = \"center\",\n    columns = \"Auto.Arima\"\n  ) %&gt;% \n  tab_header(\n    title = md(\"**Comparing the accuracy of forecasting**\"),\n    subtitle = glue::glue(\"Forecasting from {min(testing_df$datetime)} to {max(testing_df$datetime)}\")) %&gt;%\n   tab_source_note(\n    source_note = str_glue(\"Between Manual and Auto ARIMA Method\")) %&gt;% \n  gt_theme_538() %&gt;% \n  gt_highlight_cols(Auto.Arima, \n                    fill = \"blue\", \n                    alpha = 0.5)\n\n\n\n\n\n\n  \n    \n      Comparing the accuracy of forecasting\n\n    \n    \n      Forecasting from 2015-03-01 to 2016-12-01\n    \n    \n      Metric\n      Manual method\n\n      Auto.Arima method\n\n    \n  \n  \n    MAE\n8.652821\n6.428828\n    RMSE\n10.476431\n7.534382\n  \n  \n    \n      Between Manual and Auto ARIMA Method\n    \n  \n  \n\n\n\n\n\n\n\n\nDưới đây là kết quả dự đoán từ mô hình trong 3 năm tiếp theo ~ 18 tháng.\n\n\nCode\ndemand_full&lt;-ts(month_df$month_demand,\n                      frequency = 12,\n                      start = c(2012,1))\n\n#Predicting for 18 months with 99.5% range:\npredict_fit&lt;-forecast:::forecast.Arima(model_training3,\n                                       h = 18, \n                                       level = c(99.5)) \n\n#Transform to data.frame object:\ndf&lt;-predict_fit %&gt;% \n  as.data.frame() %&gt;% \n  mutate(Period = seq(max(month_df$datetime),\n                    max(month_df$datetime)+months(18), \n                    by= \"1 month\")[-1]) %&gt;% \n  relocate(Period)\n\n\n\n\nCode\ngt(df[1:9,]) %&gt;% \n  tab_header(\n    title = md(\"**Forecasting Order Demand**\"),\n    subtitle = glue::glue(\"Time from {max(month_df$datetime)} to {max(month_df$datetime)+months(9)}\")) %&gt;%\n   tab_source_note(\n    source_note = glue::glue(\"Method: Model {gt[['model']][1]}\")) %&gt;% \n  gt_theme_538() \ngt(df[10:18,]) %&gt;% \n  tab_header(\n    title = md(\"**Forecasting Order Demand**\"),\n    subtitle = glue::glue(\"Time from {max(month_df$datetime)+months(9)} to {max(month_df$datetime)+months(18)}\")) %&gt;%\n  gt_theme_538() \n#Plot the forecast value\nforecast:::plot.forecast(predict_fit, \n     xlab =\"Time\",\n     ylab = \"Order demand\")\n\n\n\n\n\n\n\n\n  \n    \n      Forecasting Order Demand\n\n    \n    \n      Time from 2016-12-01 to 2017-09-01\n    \n    \n      Period\n      Point Forecast\n      Lo 99.5\n      Hi 99.5\n    \n  \n  \n    2017-01-01\n-0.3025843\n-25.51830\n24.913133\n    2017-02-01\n-9.4633515\n-36.62171\n17.695007\n    2017-03-01\n6.7844395\n-22.34186\n35.910740\n    2017-04-01\n4.8964391\n-26.63581\n36.428686\n    2017-05-01\n-24.2754428\n-55.88982\n7.338937\n    2017-06-01\n18.5468600\n-13.98819\n51.081910\n    2017-07-01\n8.3588213\n-24.30408\n41.021726\n    2017-08-01\n-5.8293675\n-38.81299\n27.154252\n    2017-09-01\n3.9261880\n-29.17795\n37.030330\n  \n  \n    \n      Method: Model ARIMA(2,1,1)(0,1,0)[12]\n    \n  \n  \n\n\n\n\n\n\n\n\n  \n    \n      Forecasting Order Demand\n\n    \n    \n      Time from 2017-09-01 to 2018-06-01\n    \n    \n      Period\n      Point Forecast\n      Lo 99.5\n      Hi 99.5\n    \n  \n  \n    2017-10-01\n10.1401433\n-22.96736\n43.24765\n    2017-11-01\n-13.8715418\n-47.12279\n19.37971\n    2017-12-01\n16.1556198\n-17.09157\n49.40281\n    2018-01-01\n-0.2720208\n-41.40027\n40.85623\n    2018-02-01\n-8.8038655\n-50.82244\n33.21471\n    2018-03-01\n7.2730026\n-35.80101\n50.34702\n    2018-04-01\n5.0611881\n-39.57847\n49.70085\n    2018-05-01\n-23.8592527\n-68.57801\n20.85951\n    2018-06-01\n19.0576303\n-26.14966\n64.26492\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\nVậy tiếp theo ta sẽ vào phần phân tích ở trang Machine Learning."
  },
  {
    "objectID": "SARIMA.html#chuẩn-bị-dữ-liệu",
    "href": "SARIMA.html#chuẩn-bị-dữ-liệu",
    "title": "Mô hình SARIMA",
    "section": "",
    "text": "Bạn có thể quay lại trang đầu tiên để lấy dữ liệu gốc và các bước để chỉnh sửa dữ liệu ở Giới thiệu.\n\n\nTheo nghiên cứu của (JOHN A. MILLER, MOHAMMED ALDOSARI, and NASID HABIB BARNA 2024),họ nhắc đến mô hình SARIMAX có performance tốt hơn ARIMA. Vậy SARIMAX là gì:\n\nĐịnh nghĩa: ARIMA đóng vai trò là nền tảng để lập mô hình dữ liệu không theo mùa (non-seasonal), trong khi SARIMA mở rộng khả năng xử lý các mẫu theo mùa.\nThành phần: SARIMAX cũng xây dựng dựa trên lý thuyết như ARIMA nhưng thêm 2 yếu tố mới là Seasonal và Exogenous variables. Còn mô hình SARMA thì chỉ có thêm yếu tố Seasonal.\n\nThực tế, mô hình mà R đề xuất trên bằng hàm auto.arima() cũng đã bao gồm thành phần seasonal nên ta có thể xem mô hình trên SARIMA.\n\n\n\nHình 5: Stationary and non-stationary series\n\n\nDưới đây là ví dụ về mô hình SARIMA và cách để code trong R.\nGiải thích lại các thông số ta sử dụng sẽ là:\n\n(p,d,q) là bậc AR, mức độ khác biệt - Difference và bậc MA.\n(P,D,Q) là bậc seasonal của mô hình.\n[s] (period arguments) là thông số cho pattern. Ví dụ trong dữ liệu này là dữ liệu của 12 tháng nên period = 12. Bạn có thể gặp dữ liệu theo quý thì period = 3, dữ liệu theo năm thì period = 1.\n\nVậy thì còn mô hình SARIMAX thì khác gì với SARIMA.\n\n\n\nĐể xây dựng mô hình SARIMAX thì ta cần thêm 1 biến khác không phải là biến quá khứ của dữ liệu. Gỉa sử ta tạo thêm 1 biến là thu nhập bình quân của người dân trong khoảng thời gian đó.\n\n\nCode\n# Tạo biến mới thu nhập bình quân:\nincome&lt;-ts(data = runif(nrow(month_df),100,500),\n           frequency = 12,\n           start = c(2012,1))\n\nlibrary(forecast)\nggtsdisplay(income,\n            main = \"Time-series plot of median income\")\n\n\n\n\n\nSau đó ta xây dựng mô hình như các bước cũ:\n\n\nCode\n#Forecast by training model:\nmodel_training2&lt;-Arima(demand_training,,\n             xreg = income[1:length(demand_training)],\n             order = c(3,1,3),\n             seasonal = list(order = c(1,1,0),\n                             period = 12),\n             lambda = NULL,\n             include.constant = TRUE)\n\ncheckresiduals(model_training2,\n               theme = theme_bw())\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(3,1,3)(1,1,0)[12] errors\nQ* = 8.1415, df = 3, p-value = 0.04318\n\nModel df: 7.   Total lags used: 10\n\n\n\n\nCode\ntraining_forecast2&lt;-forecast(model_training2,\n                             xreg = income[39:nrow(month_df)],\n                             h = 21)\n\n#Use chart for presenting the differents:\nplot(training_forecast2,\n      main = str_glue(\"Model ARIMA(2,0,0)\"),\n      xlab = \"Time\",\n      ylab = \"Order Demand\")\nlines(demand_testing, \n      col = \"red\",\n      lwd = \"2\")\nlegend(\"topleft\",\n       legend = c(\"Actual\",\"Forecast\"),\n       col = c(\"red\",\"blue\"),\n       box.lty = 0,\n       lty = 1,\n       cex = 1,\n       lwd = 2)\n\n\n\n\n\nVà sau đó, ta sẽ sử dụng model đó để dự đoán cho tương lai. Nhìn biểu đồ ta dễ dàng kết luận mô hình không tốt. Nguyên do là tương quan giữa biến income và demand_training quá thấp, chỉ số tương quan chỉ có 0.128."
  },
  {
    "objectID": "SARIMA.html#thực-hành-trong-r",
    "href": "SARIMA.html#thực-hành-trong-r",
    "title": "Mô hình SARIMA",
    "section": "",
    "text": "Thực tế, ta thấy mô hình do R đề xuất bằng hàm auto.arima có vẻ “overfitting” - nghĩa là mô hình tốt quá, cover hết các trường hợp nhưng có nguy cơ không cho dự đoán tốt vì dữ liệu trong tương lai biến động.\nVì vậy, ta cần xây dựng cách lựa chọn mô hình theo cách khác. Mình có kham khảo cách này trên How can I select the best SARIMA model.\n\n\nCode\n## List all parameters can be appeared:\nqQ=list()\nfor(i in 1:14) qQ[[i]]=c(i-1,0)\nqQ[[15]]=c(0,1)\nqQ[[16]]=c(1,1)\npP=qQ\n \ndt_params=c()\nfor(i in 1:16){\n  for(j in 1:16){\n     temp=c(pP[[i]][1],1,qQ[[j]][1],pP[[i]][2],1,\n            qQ[[j]][2],12)\n     dt_params=rbind(temp,dt_params)\n   }\n }\ncolnames(dt_params)=c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"T\")\nrownames(dt_params)=1:256\n\n# Build all the models:\nmodels=vector(\"list\",256)\nfor(i in 1:256){\n   try(models[[i]]&lt;-Arima(diff(demand_training,lag = 1),\n                          order = dt_params[i,1:3],\n                          seasonal = list(order=dt_params[i,4:6],\n                                          period=12),\n                     lambda = NULL,\n                     method=\"ML\"))  ## use MLE (maximum likelihood estimation)\n}\n\n\nSau khi đã xây dựng hết các mô hình bằng 256 thông số. Ta sẽ kiểm tra giả thuyết về tính độc lập trong một chuỗi thời gian nhất định (White noise) - nghĩa là kiểm tra phần dư (residuals) của mô hình có phải là random noise không ?\n\n\nCode\n## Applied Ljung-Box Tests:\naa=rep(NA,256)\nfor(i in 1:256){\n   if(length(models[[i]]$residuals)&gt;1){\n     a=Box.test(x = models[[i]]$residuals,\n                lag = 10,\n                type = \"Box-Pierce\")\n     z=prod(1-(a[[\"p.value\"]]&lt;.05))\n     if(z==1) aa[i]=\"Passed\"\n     else aa[i]=\"Failed\"\n   }\n}\n\n## Transfers all these information into 1 table:\ndt_params2=data.frame(dt_params)\ndt_params2$residuals=aa\n\naic=rep(NA,256)\nmodel_names=rep(NA,256)\nfor(i in 1:256){\n   if(length(models[[i]]$aic)&gt;0){\n     aic[i]=models[[i]]$aic\n     model_names[i]=as.character(models[[i]])\n   }\n}\ndt_params2$aic=aic\ndt_params2$model=model_names\n\n\nCuối cùng trình bày bảng 10 model tốt nhất với 2 điều kiện:\n\nChỉ số AIC thấp trong top 10.\nChỉ số p của Ljung-Box Test &lt; 0.05.\n\nVà mô hình cuối cùng được chọn là ARIMA(2,1,0)(0,1,0)[12] với chỉ số AIC là 189.8917.\n\n\nCode\n## Finally plot the table and compared the AIC and BIC value among models:\ngt&lt;-dt_params2[order(dt_params2$aic,decreasing = FALSE),][1:10,] %&gt;%\n     filter(residuals == \"Passed\") %&gt;% ### Just select the models with p &lt; 0.05\n     relocate(model)\n## Just select 10 best models:\n\n\nlibrary(gt)\nlibrary(gtExtras)\n\n\nWarning: package 'gtExtras' was built under R version 4.2.3\n\n\nCode\ngt(gt) %&gt;% \n  cols_align(\n    align = \"left\",\n    columns = \"model\"\n  ) %&gt;% \n    cols_label(\n    model = md(\"**Model**\"),\n    aic = md(\"**AIC value**\")) %&gt;%\n   tab_header(\n    title = md(\"**Ljung–Box test**\"),\n    subtitle = glue::glue(\"Time from {min(training_df$datetime)} to {max(training_df$datetime)}\")) %&gt;%\n   tab_source_note(\n    source_note = \"Null hypothesis: a given time series is independence\") %&gt;% \n  gt_theme_538() %&gt;% \n  gt_highlight_rows(rows = 1, \n                    font_weight = \"normal\")\n\n\n\n\n\n\n  \n    \n      Ljung–Box test\n\n    \n    \n      Time from 2012-01-01 to 2015-03-01\n    \n    \n      Model\n\n      p\n      d\n      q\n      P\n      D\n      Q\n      T\n      residuals\n      AIC value\n\n    \n  \n  \n    ARIMA(2,1,1)(0,1,0)[12]\n2\n1\n1\n0\n1\n0\n12\nPassed\n190.2729\n    ARIMA(2,1,2)(0,1,0)[12]\n2\n1\n2\n0\n1\n0\n12\nPassed\n191.1681\n    ARIMA(3,1,1)(0,1,0)[12]\n3\n1\n1\n0\n1\n0\n12\nPassed\n191.2535\n    ARIMA(2,1,1)(0,1,1)[12]\n2\n1\n1\n0\n1\n1\n12\nPassed\n191.6419\n    ARIMA(3,1,1)(0,1,1)[12]\n3\n1\n1\n0\n1\n1\n12\nPassed\n192.6654\n    ARIMA(4,1,1)(0,1,0)[12]\n4\n1\n1\n0\n1\n0\n12\nPassed\n193.1045\n    ARIMA(2,1,3)(0,1,0)[12]\n2\n1\n3\n0\n1\n0\n12\nPassed\n193.1531\n    ARIMA(3,1,2)(0,1,0)[12]\n3\n1\n2\n0\n1\n0\n12\nPassed\n193.1566\n    ARIMA(2,1,5)(0,1,0)[12]\n2\n1\n5\n0\n1\n0\n12\nPassed\n194.1552\n    ARIMA(2,1,0)(0,1,0)[12]\n2\n1\n0\n0\n1\n0\n12\nPassed\n194.2871\n  \n  \n    \n      Null hypothesis: a given time series is independence\n    \n  \n  \n\n\n\n\n\n\n\nVà cuối cùng là đánh giá mô hình vừa được chọn ARIMA(2,1,0)(0,1,0)[12] với dữ liệu thực tế từ đối tượng demand_testing.\n\n\nCode\n#Forecast by training model:\nmodel_training3&lt;-Arima(diff(demand_training,lag = 1),\n                       order = c(2,1,1),\n                       seasonal = list(order = c(0,1,0),\n                                       period = 12),\n             lambda = NULL)\n\ntraining_forecast3&lt;-forecast(model_training3,\n                             h = 21)\n\n#Use chart for presenting the differents:\nplot(training_forecast3,\n      main = glue::glue(\"Model {gt[['model']][1]}\"),\n      xlab = \"Time\",\n      ylab = \"Order Demand\")\nlines(diff(demand_testing,lag = 1), \n      col = \"red\",\n      lwd = \"2\")\nlegend(\"topleft\",\n       legend = c(\"Actual\",\"Forecast\"),\n       col = c(\"red\",\"blue\"),\n       box.lty = 0,\n       lty = 1,\n       cex = 1,\n       lwd = 2)\n\n\n\n\n\n\n\n\nSau khi đã xây dựng mô hình, ta cần kiểm tra lại các giả thuyết như:\n\nPhần dư không tương quan.\nPhần dư có trung bình là 0.\nphương sai không đổi\nPhần dư có phân phối chuẩn.\n\n\n\nCode\n## Diagnostics the ARRIMA model in a short command:\ncheckresiduals(model_training3,\n               theme = theme_bw())\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,1,1)(0,1,0)[12]\nQ* = 6.3324, df = 5, p-value = 0.2752\n\nModel df: 3.   Total lags used: 8\n\n\nNếu so sánh với mô hình ban đầu theo cách auto.arima thì có vẻ mô hình này tệ hơn. Nhưng có thể ở trong tương lai, mô hình này có thể sẽ tốt hơn chăng.\n\n\nCode\n## Calculating MAE metric:\nsum = 0\nfor (i in 1:21){ \n  sum = abs(diff(demand_testing,lag = 1)[i]-training_forecast3$mean[i])+sum\n} \n\nMAE = sum/21\n\n## Calculating RMSE metric:\nRMSE = sqrt(mean((diff(demand_testing,lag = 1) - training_forecast3$mean)^2))\n\n## Plot the compared results:\ngt(data.frame(Metric = c(\"MAE\",\"RMSE\"),\n              Manual = c(MAE,RMSE),\n              Auto.Arima = c(6.428828,7.534382))) %&gt;% \n  cols_label(\n    Manual = md(\"**Manual method**\"),\n    Auto.Arima = md(\"**Auto.Arima method**\")) %&gt;%\n  cols_align(\n    align = \"center\",\n    columns = \"Manual\"\n  ) %&gt;% \n  cols_align(\n    align = \"center\",\n    columns = \"Auto.Arima\"\n  ) %&gt;% \n  tab_header(\n    title = md(\"**Comparing the accuracy of forecasting**\"),\n    subtitle = glue::glue(\"Forecasting from {min(testing_df$datetime)} to {max(testing_df$datetime)}\")) %&gt;%\n   tab_source_note(\n    source_note = str_glue(\"Between Manual and Auto ARIMA Method\")) %&gt;% \n  gt_theme_538() %&gt;% \n  gt_highlight_cols(Auto.Arima, \n                    fill = \"blue\", \n                    alpha = 0.5)\n\n\n\n\n\n\n  \n    \n      Comparing the accuracy of forecasting\n\n    \n    \n      Forecasting from 2015-03-01 to 2016-12-01\n    \n    \n      Metric\n      Manual method\n\n      Auto.Arima method\n\n    \n  \n  \n    MAE\n8.652821\n6.428828\n    RMSE\n10.476431\n7.534382\n  \n  \n    \n      Between Manual and Auto ARIMA Method"
  },
  {
    "objectID": "SARIMA.html#dự-đoán-số-đơn-hàng-trong-18-tháng-ở-tương-lai",
    "href": "SARIMA.html#dự-đoán-số-đơn-hàng-trong-18-tháng-ở-tương-lai",
    "title": "Mô hình SARIMA",
    "section": "",
    "text": "Dưới đây là kết quả dự đoán từ mô hình trong 3 năm tiếp theo ~ 18 tháng.\n\n\nCode\ndemand_full&lt;-ts(month_df$month_demand,\n                      frequency = 12,\n                      start = c(2012,1))\n\n#Predicting for 18 months with 99.5% range:\npredict_fit&lt;-forecast:::forecast.Arima(model_training3,\n                                       h = 18, \n                                       level = c(99.5)) \n\n#Transform to data.frame object:\ndf&lt;-predict_fit %&gt;% \n  as.data.frame() %&gt;% \n  mutate(Period = seq(max(month_df$datetime),\n                    max(month_df$datetime)+months(18), \n                    by= \"1 month\")[-1]) %&gt;% \n  relocate(Period)\n\n\n\n\nCode\ngt(df[1:9,]) %&gt;% \n  tab_header(\n    title = md(\"**Forecasting Order Demand**\"),\n    subtitle = glue::glue(\"Time from {max(month_df$datetime)} to {max(month_df$datetime)+months(9)}\")) %&gt;%\n   tab_source_note(\n    source_note = glue::glue(\"Method: Model {gt[['model']][1]}\")) %&gt;% \n  gt_theme_538() \ngt(df[10:18,]) %&gt;% \n  tab_header(\n    title = md(\"**Forecasting Order Demand**\"),\n    subtitle = glue::glue(\"Time from {max(month_df$datetime)+months(9)} to {max(month_df$datetime)+months(18)}\")) %&gt;%\n  gt_theme_538() \n#Plot the forecast value\nforecast:::plot.forecast(predict_fit, \n     xlab =\"Time\",\n     ylab = \"Order demand\")\n\n\n\n\n\n\n\n\n  \n    \n      Forecasting Order Demand\n\n    \n    \n      Time from 2016-12-01 to 2017-09-01\n    \n    \n      Period\n      Point Forecast\n      Lo 99.5\n      Hi 99.5\n    \n  \n  \n    2017-01-01\n-0.3025843\n-25.51830\n24.913133\n    2017-02-01\n-9.4633515\n-36.62171\n17.695007\n    2017-03-01\n6.7844395\n-22.34186\n35.910740\n    2017-04-01\n4.8964391\n-26.63581\n36.428686\n    2017-05-01\n-24.2754428\n-55.88982\n7.338937\n    2017-06-01\n18.5468600\n-13.98819\n51.081910\n    2017-07-01\n8.3588213\n-24.30408\n41.021726\n    2017-08-01\n-5.8293675\n-38.81299\n27.154252\n    2017-09-01\n3.9261880\n-29.17795\n37.030330\n  \n  \n    \n      Method: Model ARIMA(2,1,1)(0,1,0)[12]\n    \n  \n  \n\n\n\n\n\n\n\n\n  \n    \n      Forecasting Order Demand\n\n    \n    \n      Time from 2017-09-01 to 2018-06-01\n    \n    \n      Period\n      Point Forecast\n      Lo 99.5\n      Hi 99.5\n    \n  \n  \n    2017-10-01\n10.1401433\n-22.96736\n43.24765\n    2017-11-01\n-13.8715418\n-47.12279\n19.37971\n    2017-12-01\n16.1556198\n-17.09157\n49.40281\n    2018-01-01\n-0.2720208\n-41.40027\n40.85623\n    2018-02-01\n-8.8038655\n-50.82244\n33.21471\n    2018-03-01\n7.2730026\n-35.80101\n50.34702\n    2018-04-01\n5.0611881\n-39.57847\n49.70085\n    2018-05-01\n-23.8592527\n-68.57801\n20.85951\n    2018-06-01\n19.0576303\n-26.14966\n64.26492\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\nVậy tiếp theo ta sẽ vào phần phân tích ở trang Machine Learning."
  },
  {
    "objectID": "Forecasting.html",
    "href": "Forecasting.html",
    "title": "Mô hình ARIMA",
    "section": "",
    "text": "Bạn có thể quay lại trang đầu tiên để lấy dữ liệu gốc và các bước để chỉnh sửa dữ liệu ở Giới thiệu.\nSau khi đã chuyển đổi dữ liệu, tiếp theo chúng ta sẽ chia dữ liệu theo tỉ lệ 70:30. Lý do chia ra là vì ở phần cuối, chúng ta sẽ sử dụng phần 30% bộ dữ liệu để đánh giá mô hình được xây dựng trên 70% bộ dữ liệu.\nViệc chia dữ liệu này cũng khá phổ biến vì ta có thể đánh giá mô hình bằng chính dữ liệu thực tế và không cần tốn thời gian và công sức để theo dõi mô hình trong tương lai nữa.\n\n\nCode\n#First we will divde the data into training data and testing data in 70-30:\n#Create ts object for month demand variable:\ntraining_df&lt;-month_df[month_df$datetime &lt;= as.Date(\"2015-03-01\"),]\ntesting_df &lt;-month_df[month_df$datetime &gt;= as.Date(\"2015-03-01\"),]\n\n\nNhìn hình dưới đây, các bạn có thể hiểu là nhiệm vụ của mình sẽ là xây dựng mô hình dựa vào dữ liệu đã thu được trước ngày 01-03-2015 và dự đoán giá trị cho khoảng thời gian từ 01-03-2015 đến 01-12-2016.\n\n\nCode\ndemand_training&lt;-ts(training_df$month_demand,\n                      frequency = 12,\n                      start = c(2012,1))\ndemand_testing&lt;-ts(testing_df$month_demand,\n                frequency = 12,\n                start = c(2015,3))\n\n## Hiển thị hóa dữ liệu về demand:\nlibrary(dygraphs)\nlines&lt;-cbind(demand_training,\n             demand_testing)\ndygraph(lines,\n        main = \"Training and testing data\", \n        ylab = \"Quantity order (Unit: Millions)\") %&gt;% \n  dySeries(\"demand_training\", label = \"Training data\") %&gt;%\n  dySeries(\"demand_testing\", label = \"Testing data\") %&gt;%\n  dyOptions(fillGraph = TRUE, fillAlpha = 0.4) %&gt;% \n  dyRangeSelector(height = 20)\n\n\n\n\n\n\n\n\nVề thông tin của dữ liệu, đây là dữ liệu thuộc dạng time-series nghĩa là chuỗi dữ liệu theo thời gian nên nó sẽ có các đặt tính chung như:\n\nTrend: Tăng, giảm dài hạn hoặc chuyển động đứng yên.\nSeasonal: Các mô hình có thể dự đoán được ở những khoảng thời gian cố định.\nCycle: Biến động không có chu kỳ nhất quán.\nNoise: Sai số còn sót lại không giải thích được.\n\nVậy mục tiêu của việc phân tích time series là để tìm ra thành phần seasonal trong vì nó có tính lặp lại và có thể dùng để dự đoán cho tương lai. Ngoài ra, thành phần trend cũng cần được quan tâm vì nó thể hiện xu hướng của dữ liệu trong tương lai.\nTrong R, ta có thể phân tích dễ dàng với hàm decompose() như code dưới đây.\nVề công thức tính, hàm decompose() dựa vào kĩ thuật Moving Averages để tính trung bình giá trị theo 1 khoảng thời gian (Vd: 3 tháng 6 tháng hoặc 1 năm).\n\n\n\nHình 3: Additive and multiplicative model\n\n\nCó 2 mô hình gồm Additive và Multiplicative có thể sử dụng. Ở mặc định, hàm decompose() tính theo mô hình Additive, còn bạn muốn tính theo mô hình Multiplicative thì phải thêm đối số type = \"multiplicative\".\n\n\nCode\nlibrary(TSstudio)\nts_decompose(demand_training, \n             type = \"both\")\n\n\n\n\nKhi mức độ biến động của seasonal hoặc sự biến đổi xung quanh trend-cycle không thay đổi theo mức độ của chuỗi thời gian, mô hình Additive sẽ phù hợp hơn mô hình Multiplicative.\n\n\nNhìn sơ bộ, ta có thể thấy xu hướng tăng (trend) của số lượng đơn đặt hàng. Về phần random thì sẽ có 1 khoảng từ (-10,5) số đơn là tự nhiên xảy ra, nghĩa là giá trị dự đoán có thể lệch từ -10 đến 5 đơn hàng và sai lệch này là do tự nhiên.\n\n\n\nTrên thực tế, phần phân tích thành các thành phần của time series chỉ đưa ra dự đoán định tính, không thể dự đoán bằng các dữ liệu trên mà phải cần thông qua mô hình cụ thể. Dưới đây là giới thiệu về mô hình ARIMA.\n\n\nTheo (phamdinhkhanh 2019), Mô hình ARIMA “sử dụng đầu vào chính là những tín hiệu quá khứ của chuỗi được dự báo để dự báo nó. Các tín hiệu đó bao gồm: Chuỗi tự hồi qui AR (auto regression) và chuỗi trung bình trượt MA (moving average).\nHầu hết các chuỗi thời gian sẽ có xu hướng tăng hoặc giảm theo thời gian, do đó yếu tố chuỗi dừng thường không đạt được. Trong trường hợp chuỗi không dừng thì ta sẽ cần biến đổi sang chuỗi dừng bằng sai phân. Khi đó tham số đặc trưng của mô hình sẽ có thêm thành phần bậc của sai phân d và mô hình được đặc tả bởi 3 tham số ARIMA(p, d, q)“.\nMô hình được xây dựng “dựa trên giả thuyết: Stationary series (Chuỗi dừng) đòi hỏi Phương sai sai số không đổi và Nhiễu trắng (White noise), cụ thể trong đó:\n\nStationary series: điều kiện là trung bình của chuỗi là constant (bất biến), phương sai (variance) của chuỗi phải có tính đồng nhất (homoscedasticity) và hiệp phương sai (covariance) giữa giá trị t và t+1 phải không liên quan tới nhau.\n\n\n\n\n\n\nLưu ý\n\n\n\nNếu chuỗi dữ liệu không phải là chuỗi dùng thì bạn sẽ không xây dựng được mô hình chuỗi thời gian (time-series model)\n\n\nNhiễu trắng là: một thành phần ngẫu nhiên thể hiện cho yếu tố không thể dự báo của model và không có tính qui luật.\n\n\n\n\nHình 4: Stationary and non-stationary series\n\n\n\n\n\n\n\nVà để thỏa mãn giả định này, cần tính toán các chỉ số trên và đánh giá và điều này khá phức tạp. Trong R, ta có hàm adf.test() có thể kiểm tra vấn đề này nhanh hơn.\n\n\nCode\nlibrary(tseries)\nadf.test(demand_training)    ## p-value = 0.3779 &gt; 0.05 means this series is not stationary\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  demand_training\nDickey-Fuller = -2.4991, Lag order = 3, p-value = 0.3779\nalternative hypothesis: stationary\n\n\nNhư vậy, ta thấy chuỗi dữ liệu này không phải chuỗi dừng vì giá trị p = 0.3779 &gt; 0.05 nghĩa là chấp nhận giả thuyết H0: Chuỗi này là chuỗi không dừng.\nTrong time-series analyst, ta sẽ có cách để xử lí chuỗi thành chuỗi dừng. Đó là tính sự khác nhau (Difference) giữa giá trị t và giá trị của nó ở quá khứ t-1,t-2,…\nTrong R, bạn có thể tính bằng cách:\n\ndiff(series, lag = n): tính sự khác nhau giữa các thời điểm t và t-n.\nlog(series): chuyển time-series sang dạng log.\n\nNày tùy thuộc vào công thức toán học bạn muốn định nghĩa, miễn sao bạn có thể xác định được chuỗi dừng là đạt.\n\n\nCode\n#First we will calculate the different in demand product monthly:\n#Check stationary assumption:\ntest&lt;-lapply(1:3, function(x) {\n         a&lt;-diff(demand_training, lag = x)\n         adf.test(a)$p.value}\n       ) #p&lt;0,05 is accepted\n\n## Second transform it to dataframe object:\ntest&lt;-data.frame(test)\ncolnames(test)&lt;-c(\"Lag 1\",\"Lag 2\",\"Lag 3\")\n\n## Finally plot the result:\nlibrary(gt)\nlibrary(gtExtras)\ngt(test) %&gt;% \n  cols_align(\n    align = \"left\",\n    columns = \"Lag 1\"\n  ) %&gt;% \n  cols_align(\n    align = \"center\",\n    columns = \"Lag 2\"\n  ) %&gt;%\n   tab_header(\n    title = md(\"**Checking stationary assumption**\"),\n    subtitle = glue::glue(\"Time from {min(month_df$datetime)} to 01-03-2015\")) %&gt;%\n   tab_source_note(\n    source_note = \"Alternative hypothesis: stationary\") %&gt;% \n  gt_theme_538()\n\n\n\n\n\n\n  \n    \n      Checking stationary assumption\n\n    \n    \n      Time from 2012-01-01 to 01-03-2015\n    \n    \n      Lag 1\n      Lag 2\n      Lag 3\n    \n  \n  \n    0.01\n0.01\n0.152641\n  \n  \n    \n      Alternative hypothesis: stationary\n    \n  \n  \n\n\n\n\nKết quả testing cho thấy chỉ có chuỗi 1 và 2 đạt yêu cầu, chuỗi 3 không phải chuỗi dừng vì p-value = 0.107 &gt; 0.05.\n\n\n\n\n\nPACF (Partial Autocorrelation Function) và ACF (Autocorrelation Function) là 2 công thức tính thuộc Autocorrelation Analyst - 1 bước quan trọng trong việc phân tích chuỗi dữ liệu thời gian. Mục tiêu của Autocorrelation analyst là tìm ra các mẫu (pattern) giữa nhiều chuỗi thời gian và kiểm tra tính ngẫu nhiên.\n\n\n\nSau khi đã xác định được chuỗi dừng, bước tiếp theo là xác định các tham số (p, d, q) cho mô hình ARIMA.\nTrong R có hàm ggtsdisplay của package forecast sẽ hiển thị cả ACF, PACF và Time series plot của đối tượng mà bạn gán. Còn nếu bạn muốn hiển thị riêng giá trị ACF hoặc PACF thì dùng hàm Acf hoặc Pacf để tính và dùng hàm autoplot() để hiển thị biểu đồ.\n\n\nCode\n#Rename of two time series:\nts1&lt;-diff(demand_training, lag = 1)\nts2&lt;-diff(demand_training, lag = 2)\n#Plot value ACF for 2 series:\nlibrary(forecast)\nggtsdisplay(ts1,\n            main = \"Time series lag 1\",\n            theme=theme_bw())\nggtsdisplay(ts2,\n            main = \"Time series lag 2\",\n            theme=theme_bw())\n\n\n\n\n\n\n\n\n\n\n\n\nDựa vào tricks từ (Tavish Srivastava 2023), ta sẽ dựa vào giá trị PACF để xác định bậc của AR và ACF để xác định bậc của MA.\nVí dụ ở trên, đối với chuỗi lag 1, giá trị PACF có sự đứt gãy (cut off) ở bậc 2 đến bậc 3 nên có thể thuộc AR(3). Còn giá trị ACF thì có thể thuộc MA(2) hoặc rõ ràng hơn là MA(3). Còn lại, đối với chuỗi lag 2, các bạn có thể làm tương tự.\nVậy mô hình tự chọn cuối cùng là ARIMA(3,0,2).\n\n\n\n\nThực tế, trong R có hàm auto.arimađể chúng ta lựa chọn và so sánh nhiều mô hình ARIMA một cách tự động và không nặng về code như dưới đây. Nó sẽ tự liệt kê ra các mô hình phù hợp và chọn ra mô hình tốt nhất.\nNgoài ra, nếu bạn muốn tìm hiểu sâu về cách xây dựng mô hình ARIMA, bạn có thể tham khảo thêm bài blog (Dũng, n.d.). Anh Chí Dũng có khá nhiều bài viết hay về cách sử dụng R trong nghiên cứu và phân tích kinh tế, bạn có thể tham khảo trang blog của ảnh thông qua đường link chidungkt.\n\n\nCode\n#Select the best model:\nmodel&lt;-auto.arima(ts1,trace = T)\n\n\n\n ARIMA(2,0,2)(1,0,1)[12] with non-zero mean : 279.6301\n ARIMA(0,0,0)            with non-zero mean : 291.5234\n ARIMA(1,0,0)(1,0,0)[12] with non-zero mean : 285.1005\n ARIMA(0,0,1)(0,0,1)[12] with non-zero mean : Inf\n ARIMA(0,0,0)            with zero mean     : 289.5102\n ARIMA(2,0,2)(0,0,1)[12] with non-zero mean : 278.2485\n ARIMA(2,0,2)            with non-zero mean : 276.6431\n ARIMA(2,0,2)(1,0,0)[12] with non-zero mean : 277.2391\n ARIMA(1,0,2)            with non-zero mean : Inf\n ARIMA(2,0,1)            with non-zero mean : 274.6588\n ARIMA(2,0,1)(1,0,0)[12] with non-zero mean : 274.4807\n ARIMA(2,0,1)(1,0,1)[12] with non-zero mean : 276.6914\n ARIMA(2,0,1)(0,0,1)[12] with non-zero mean : 275.6882\n ARIMA(1,0,1)(1,0,0)[12] with non-zero mean : Inf\n ARIMA(2,0,0)(1,0,0)[12] with non-zero mean : 271.6811\n ARIMA(2,0,0)            with non-zero mean : 272.1458\n ARIMA(2,0,0)(1,0,1)[12] with non-zero mean : 273.7323\n ARIMA(2,0,0)(0,0,1)[12] with non-zero mean : 272.8549\n ARIMA(3,0,0)(1,0,0)[12] with non-zero mean : 274.4922\n ARIMA(3,0,1)(1,0,0)[12] with non-zero mean : 277.4715\n ARIMA(2,0,0)(1,0,0)[12] with zero mean     : 269.4654\n ARIMA(2,0,0)            with zero mean     : 270.5103\n ARIMA(2,0,0)(1,0,1)[12] with zero mean     : 271.365\n ARIMA(2,0,0)(0,0,1)[12] with zero mean     : 270.7772\n ARIMA(1,0,0)(1,0,0)[12] with zero mean     : 282.7531\n ARIMA(3,0,0)(1,0,0)[12] with zero mean     : 272.0724\n ARIMA(2,0,1)(1,0,0)[12] with zero mean     : 272.0509\n ARIMA(1,0,1)(1,0,0)[12] with zero mean     : 275.1242\n ARIMA(3,0,1)(1,0,0)[12] with zero mean     : 274.8562\n\n Best model: ARIMA(2,0,0)(1,0,0)[12] with zero mean     \n\n\n\n\n\nSau khi đã xây dựng mô hình, ta sẽ dùng nó để dự đoán và so sánh với dữ liệu thực tế từ bộ dữ liệu testing data.\n\n\nCode\n#Forecast by training model:\ntraining_forecast&lt;-forecast(model,h = 21)\n\n\nBảng trình bày các giá trị dự đoán theo từng tháng. Ta thấy chỉ có 4/21 thời điểm mà giá trị thực tế vượt ra giá trị dự đoán trong khoảng tin cậy 80%. Còn đối với giá trị dự đoán trong khoảng tin cậy 95% thì đều đạt yêu cầu.\n\n\nCode\n#Calculate RMSE:\nactual&lt;- diff(demand_testing,1)\n\naccuracy&lt;-data_frame(Period = paste(month(testing_df$datetime),\n                                    year(testing_df$datetime),\n                                    sep = \"/\")[-1],\n                     Actual = actual %&gt;% as.vector(), \n                     High.80 = training_forecast$upper[,1],\n                     Low.80 = training_forecast$lower[,1],\n                     High.95 = training_forecast$upper[,2],\n                     Low.95 = training_forecast$lower[,2]) %&gt;% \n  mutate(Check.80 = ifelse(Actual &lt;= High.80 & Actual &gt;= Low.80,\"Pass\",\"Fail\"),\n         Check.95 = ifelse(Actual &lt;= High.95 & Actual &gt;= Low.95,\"Pass\",\"Fail\"))\n\n## Finally plot the result\ngt(accuracy) %&gt;% \n   tab_header(\n    title = md(\"**Comparing the accuracy of forecasting**\"),\n    subtitle = glue::glue(\"Forecasting from {min(testing_df$datetime)} to {max(testing_df$datetime)}\")) %&gt;%\n   tab_source_note(\n    source_note = str_glue(\"Method: Model {training_forecast$method}\")) %&gt;% \n  gt_theme_538() %&gt;% \n   data_color(\n    columns = Check.80,\n    method = \"factor\",\n    palette = c(\"red\",\"darkgreen\")\n  ) %&gt;% data_color(\n    columns = Check.95,\n    method = \"factor\",\n    palette = c(\"darkgreen\",\"red\")\n  ) \n\n\n\n\n\n\n  \n    \n      Comparing the accuracy of forecasting\n\n    \n    \n      Forecasting from 2015-03-01 to 2016-12-01\n    \n    \n      Period\n      Actual\n      High.80\n      Low.80\n      High.95\n      Low.95\n      Check.80\n      Check.95\n    \n  \n  \n    4/2015\n-11.157\n8.2151971\n-10.812921\n13.251636\n-15.84936\nFail\nPass\n    5/2015\n-12.621\n1.6260371\n-20.888910\n7.585384\n-26.84826\nPass\nPass\n    6/2015\n13.813\n18.5336717\n-4.315841\n24.581572\n-10.36374\nPass\nPass\n    7/2015\n8.293\n14.9318430\n-9.908314\n21.506636\n-16.48311\nPass\nPass\n    8/2015\n-20.715\n-0.7494574\n-25.879586\n5.902086\n-32.53113\nPass\nPass\n    9/2015\n4.671\n21.7271249\n-3.643527\n28.442331\n-10.35873\nPass\nPass\n    10/2015\n1.452\n17.1916812\n-8.576132\n24.012009\n-15.39646\nPass\nPass\n    11/2015\n-8.055\n8.5209607\n-17.257552\n15.344121\n-24.08071\nPass\nPass\n    12/2015\n8.132\n14.8015863\n-11.075451\n21.650824\n-17.92469\nPass\nPass\n    1/2016\n-9.978\n17.8052582\n-8.139698\n24.672473\n-15.00691\nFail\nPass\n    2/2016\n-4.696\n6.4211445\n-19.524421\n13.288521\n-26.39180\nPass\nPass\n    3/2016\n19.274\n19.2007071\n-6.774814\n26.076012\n-13.65012\nFail\nPass\n    4/2016\n-14.336\n13.5655001\n-13.694775\n20.780859\n-20.91013\nFail\nPass\n    5/2016\n0.513\n9.7760700\n-17.849339\n17.088074\n-25.16134\nPass\nPass\n    6/2016\n2.751\n16.5398455\n-11.170685\n23.874380\n-18.50522\nPass\nPass\n    7/2016\n6.377\n15.2198557\n-12.789469\n22.633476\n-20.20309\nPass\nPass\n    8/2016\n-8.324\n8.6649731\n-19.373047\n16.086189\n-26.79426\nPass\nPass\n    9/2016\n-2.439\n17.5484745\n-10.538978\n24.982774\n-17.97328\nPass\nPass\n    10/2016\n6.244\n15.8818767\n-12.264517\n23.331777\n-19.71442\nPass\nPass\n    11/2016\n5.996\n12.3351533\n-15.811609\n19.785151\n-23.26161\nPass\nPass\n    12/2016\n-9.544\n14.7681518\n-13.396724\n22.222944\n-20.85152\nPass\nPass\n  \n  \n    \n      Method: Model ARIMA(2,0,0)(1,0,0)[12] with zero mean\n    \n  \n  \n\n\n\n\nVà dưới đây là biểu đồ hiển thị giá trị trung bình (đường màu xanh dương), giá trị dự đoán trong khoảng tin cậy 80% (đường màu xám đậm) và khoảng tin cậy 95% (đường màu xám nhạt).\nNgoài ra ta cũng tính các chỉ số MAE và RMSE của mô hình như sau:\n\n\nCode\n## Calculating MAE metric:\nsum = 0\nfor (i in 1:nrow(accuracy)){ \n  sum = abs(accuracy$Actual[i]-training_forecast$mean[i]) + sum\n} \n\nMAE = sum/nrow(accuracy) \n\n## Calculating RMSE metric:\nRMSE= sqrt(mean((accuracy$Actual - training_forecast$mean)^2))\n\n\n\n\nCode\n#Use chart for presenting the differents:\nplot(training_forecast,\n      main = str_glue(\"Method: Model {training_forecast$method}\"),\n      xlab = \"Time\",\n      ylab = \"Order Demand\")\nlines(actual, \n      col = \"red\",\n      lwd = \"2\")\nlegend(\"topleft\",\n       legend = c(\"Actual\",\"Forecast\"),\n       col = c(\"red\",\"blue\"),\n       box.lty = 0,\n       lty = 1,\n       cex = 1,\n       lwd = 2)\n\n\n\n\n\nTa thấy kết quả dự đoán cũng ổn nhưng vẫn chưa bám sát thực tế. Vì vậy tiếp theo chúng ta sẽ làm cho mô hình tốt hơn ở trang sau Mô hình SARIMA"
  },
  {
    "objectID": "Forecasting.html#phân-tích-thành-phần-trong-time-series-dữ-liệu",
    "href": "Forecasting.html#phân-tích-thành-phần-trong-time-series-dữ-liệu",
    "title": "Mô hình ARIMA",
    "section": "",
    "text": "Về thông tin của dữ liệu, đây là dữ liệu thuộc dạng time-series nghĩa là chuỗi dữ liệu theo thời gian nên nó sẽ có các đặt tính chung như:\n\nTrend: Tăng, giảm dài hạn hoặc chuyển động đứng yên.\nSeasonal: Các mô hình có thể dự đoán được ở những khoảng thời gian cố định.\nCycle: Biến động không có chu kỳ nhất quán.\nNoise: Sai số còn sót lại không giải thích được.\n\nVậy mục tiêu của việc phân tích time series là để tìm ra thành phần seasonal trong vì nó có tính lặp lại và có thể dùng để dự đoán cho tương lai. Ngoài ra, thành phần trend cũng cần được quan tâm vì nó thể hiện xu hướng của dữ liệu trong tương lai.\nTrong R, ta có thể phân tích dễ dàng với hàm decompose() như code dưới đây.\nVề công thức tính, hàm decompose() dựa vào kĩ thuật Moving Averages để tính trung bình giá trị theo 1 khoảng thời gian (Vd: 3 tháng 6 tháng hoặc 1 năm).\n\n\n\nHình 3: Additive and multiplicative model\n\n\nCó 2 mô hình gồm Additive và Multiplicative có thể sử dụng. Ở mặc định, hàm decompose() tính theo mô hình Additive, còn bạn muốn tính theo mô hình Multiplicative thì phải thêm đối số type = \"multiplicative\".\n\n\nCode\nlibrary(TSstudio)\nts_decompose(demand_training, \n             type = \"both\")\n\n\n\n\nKhi mức độ biến động của seasonal hoặc sự biến đổi xung quanh trend-cycle không thay đổi theo mức độ của chuỗi thời gian, mô hình Additive sẽ phù hợp hơn mô hình Multiplicative.\n\n\nNhìn sơ bộ, ta có thể thấy xu hướng tăng (trend) của số lượng đơn đặt hàng. Về phần random thì sẽ có 1 khoảng từ (-10,5) số đơn là tự nhiên xảy ra, nghĩa là giá trị dự đoán có thể lệch từ -10 đến 5 đơn hàng và sai lệch này là do tự nhiên."
  },
  {
    "objectID": "Forecasting.html#dự-đoán-bằng-mô-hình-arima",
    "href": "Forecasting.html#dự-đoán-bằng-mô-hình-arima",
    "title": "Mô hình ARIMA",
    "section": "",
    "text": "Trên thực tế, phần phân tích thành các thành phần của time series chỉ đưa ra dự đoán định tính, không thể dự đoán bằng các dữ liệu trên mà phải cần thông qua mô hình cụ thể. Dưới đây là giới thiệu về mô hình ARIMA.\n\n\nTheo (phamdinhkhanh 2019), Mô hình ARIMA “sử dụng đầu vào chính là những tín hiệu quá khứ của chuỗi được dự báo để dự báo nó. Các tín hiệu đó bao gồm: Chuỗi tự hồi qui AR (auto regression) và chuỗi trung bình trượt MA (moving average).\nHầu hết các chuỗi thời gian sẽ có xu hướng tăng hoặc giảm theo thời gian, do đó yếu tố chuỗi dừng thường không đạt được. Trong trường hợp chuỗi không dừng thì ta sẽ cần biến đổi sang chuỗi dừng bằng sai phân. Khi đó tham số đặc trưng của mô hình sẽ có thêm thành phần bậc của sai phân d và mô hình được đặc tả bởi 3 tham số ARIMA(p, d, q)“.\nMô hình được xây dựng “dựa trên giả thuyết: Stationary series (Chuỗi dừng) đòi hỏi Phương sai sai số không đổi và Nhiễu trắng (White noise), cụ thể trong đó:\n\nStationary series: điều kiện là trung bình của chuỗi là constant (bất biến), phương sai (variance) của chuỗi phải có tính đồng nhất (homoscedasticity) và hiệp phương sai (covariance) giữa giá trị t và t+1 phải không liên quan tới nhau.\n\n\n\n\n\n\nLưu ý\n\n\n\nNếu chuỗi dữ liệu không phải là chuỗi dùng thì bạn sẽ không xây dựng được mô hình chuỗi thời gian (time-series model)\n\n\nNhiễu trắng là: một thành phần ngẫu nhiên thể hiện cho yếu tố không thể dự báo của model và không có tính qui luật.\n\n\n\n\nHình 4: Stationary and non-stationary series\n\n\n\n\n\n\n\nVà để thỏa mãn giả định này, cần tính toán các chỉ số trên và đánh giá và điều này khá phức tạp. Trong R, ta có hàm adf.test() có thể kiểm tra vấn đề này nhanh hơn.\n\n\nCode\nlibrary(tseries)\nadf.test(demand_training)    ## p-value = 0.3779 &gt; 0.05 means this series is not stationary\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  demand_training\nDickey-Fuller = -2.4991, Lag order = 3, p-value = 0.3779\nalternative hypothesis: stationary\n\n\nNhư vậy, ta thấy chuỗi dữ liệu này không phải chuỗi dừng vì giá trị p = 0.3779 &gt; 0.05 nghĩa là chấp nhận giả thuyết H0: Chuỗi này là chuỗi không dừng.\nTrong time-series analyst, ta sẽ có cách để xử lí chuỗi thành chuỗi dừng. Đó là tính sự khác nhau (Difference) giữa giá trị t và giá trị của nó ở quá khứ t-1,t-2,…\nTrong R, bạn có thể tính bằng cách:\n\ndiff(series, lag = n): tính sự khác nhau giữa các thời điểm t và t-n.\nlog(series): chuyển time-series sang dạng log.\n\nNày tùy thuộc vào công thức toán học bạn muốn định nghĩa, miễn sao bạn có thể xác định được chuỗi dừng là đạt.\n\n\nCode\n#First we will calculate the different in demand product monthly:\n#Check stationary assumption:\ntest&lt;-lapply(1:3, function(x) {\n         a&lt;-diff(demand_training, lag = x)\n         adf.test(a)$p.value}\n       ) #p&lt;0,05 is accepted\n\n## Second transform it to dataframe object:\ntest&lt;-data.frame(test)\ncolnames(test)&lt;-c(\"Lag 1\",\"Lag 2\",\"Lag 3\")\n\n## Finally plot the result:\nlibrary(gt)\nlibrary(gtExtras)\ngt(test) %&gt;% \n  cols_align(\n    align = \"left\",\n    columns = \"Lag 1\"\n  ) %&gt;% \n  cols_align(\n    align = \"center\",\n    columns = \"Lag 2\"\n  ) %&gt;%\n   tab_header(\n    title = md(\"**Checking stationary assumption**\"),\n    subtitle = glue::glue(\"Time from {min(month_df$datetime)} to 01-03-2015\")) %&gt;%\n   tab_source_note(\n    source_note = \"Alternative hypothesis: stationary\") %&gt;% \n  gt_theme_538()\n\n\n\n\n\n\n  \n    \n      Checking stationary assumption\n\n    \n    \n      Time from 2012-01-01 to 01-03-2015\n    \n    \n      Lag 1\n      Lag 2\n      Lag 3\n    \n  \n  \n    0.01\n0.01\n0.152641\n  \n  \n    \n      Alternative hypothesis: stationary\n    \n  \n  \n\n\n\n\nKết quả testing cho thấy chỉ có chuỗi 1 và 2 đạt yêu cầu, chuỗi 3 không phải chuỗi dừng vì p-value = 0.107 &gt; 0.05.\n\n\n\n\n\nPACF (Partial Autocorrelation Function) và ACF (Autocorrelation Function) là 2 công thức tính thuộc Autocorrelation Analyst - 1 bước quan trọng trong việc phân tích chuỗi dữ liệu thời gian. Mục tiêu của Autocorrelation analyst là tìm ra các mẫu (pattern) giữa nhiều chuỗi thời gian và kiểm tra tính ngẫu nhiên.\n\n\n\nSau khi đã xác định được chuỗi dừng, bước tiếp theo là xác định các tham số (p, d, q) cho mô hình ARIMA.\nTrong R có hàm ggtsdisplay của package forecast sẽ hiển thị cả ACF, PACF và Time series plot của đối tượng mà bạn gán. Còn nếu bạn muốn hiển thị riêng giá trị ACF hoặc PACF thì dùng hàm Acf hoặc Pacf để tính và dùng hàm autoplot() để hiển thị biểu đồ.\n\n\nCode\n#Rename of two time series:\nts1&lt;-diff(demand_training, lag = 1)\nts2&lt;-diff(demand_training, lag = 2)\n#Plot value ACF for 2 series:\nlibrary(forecast)\nggtsdisplay(ts1,\n            main = \"Time series lag 1\",\n            theme=theme_bw())\nggtsdisplay(ts2,\n            main = \"Time series lag 2\",\n            theme=theme_bw())\n\n\n\n\n\n\n\n\n\n\n\n\nDựa vào tricks từ (Tavish Srivastava 2023), ta sẽ dựa vào giá trị PACF để xác định bậc của AR và ACF để xác định bậc của MA.\nVí dụ ở trên, đối với chuỗi lag 1, giá trị PACF có sự đứt gãy (cut off) ở bậc 2 đến bậc 3 nên có thể thuộc AR(3). Còn giá trị ACF thì có thể thuộc MA(2) hoặc rõ ràng hơn là MA(3). Còn lại, đối với chuỗi lag 2, các bạn có thể làm tương tự.\nVậy mô hình tự chọn cuối cùng là ARIMA(3,0,2).\n\n\n\n\nThực tế, trong R có hàm auto.arimađể chúng ta lựa chọn và so sánh nhiều mô hình ARIMA một cách tự động và không nặng về code như dưới đây. Nó sẽ tự liệt kê ra các mô hình phù hợp và chọn ra mô hình tốt nhất.\nNgoài ra, nếu bạn muốn tìm hiểu sâu về cách xây dựng mô hình ARIMA, bạn có thể tham khảo thêm bài blog (Dũng, n.d.). Anh Chí Dũng có khá nhiều bài viết hay về cách sử dụng R trong nghiên cứu và phân tích kinh tế, bạn có thể tham khảo trang blog của ảnh thông qua đường link chidungkt.\n\n\nCode\n#Select the best model:\nmodel&lt;-auto.arima(ts1,trace = T)\n\n\n\n ARIMA(2,0,2)(1,0,1)[12] with non-zero mean : 279.6301\n ARIMA(0,0,0)            with non-zero mean : 291.5234\n ARIMA(1,0,0)(1,0,0)[12] with non-zero mean : 285.1005\n ARIMA(0,0,1)(0,0,1)[12] with non-zero mean : Inf\n ARIMA(0,0,0)            with zero mean     : 289.5102\n ARIMA(2,0,2)(0,0,1)[12] with non-zero mean : 278.2485\n ARIMA(2,0,2)            with non-zero mean : 276.6431\n ARIMA(2,0,2)(1,0,0)[12] with non-zero mean : 277.2391\n ARIMA(1,0,2)            with non-zero mean : Inf\n ARIMA(2,0,1)            with non-zero mean : 274.6588\n ARIMA(2,0,1)(1,0,0)[12] with non-zero mean : 274.4807\n ARIMA(2,0,1)(1,0,1)[12] with non-zero mean : 276.6914\n ARIMA(2,0,1)(0,0,1)[12] with non-zero mean : 275.6882\n ARIMA(1,0,1)(1,0,0)[12] with non-zero mean : Inf\n ARIMA(2,0,0)(1,0,0)[12] with non-zero mean : 271.6811\n ARIMA(2,0,0)            with non-zero mean : 272.1458\n ARIMA(2,0,0)(1,0,1)[12] with non-zero mean : 273.7323\n ARIMA(2,0,0)(0,0,1)[12] with non-zero mean : 272.8549\n ARIMA(3,0,0)(1,0,0)[12] with non-zero mean : 274.4922\n ARIMA(3,0,1)(1,0,0)[12] with non-zero mean : 277.4715\n ARIMA(2,0,0)(1,0,0)[12] with zero mean     : 269.4654\n ARIMA(2,0,0)            with zero mean     : 270.5103\n ARIMA(2,0,0)(1,0,1)[12] with zero mean     : 271.365\n ARIMA(2,0,0)(0,0,1)[12] with zero mean     : 270.7772\n ARIMA(1,0,0)(1,0,0)[12] with zero mean     : 282.7531\n ARIMA(3,0,0)(1,0,0)[12] with zero mean     : 272.0724\n ARIMA(2,0,1)(1,0,0)[12] with zero mean     : 272.0509\n ARIMA(1,0,1)(1,0,0)[12] with zero mean     : 275.1242\n ARIMA(3,0,1)(1,0,0)[12] with zero mean     : 274.8562\n\n Best model: ARIMA(2,0,0)(1,0,0)[12] with zero mean     \n\n\n\n\n\nSau khi đã xây dựng mô hình, ta sẽ dùng nó để dự đoán và so sánh với dữ liệu thực tế từ bộ dữ liệu testing data.\n\n\nCode\n#Forecast by training model:\ntraining_forecast&lt;-forecast(model,h = 21)\n\n\nBảng trình bày các giá trị dự đoán theo từng tháng. Ta thấy chỉ có 4/21 thời điểm mà giá trị thực tế vượt ra giá trị dự đoán trong khoảng tin cậy 80%. Còn đối với giá trị dự đoán trong khoảng tin cậy 95% thì đều đạt yêu cầu.\n\n\nCode\n#Calculate RMSE:\nactual&lt;- diff(demand_testing,1)\n\naccuracy&lt;-data_frame(Period = paste(month(testing_df$datetime),\n                                    year(testing_df$datetime),\n                                    sep = \"/\")[-1],\n                     Actual = actual %&gt;% as.vector(), \n                     High.80 = training_forecast$upper[,1],\n                     Low.80 = training_forecast$lower[,1],\n                     High.95 = training_forecast$upper[,2],\n                     Low.95 = training_forecast$lower[,2]) %&gt;% \n  mutate(Check.80 = ifelse(Actual &lt;= High.80 & Actual &gt;= Low.80,\"Pass\",\"Fail\"),\n         Check.95 = ifelse(Actual &lt;= High.95 & Actual &gt;= Low.95,\"Pass\",\"Fail\"))\n\n## Finally plot the result\ngt(accuracy) %&gt;% \n   tab_header(\n    title = md(\"**Comparing the accuracy of forecasting**\"),\n    subtitle = glue::glue(\"Forecasting from {min(testing_df$datetime)} to {max(testing_df$datetime)}\")) %&gt;%\n   tab_source_note(\n    source_note = str_glue(\"Method: Model {training_forecast$method}\")) %&gt;% \n  gt_theme_538() %&gt;% \n   data_color(\n    columns = Check.80,\n    method = \"factor\",\n    palette = c(\"red\",\"darkgreen\")\n  ) %&gt;% data_color(\n    columns = Check.95,\n    method = \"factor\",\n    palette = c(\"darkgreen\",\"red\")\n  ) \n\n\n\n\n\n\n  \n    \n      Comparing the accuracy of forecasting\n\n    \n    \n      Forecasting from 2015-03-01 to 2016-12-01\n    \n    \n      Period\n      Actual\n      High.80\n      Low.80\n      High.95\n      Low.95\n      Check.80\n      Check.95\n    \n  \n  \n    4/2015\n-11.157\n8.2151971\n-10.812921\n13.251636\n-15.84936\nFail\nPass\n    5/2015\n-12.621\n1.6260371\n-20.888910\n7.585384\n-26.84826\nPass\nPass\n    6/2015\n13.813\n18.5336717\n-4.315841\n24.581572\n-10.36374\nPass\nPass\n    7/2015\n8.293\n14.9318430\n-9.908314\n21.506636\n-16.48311\nPass\nPass\n    8/2015\n-20.715\n-0.7494574\n-25.879586\n5.902086\n-32.53113\nPass\nPass\n    9/2015\n4.671\n21.7271249\n-3.643527\n28.442331\n-10.35873\nPass\nPass\n    10/2015\n1.452\n17.1916812\n-8.576132\n24.012009\n-15.39646\nPass\nPass\n    11/2015\n-8.055\n8.5209607\n-17.257552\n15.344121\n-24.08071\nPass\nPass\n    12/2015\n8.132\n14.8015863\n-11.075451\n21.650824\n-17.92469\nPass\nPass\n    1/2016\n-9.978\n17.8052582\n-8.139698\n24.672473\n-15.00691\nFail\nPass\n    2/2016\n-4.696\n6.4211445\n-19.524421\n13.288521\n-26.39180\nPass\nPass\n    3/2016\n19.274\n19.2007071\n-6.774814\n26.076012\n-13.65012\nFail\nPass\n    4/2016\n-14.336\n13.5655001\n-13.694775\n20.780859\n-20.91013\nFail\nPass\n    5/2016\n0.513\n9.7760700\n-17.849339\n17.088074\n-25.16134\nPass\nPass\n    6/2016\n2.751\n16.5398455\n-11.170685\n23.874380\n-18.50522\nPass\nPass\n    7/2016\n6.377\n15.2198557\n-12.789469\n22.633476\n-20.20309\nPass\nPass\n    8/2016\n-8.324\n8.6649731\n-19.373047\n16.086189\n-26.79426\nPass\nPass\n    9/2016\n-2.439\n17.5484745\n-10.538978\n24.982774\n-17.97328\nPass\nPass\n    10/2016\n6.244\n15.8818767\n-12.264517\n23.331777\n-19.71442\nPass\nPass\n    11/2016\n5.996\n12.3351533\n-15.811609\n19.785151\n-23.26161\nPass\nPass\n    12/2016\n-9.544\n14.7681518\n-13.396724\n22.222944\n-20.85152\nPass\nPass\n  \n  \n    \n      Method: Model ARIMA(2,0,0)(1,0,0)[12] with zero mean\n    \n  \n  \n\n\n\n\nVà dưới đây là biểu đồ hiển thị giá trị trung bình (đường màu xanh dương), giá trị dự đoán trong khoảng tin cậy 80% (đường màu xám đậm) và khoảng tin cậy 95% (đường màu xám nhạt).\nNgoài ra ta cũng tính các chỉ số MAE và RMSE của mô hình như sau:\n\n\nCode\n## Calculating MAE metric:\nsum = 0\nfor (i in 1:nrow(accuracy)){ \n  sum = abs(accuracy$Actual[i]-training_forecast$mean[i]) + sum\n} \n\nMAE = sum/nrow(accuracy) \n\n## Calculating RMSE metric:\nRMSE= sqrt(mean((accuracy$Actual - training_forecast$mean)^2))\n\n\n\n\nCode\n#Use chart for presenting the differents:\nplot(training_forecast,\n      main = str_glue(\"Method: Model {training_forecast$method}\"),\n      xlab = \"Time\",\n      ylab = \"Order Demand\")\nlines(actual, \n      col = \"red\",\n      lwd = \"2\")\nlegend(\"topleft\",\n       legend = c(\"Actual\",\"Forecast\"),\n       col = c(\"red\",\"blue\"),\n       box.lty = 0,\n       lty = 1,\n       cex = 1,\n       lwd = 2)\n\n\n\n\n\nTa thấy kết quả dự đoán cũng ổn nhưng vẫn chưa bám sát thực tế. Vì vậy tiếp theo chúng ta sẽ làm cho mô hình tốt hơn ở trang sau Mô hình SARIMA"
  }
]