[
  {
    "objectID": "projects.html#project-2",
    "href": "projects.html#project-2",
    "title": "Projects",
    "section": "Project 2",
    "text": "Project 2"
  },
  {
    "objectID": "projects.html#project-3",
    "href": "projects.html#project-3",
    "title": "Projects",
    "section": "Project 3",
    "text": "Project 3"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cao Xu√¢n L·ªôc",
    "section": "",
    "text": "Xin ch√†o, m√¨nh l√† L·ªôc, sinh nƒÉm 2003 v√† l√† m·ªôt ch√†ng trai ƒë·∫øn t·ª´ m·∫£nh ƒë·∫•t ƒë·∫ßy n·∫Øng v√† gi√≥ - Ph√∫ Y√™n, Vi·ªát Nam. M√¨nh c√≥ b·∫±ng c·ª≠ nh√¢n tr∆∞·ªùng ƒê·∫°i h·ªçc Kinh T·∫ø - T√†i Ch√≠nh (UEF) v√† chuy√™n ng√†nh c·ªßa m√¨nh l√† Logistics v√† qu·∫£n l√Ω chu·ªói cung ·ª©ng.\nL√† ng∆∞·ªùi c√≥ ni·ªÅm ƒëam m√™ m·∫°nh m·∫Ω v·ªõi R, m√¨nh c√≥ s·ªü th√≠ch vi·∫øt post v·ªÅ vi·ªác ph√¢n t√≠ch d·ªØ li·ªáu v·ªõi R ƒë·ªÉ ·ª©ng d·ª•ng v√†o c√°c c√¥ng vi·ªác, b√†i to√°n th∆∞·ªùng g·∫∑p trong Supply Chain. Ngo√†i ra, s·ªü th√≠ch c·ªßa m√¨nh l√† nghe s√°ch n√≥i v√† ƒëi b·ªô!\nC√¢u slogan m√† m√¨nh th√≠ch nh·∫•t l√†: ‚ÄúDon‚Äôt fear the risk, fear the opportunity lost!‚Äù v√† ƒë√≥ c≈©ng l√† c√°ch m√¨nh s·ªëng ƒë·∫øn b√¢y gi·ªù. V√† m√¨nh c≈©ng mu·ªën truy·ªÅn ƒë·ªông l·ª±c ƒë√≥ ƒë·∫øn t·∫•t c·∫£ c√°c b·∫°n üíùüíùüíù.\nHi v·ªçng c√°c b·∫°n s·∫Ω th√≠ch b√†i vi·∫øt c·ªßa m√¨nh!"
  },
  {
    "objectID": "EnsembleML.html",
    "href": "EnsembleML.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Theo (Topdev, n.d.), Machine learning (ML) hay m√°y h·ªçc l√† ‚Äúm·ªôt nh√°nh c·ªßa tr√≠ tu·ªá nh√¢n t·∫°o (AI), n√≥ l√† m·ªôt lƒ©nh v·ª±c nghi√™n c·ª©u cho ph√©p m√°y t√≠nh c√≥ kh·∫£ nƒÉng c·∫£i thi·ªán ch√≠nh b·∫£n th√¢n ch√∫ng d·ª±a tr√™n d·ªØ li·ªáu m·∫´u (training data) ho·∫∑c d·ª±a v√†o kinh nghi·ªám (nh·ªØng g√¨ ƒë√£ ƒë∆∞·ª£c h·ªçc). Machine learning c√≥ th·ªÉ t·ª± d·ª± ƒëo√°n ho·∫∑c ƒë∆∞a ra quy·∫øt ƒë·ªãnh m√† kh√¥ng c·∫ßn ƒë∆∞·ª£c l·∫≠p tr√¨nh c·ª• th·ªÉ.‚Äù\nPh∆∞∆°ng ph√°p Machine Learning t·ª´ng ‚Äúg√¢y b√£o‚Äù trong gi·ªõi khoa h·ªçc khi ra m·∫Øt v√¨ kh·∫£ nƒÉng x√¢y d·ª±ng m√¥ h√¨nh nhanh ch√≥ng v√† s·ª± chu·∫©n x√°c c·ªßa m√¥ h√¨nh trong vi·ªác d·ª± ƒëo√°n v√† ph√¢n lo·∫°i k·∫øt qu·∫£. V·ªõi s·ª± ph√°t tri·ªÉn c·ªßa khoa h·ªçc, l∆∞·ª£ng l·ªõn d·ªØ li·ªáu ƒë∆∞·ª£c thu th·∫≠p hay ƒë∆∞·ª£c g·ªçi l√† Big Data ƒë√≤i h·ªèi nhu c·∫ßu t√≠nh to√°n nhanh ch√≥ng v√† c√¥ng c·ª• m·∫°nh. C√°c ph∆∞∆°ng ph√°p khoa h·ªçc truy·ªÅn th·ªëng l·∫°i kh√¥ng l√†m t·ªët vi·ªác n√†y b·∫±ng Machine Learning.\nNgo√†i ra, kh√°c v·ªõi c√°c m√¥ h√¨nh truy·ªÅn th·ªëng ƒë√≤i h·ªèi nhi·ªÅu v·ªÅ ƒë√°p ·ª©ng gi·∫£ ƒë·ªãnh v√† quy t·∫Øc r·∫Øc r·ªëi, Machine Learning gi√∫p con ng∆∞·ªùi nhanh ch√≥ng ƒë∆∞a ra quy·∫øt ƒë·ªãnh v√† c√≥ th·ªÉ t·ª± c·∫£i thi·ªán performance c·ªßa m√¨nh b·∫±ng h·ªçc m√°y m√† kh√¥ng c·∫ßn ng∆∞·ªùi d√πng ph·∫£i t∆∞∆°ng t√°c nhi·ªÅu.\n\n\n\nTrong machine learning t·ªìn t·∫°i ƒë·ªãnh l√Ω ‚Äúkh√¥ng c√≥ b·ªØa tr∆∞a mi·ªÖn ph√≠‚Äù (No free lunch theorem), t·ª©c l√† kh√¥ng t·ªìn t·∫°i m·ªôt thu·∫≠t to√°n m√† t√¥ÃÅt cho m·ªçi ·ª©ng d·ª•ng v√† m·ªçi t·∫≠p d·ªØ li·ªáu. V√¨ ML c√≥ nhi·ªÅu thu·∫≠t to√°n kh√°c nhau v√† t√πy v√†o ƒë·∫∑c t√≠nh c·ªßa b·ªô d·ªØ li·ªáu m√† thu·∫≠t to√°n ML s·∫Ω t√≠nh ra k·∫øt qu·∫£ kh√°c nhau. Mu·ªën t√¨m ra thu·∫≠t to√°n ph√π h·ª£p, ng∆∞·ªùi s·ª≠ d·ª•ng ph·∫£i c·∫ßn nhi·ªÅu th·ªùi gian ƒë·ªÉ test v√† ƒëi·ªÅu ch·ªânh h·ªá s·ªë (tuning hyperparameters) ƒë·ªÉ ƒë·∫°t ƒë·ªô ch√≠nh x√°c cao.\nV√† thu·∫≠t to√°n Ensemble ML c√≥ th·ªÉ gi√∫p ng∆∞·ªùi d√πng gi·∫£m th·ªùi gian trong vi·ªác testing b·∫±ng c√°ch k·∫øt h·ª£p c√°c m√¥ h√¨nh n√†y v·ªõi nhau. Theo (Cuong Sai 2020),‚Äú√ù t∆∞·ªüng c·ªßa vi·ªác combine c√°c m√¥ hiÃÄnh khaÃÅc nhau xu·∫•t ph√°t t·ª´ m·ªôt suy nghƒ© h·ª£p l√Ω l√†: caÃÅc m√¥ hiÃÄnh kh√°c nhau c√≥ kh·∫£ nƒÉng kh√°c nhau, c√≥ th·ªÉ th·ª±c hi·ªán t·ªët nh·∫•t c√°c lo·∫°i c√¥ng vi·ªác kh√°c nhau (subtasks), khi k·∫øt h·ª£p c√°c m√¥ hiÃÄnh n√†y v·ªõi nhau m·ªôt c√°ch h·ª£p l√Ω th√¨ s·∫Ω t·∫°o th√†nh m·ªôt m√¥ hiÃÄnh k√™ÃÅt h∆°Ã£p (combined model) m·∫°nh c√≥ kh·∫£ nƒÉng c·∫£i thi·ªán hi·ªáu su√¢t t·ªïng th·ªÉ (overall performance) so v·ªõi vi·ªác ch·ªâ d√πng c√°c m√¥ hiÃÄnh m·ªôt c√°ch ƒë∆°n l·∫ª.‚Äù\nThu·∫≠t to√°n Ensemble ML chia th√†nh 3 lo·∫°i:\n\nBagging: chia b·ªô d·ªØ li·ªáu th√†nh subsamples v√† x√¢y d·ª±ng th√†nh model c√πng ki·ªÉu v·ªõi nhau ƒë·ªÉ ƒë∆∞a ra d·ª± ƒëo√°n.\nBoosting: c≈©ng chia d·ªØ li·ªáu th√†nh subsamples nh∆∞ng vi·ªác x√¢y d·ª±ng m√¥ h√¨nh kh√¥ng di·ªÖn ra c√πng l√∫c nh∆∞ bagging m√† l√† theo chu·ªói n·ªëi ti·∫øp nhau.\n\nB·∫°n c√≥ th·ªÉ t∆∞·ªüng t∆∞·ª£ng nh∆∞ h√¨nh d∆∞·ªõi ƒë√¢y:\n\n\n\nH√¨nh 6: Bagging vs Boosting method.\n\n\n\nStacking x√¢y d·ª±ng c√°c m√¥ h√¨nh kh√°c lo·∫°i t·ª´ training data v√† m·ªôt m√¥ h√¨nh supervisor model. Sau ƒë√≥, m√¥ h√¨nh n√†y s·∫Ω k·∫øt h·ª£p c√°c k·∫øt qu·∫£ d·ª± b√°o ƒë·ªÉ t√¨m ra m√¥ h√¨nh t·ªët nh·∫•t.\n\n\n\n\nH√¨nh 7: Staking method.\n\n\nV·∫≠y ti·∫øp theo, ch√∫ng ta s·∫Ω th·ª≠ d√πng Ensemble ML trong R ƒë·ªÉ d·ª± ƒëo√°n.\n\n\n\nMachine Learning l√†m t·ªët v·ªÅ m·∫∑t performance ·ªü c√°c v·∫•n ƒë·ªÅ nh∆∞: ph√¢n lo·∫°i nh√£n (Classification), t·ª± h·ªçc v√† b·ªï sung (AI), ph√¢n t√≠ch l·ªõp ·∫£nh (Neural network),‚Ä¶ nh∆∞ng ·ªü lƒ©nh v·ª±c d·ª± ƒëo√°n chu·ªói th·ªùi gian (Time series forecast), ML l·∫°i kh√¥ng t·ªët b·∫±ng c√°c ph∆∞∆°ng ph√°p th·ªëng k√™ truy·ªÅn th·ªëng."
  },
  {
    "objectID": "EnsembleML.html#d·ª±-ƒëo√°n-b·∫±ng-machine-learning",
    "href": "EnsembleML.html#d·ª±-ƒëo√°n-b·∫±ng-machine-learning",
    "title": "Machine Learning",
    "section": "",
    "text": "Theo (Topdev, n.d.), Machine learning (ML) hay m√°y h·ªçc l√† ‚Äúm·ªôt nh√°nh c·ªßa tr√≠ tu·ªá nh√¢n t·∫°o (AI), n√≥ l√† m·ªôt lƒ©nh v·ª±c nghi√™n c·ª©u cho ph√©p m√°y t√≠nh c√≥ kh·∫£ nƒÉng c·∫£i thi·ªán ch√≠nh b·∫£n th√¢n ch√∫ng d·ª±a tr√™n d·ªØ li·ªáu m·∫´u (training data) ho·∫∑c d·ª±a v√†o kinh nghi·ªám (nh·ªØng g√¨ ƒë√£ ƒë∆∞·ª£c h·ªçc). Machine learning c√≥ th·ªÉ t·ª± d·ª± ƒëo√°n ho·∫∑c ƒë∆∞a ra quy·∫øt ƒë·ªãnh m√† kh√¥ng c·∫ßn ƒë∆∞·ª£c l·∫≠p tr√¨nh c·ª• th·ªÉ.‚Äù\nPh∆∞∆°ng ph√°p Machine Learning t·ª´ng ‚Äúg√¢y b√£o‚Äù trong gi·ªõi khoa h·ªçc khi ra m·∫Øt v√¨ kh·∫£ nƒÉng x√¢y d·ª±ng m√¥ h√¨nh nhanh ch√≥ng v√† s·ª± chu·∫©n x√°c c·ªßa m√¥ h√¨nh trong vi·ªác d·ª± ƒëo√°n v√† ph√¢n lo·∫°i k·∫øt qu·∫£. V·ªõi s·ª± ph√°t tri·ªÉn c·ªßa khoa h·ªçc, l∆∞·ª£ng l·ªõn d·ªØ li·ªáu ƒë∆∞·ª£c thu th·∫≠p hay ƒë∆∞·ª£c g·ªçi l√† Big Data ƒë√≤i h·ªèi nhu c·∫ßu t√≠nh to√°n nhanh ch√≥ng v√† c√¥ng c·ª• m·∫°nh. C√°c ph∆∞∆°ng ph√°p khoa h·ªçc truy·ªÅn th·ªëng l·∫°i kh√¥ng l√†m t·ªët vi·ªác n√†y b·∫±ng Machine Learning.\nNgo√†i ra, kh√°c v·ªõi c√°c m√¥ h√¨nh truy·ªÅn th·ªëng ƒë√≤i h·ªèi nhi·ªÅu v·ªÅ ƒë√°p ·ª©ng gi·∫£ ƒë·ªãnh v√† quy t·∫Øc r·∫Øc r·ªëi, Machine Learning gi√∫p con ng∆∞·ªùi nhanh ch√≥ng ƒë∆∞a ra quy·∫øt ƒë·ªãnh v√† c√≥ th·ªÉ t·ª± c·∫£i thi·ªán performance c·ªßa m√¨nh b·∫±ng h·ªçc m√°y m√† kh√¥ng c·∫ßn ng∆∞·ªùi d√πng ph·∫£i t∆∞∆°ng t√°c nhi·ªÅu.\n\n\n\nTrong machine learning t·ªìn t·∫°i ƒë·ªãnh l√Ω ‚Äúkh√¥ng c√≥ b·ªØa tr∆∞a mi·ªÖn ph√≠‚Äù (No free lunch theorem), t·ª©c l√† kh√¥ng t·ªìn t·∫°i m·ªôt thu·∫≠t to√°n m√† t√¥ÃÅt cho m·ªçi ·ª©ng d·ª•ng v√† m·ªçi t·∫≠p d·ªØ li·ªáu. V√¨ ML c√≥ nhi·ªÅu thu·∫≠t to√°n kh√°c nhau v√† t√πy v√†o ƒë·∫∑c t√≠nh c·ªßa b·ªô d·ªØ li·ªáu m√† thu·∫≠t to√°n ML s·∫Ω t√≠nh ra k·∫øt qu·∫£ kh√°c nhau. Mu·ªën t√¨m ra thu·∫≠t to√°n ph√π h·ª£p, ng∆∞·ªùi s·ª≠ d·ª•ng ph·∫£i c·∫ßn nhi·ªÅu th·ªùi gian ƒë·ªÉ test v√† ƒëi·ªÅu ch·ªânh h·ªá s·ªë (tuning hyperparameters) ƒë·ªÉ ƒë·∫°t ƒë·ªô ch√≠nh x√°c cao.\nV√† thu·∫≠t to√°n Ensemble ML c√≥ th·ªÉ gi√∫p ng∆∞·ªùi d√πng gi·∫£m th·ªùi gian trong vi·ªác testing b·∫±ng c√°ch k·∫øt h·ª£p c√°c m√¥ h√¨nh n√†y v·ªõi nhau. Theo (Cuong Sai 2020),‚Äú√ù t∆∞·ªüng c·ªßa vi·ªác combine c√°c m√¥ hiÃÄnh khaÃÅc nhau xu·∫•t ph√°t t·ª´ m·ªôt suy nghƒ© h·ª£p l√Ω l√†: caÃÅc m√¥ hiÃÄnh kh√°c nhau c√≥ kh·∫£ nƒÉng kh√°c nhau, c√≥ th·ªÉ th·ª±c hi·ªán t·ªët nh·∫•t c√°c lo·∫°i c√¥ng vi·ªác kh√°c nhau (subtasks), khi k·∫øt h·ª£p c√°c m√¥ hiÃÄnh n√†y v·ªõi nhau m·ªôt c√°ch h·ª£p l√Ω th√¨ s·∫Ω t·∫°o th√†nh m·ªôt m√¥ hiÃÄnh k√™ÃÅt h∆°Ã£p (combined model) m·∫°nh c√≥ kh·∫£ nƒÉng c·∫£i thi·ªán hi·ªáu su√¢t t·ªïng th·ªÉ (overall performance) so v·ªõi vi·ªác ch·ªâ d√πng c√°c m√¥ hiÃÄnh m·ªôt c√°ch ƒë∆°n l·∫ª.‚Äù\nThu·∫≠t to√°n Ensemble ML chia th√†nh 3 lo·∫°i:\n\nBagging: chia b·ªô d·ªØ li·ªáu th√†nh subsamples v√† x√¢y d·ª±ng th√†nh model c√πng ki·ªÉu v·ªõi nhau ƒë·ªÉ ƒë∆∞a ra d·ª± ƒëo√°n.\nBoosting: c≈©ng chia d·ªØ li·ªáu th√†nh subsamples nh∆∞ng vi·ªác x√¢y d·ª±ng m√¥ h√¨nh kh√¥ng di·ªÖn ra c√πng l√∫c nh∆∞ bagging m√† l√† theo chu·ªói n·ªëi ti·∫øp nhau.\n\nB·∫°n c√≥ th·ªÉ t∆∞·ªüng t∆∞·ª£ng nh∆∞ h√¨nh d∆∞·ªõi ƒë√¢y:\n\n\n\nH√¨nh 6: Bagging vs Boosting method.\n\n\n\nStacking x√¢y d·ª±ng c√°c m√¥ h√¨nh kh√°c lo·∫°i t·ª´ training data v√† m·ªôt m√¥ h√¨nh supervisor model. Sau ƒë√≥, m√¥ h√¨nh n√†y s·∫Ω k·∫øt h·ª£p c√°c k·∫øt qu·∫£ d·ª± b√°o ƒë·ªÉ t√¨m ra m√¥ h√¨nh t·ªët nh·∫•t.\n\n\n\n\nH√¨nh 7: Staking method.\n\n\nV·∫≠y ti·∫øp theo, ch√∫ng ta s·∫Ω th·ª≠ d√πng Ensemble ML trong R ƒë·ªÉ d·ª± ƒëo√°n.\n\n\n\nMachine Learning l√†m t·ªët v·ªÅ m·∫∑t performance ·ªü c√°c v·∫•n ƒë·ªÅ nh∆∞: ph√¢n lo·∫°i nh√£n (Classification), t·ª± h·ªçc v√† b·ªï sung (AI), ph√¢n t√≠ch l·ªõp ·∫£nh (Neural network),‚Ä¶ nh∆∞ng ·ªü lƒ©nh v·ª±c d·ª± ƒëo√°n chu·ªói th·ªùi gian (Time series forecast), ML l·∫°i kh√¥ng t·ªët b·∫±ng c√°c ph∆∞∆°ng ph√°p th·ªëng k√™ truy·ªÅn th·ªëng."
  },
  {
    "objectID": "EnsembleML.html#th·ª±c-h√†nh-trong-r",
    "href": "EnsembleML.html#th·ª±c-h√†nh-trong-r",
    "title": "Machine Learning",
    "section": "2 Th·ª±c h√†nh trong R:",
    "text": "2 Th·ª±c h√†nh trong R:\n\n2.1 Chu·∫©n b·ªã d·ªØ li·ªáu:\nB·∫°n c√≥ th·ªÉ quay l·∫°i trang ƒë·∫ßu ti√™n ƒë·ªÉ l·∫•y d·ªØ li·ªáu g·ªëc v√† c√°c b∆∞·ªõc ƒë·ªÉ ch·ªânh s·ª≠a d·ªØ li·ªáu ·ªü Gi·ªõi thi·ªáu.\nTrong ph·∫ßn n√†y, ƒë·ªëi v·ªõi Machine Learning, ta n√™n chia b·ªô d·ªØ li·ªáu th√†nh 3 b·ªô: training, testing v√† forecasting dataset. Ngo√†i ra, ML c·∫ßn d·ªØ li·ªáu l·ªõn n√™n ta s·∫Ω t√≠nh theo tu·∫ßn ch·ª© kh√¥ng theo th√°ng nh∆∞ c√°c ph·∫ßn tr∆∞·ªõc.\n\n\nCode\n#Sum by daily and remove negative value:\nweekly_df&lt;-product_demand %&gt;% \n  select(c(Warehouse,\n           Date,\n           Order_Demand)) %&gt;%\n  mutate(order_date = floor_date(Date, \n                                 unit = 'week', \n                     # setting up week commencing Monday\n                     week_start = getOption(\"lubridate.week.start\", \n                                            1))) %&gt;%\n  group_by(order_date) %&gt;%\n  summarise(Order_Demand = sum(Order_Demand)) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\nGi·ªëng √Ω t∆∞·ªüng c·ªßa ARIMA, Ensemble ML c≈©ng ph√¢n t√≠ch m·ªëi t∆∞∆°ng quan gi·ªØa gi√° tr·ªã t·∫°i th·ªùi ƒëi·ªÉm t v·ªõi th·ªùi ƒëi·ªÉm t-1, t-2,‚Ä¶ V√† v√¨ ta ƒë√£ c√≥ d·ªØ li·ªáu t·∫°i th·ªùi ƒëi·ªÉm t n√™n ta c·∫ßn t√≠nh gi√° tr·ªã t·∫°i c√°c th·ªùi ƒëi·ªÉm t-1, t-2 b·∫±ng h√†m lag.\nTrong R, c√≥ h√†m ts_lags ƒë·ªÉ ki·∫øm tra m·ª©c ƒë·ªô t∆∞∆°ng quan gi·ªØa bi·∫øn hi·ªán t·∫°i v√† c√°c bi·∫øn trong qu√° kh·ª©. M·∫∑c ƒë·ªãnh, h√†m s·∫Ω t√≠nh cho ta trong 12 lags nh∆∞ng ta c√≥ th·ªÉ ch·ªâ ƒë·ªãnh b·∫±ng ƒë·ªëi s·ªë: lags = c()\n\n\nCode\nlibrary(TSstudio)\nts_lags(demand_training, lags = c(13, 26, 39, 52))\n\n\n\n\n\n\nD·ª±a v√†o bi·ªÉu ƒë·ªì tr√™n n√†y, ta th·∫•y ƒë∆∞·ª£c m·ªëi quan h·ªá tuy·∫øn t√≠nh theo h∆∞·ªõng t√≠ch c·ª±c gi·ªØa d·ªØ li·ªáu chu·ªói v√† gi√° tr·ªã c·ªßa n√≥ ·ªü lag 52 (nghƒ©a l√† 1 nƒÉm sau) v√† h∆∞·ªõng ti√™u c·ª±c v·ªõi gi√° tr·ªã c·ªßa n√≥ ·ªü lag 13.\nDo ƒë√≥, ch√∫ng ta s·∫Ω t·∫°o l·∫°i b·ªô d·ªØ li·ªáu c√≥ c√°c bi·∫øn m·ªõi.\n\n\nCode\nmodel_data &lt;- \n  weekly_df %&gt;% \n  mutate(trend       = 1:nrow(weekly_df),\n         trend_sqr   = trend^2,\n         rev_lag_13  = lag(Order_Demand, n = 13),\n         rev_lag_52  = lag(Order_Demand, n = 52),\n         season      = case_when(Order_Demand == 0 ~ 0,\n                                 TRUE ~ 1)\n        ) %&gt;% \n filter(!is.na(rev_lag_52)&!is.na(rev_lag_13)) %&gt;% \n  mutate(class = ifelse(order_date &lt;= n[[2]],\n                        \"train\",\n                        ifelse(order_date &gt; n[[2]]& order_date &lt;= n[[3]],\n                               \"test\",\"forecast\")))\n\n\n\n\n2.2 X·ª≠ l√≠ missing value v√† outliers:\n\n2.2.1 Missing value:\nG√≠a tr·ªã NA xu·∫•t hi·ªán l√† do ta ƒëang l·∫•y d·ªØ li·ªáu t·ª´ qu√° kh·ª© th·ªùi ƒëi·ªÉm c√°ch 1 th√°ng, 2 th√°ng v√† 3 th√°ng. V√¨ Machine Learning b·∫Øt bu·ªôc ph·∫£i c√≥ ƒë·∫ßy ƒë·ªß gi√° tr·ªã n√™n ta c√≥ th·ªÉ s·ª≠ d·ª•ng c√°ch kh√°c ƒë·ªÉ t·∫°o ra gi√° tr·ªã thay th·∫ø cho NA. M√¨nh kham kh·∫£o ƒë∆∞·ª£c c√°ch n√†y t·ª´ (Sauravkaushik8 Kaushik 2019).\n\n\n2.2.2 Outliers:\nNgo√†i ra, v·∫•n ƒë·ªÅ v·ªÅ outliers c≈©ng c·∫ßn ƒë∆∞·ª£c quan t√¢m. Outlier l√† c√°c gi√° tr·ªã c√≥ v·∫ª ‚Äúl·ªách‚Äù ho·∫∑c kh√¥ng b√¨nh th∆∞·ªùng so v·ªõi to√†n b·ªô d·ªØ li·ªáu. Nguy√™n nh√¢n xu·∫•t hi·ªán outlier c√≥ th·ªÉ do c√°c bi·∫øn c·ªë kh√¥ng l∆∞·ªùng tr∆∞·ªõc ho·∫∑c ƒë∆°n gi·∫£n l√† sai s√≥t trong vi·ªác ƒëo l∆∞·ªùng, t√≠nh to√°n c·ªßa ng∆∞·ªùi thu th·∫≠p d·ªØ li·ªáu.\nV√¨ m·ª•c ƒë√≠ch c·ªßa ch√∫ng ta l√† x√¢y d·ª±ng m√¥ h√¨nh n√™n c√°c outliers kh√¥ng gi√∫p √≠ch nhi·ªÅu. Do ƒë√≥ ch√∫ng ta c·∫ßn lo·∫°i b·ªè n√≥ tr∆∞·ªõc khi m√¥ h√¨nh h√≥a.\n\n\nCode\nlibrary(viridis)\nggplot(model_data,\n       aes(x=Order_Demand,\n           y = as.factor(class),\n           fill = as.factor(class))) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    geom_jitter(color=\"black\", \n                size=0.4, \n                alpha=0.9) +\n    theme_minimal() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11,\n                                hjust=1, \n                                vjust=0.5, \n                                face='bold')\n    ) +\n    ggtitle(\"A boxplot with jitter\") +\n    xlab(\"\")+\n    ylab(\"Dataset\")\n\n\n\n\n\nC√°c ƒëi·ªÉm ƒëen l·∫°c l·ªèng ·ªü ngo√†i v√πng boxplot ch√≠nh l√† outliers\n\n\n\nBi·ªÉu ƒë·ªì ph√¢n b·ªë c·ªßa 3 b·ªô d·ªØ li·ªáu\n\nC√°ch x·ª≠ l√≠ outliers kh√° ƒë∆°n gi·∫£n. ·ªû ƒë√¢y m√¨nh s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p IQR hay c√≤n g·ªçi l√† t·ª© ph√¢n v·ªã. Sau khi x·ª≠ l√≠, b·∫°n c√≥ th·ªÉ ch·∫°y l·∫°i code tr√™n ƒë·ªÉ ki·ªÉm tra xem outliers ƒë√£ ƒë∆∞·ª£c lo·∫°i b·ªè hay ch∆∞a.\n\n\n\nH√¨nh 8: IQR method.\n\n\n\n\nCode\n# T√≠nh IQR\nq25 &lt;- quantile(model_data$Order_Demand, 0.25)\nq75 &lt;- quantile(model_data$Order_Demand, 0.75)\niqr &lt;- q75 - q25\n\n# thi·∫øt l·∫≠p gi·ªõi h·∫°n ƒë·ªÉ x√°c ƒë·ªãnh outliers\nlimit_iqr = 1.5*iqr\nlower_iqr = q25 - limit_iqr\nupper_iqr = q75 + limit_iqr\n\n# Lo·∫°i b·ªè c√°c outliers\nmodel_data &lt;- model_data[-which(model_data$Order_Demand &gt; upper_iqr | model_data$Order_Demand &lt; lower_iqr),]\n\n## T·∫°o c√°c b·ªô d·ªØ li·ªáu training,testing v√† forecasting:\ntrain_data &lt;- \n  model_data %&gt;% \n  filter(class == \"train\")\n\ntest_data &lt;- \n  model_data %&gt;% \n  filter(class == \"test\")\n\nforecast_data &lt;- \n  model_data %&gt;% \n  filter(class == \"forecast\")\n\n\n\n\n\n2.3 D·ª± ƒëo√°n:\n\n2.3.1 M√¥ h√¨nh Random Forest:\nƒê·∫ßu ti√™n ch√∫ng ta s·∫Ω l√†m vi·ªác v·ªõi thu·∫≠t to√°n boosting kh√° ph·ªï bi·∫øn l√†: Random Forest.\nRandom Forest l√† m·ªôt ph∆∞∆°ng ph√°p h·ªçc m√°y thu·ªôc l·ªõp ensemble learning, ƒë∆∞·ª£c s·ª≠ d·ª•ng ch·ªß y·∫øu cho c√°c b√†i to√°n ph√¢n lo·∫°i v√† h·ªìi quy. ƒê√¢y l√† m·ªôt k·ªπ thu·∫≠t m·∫°nh m·∫Ω v√† ph·ªï bi·∫øn, ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Leo Breiman v√†o nƒÉm 2001.\nV·ªÅ ∆∞u ƒëi·ªÉm:\n\nKh·∫£ nƒÉng t·ªïng qu√°t cao: Random Forest th∆∞·ªùng c√≥ kh·∫£ nƒÉng t·ªïng qu√°t t·ªët h∆°n so v·ªõi c√°c m√¥ h√¨nh c√¢y quy·∫øt ƒë·ªãnh ƒë∆°n l·∫ª, do gi·∫£m thi·ªÉu overfitting (qu√° kh·ªõp) nh·ªù v√†o s·ª± k·∫øt h·ª£p c·ªßa nhi·ªÅu c√¢y.\nKh·∫£ nƒÉng x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn v√† nhi·ªÅu ƒë·∫∑c tr∆∞ng: Random Forest c√≥ th·ªÉ x·ª≠ l√Ω hi·ªáu qu·∫£ d·ªØ li·ªáu v·ªõi s·ªë l∆∞·ª£ng l·ªõn c√°c ƒë·∫∑c tr∆∞ng v√† quan s√°t.\nKh·∫£ nƒÉng ƒë√°nh gi√° t·∫ßm quan tr·ªçng c·ªßa c√°c ƒë·∫∑c tr∆∞ng: Random Forest cung c·∫•p th√¥ng tin v·ªÅ t·∫ßm quan tr·ªçng c·ªßa t·ª´ng ƒë·∫∑c tr∆∞ng trong vi·ªác ƒë∆∞a ra d·ª± ƒëo√°n, gi√∫p √≠ch trong vi·ªác ch·ªçn l·ªçc v√† ph√¢n t√≠ch ƒë·∫∑c tr∆∞ng.\n\nV·ªÅ nh∆∞·ª£c ƒëi·ªÉm:\n\nKh√≥ gi·∫£i th√≠ch: M·∫∑c d√π Random Forest c√≥ hi·ªáu su·∫•t t·ªët, nh∆∞ng c√°c m√¥ h√¨nh c√¢y quy·∫øt ƒë·ªãnh k·∫øt h·ª£p l·∫°i c√≥ th·ªÉ kh√≥ gi·∫£i th√≠ch v√† kh√¥ng tr·ª±c quan b·∫±ng c√°c m√¥ h√¨nh ƒë∆°n gi·∫£n h∆°n.\nT·ªën t√†i nguy√™n: ƒê·∫∑c bi·ªát khi s·ªë l∆∞·ª£ng c√¢y l·ªõn, Random Forest c√≥ th·ªÉ y√™u c·∫ßu nhi·ªÅu t√†i nguy√™n t√≠nh to√°n v√† b·ªô nh·ªõ.\n\n\n\nCode\nlibrary(h2o)\n## specify the size of the memory allocation pool cluster. \nh2o.init(max_mem_size = \"8G\")\n\n## Set dependent and independent variabls:\ny = \"Order_Demand\"\nx &lt;- setdiff(names(train_data) %&gt;% as.h2o(), \n             c(y, \"order_date\",\"class\"))\n\n## Build model:\nrft_model &lt;- \n  h2o.randomForest(\n    x = x, \n    y = y, \n    training_frame = train_data %&gt;% as.h2o(),\n    nfolds = 10,\n    ntrees = 500,\n    stopping_metric = \"RMSE\",\n    stopping_rounds = 10,\n    stopping_tolerance = 0.005,\n    seed = 1975\n  )\n\n\nPh√¢n t√≠ch th√™m v·ªÅ m·ª©c ƒë·ªô quan tr·ªçng c·ªßa c√°c bi·∫øn trong m√¥ h√¨nh. Ta th·∫•y bi·∫øn lag_50 ƒë√≥ng vai tr√≤ quan tr·ªçng nh·∫•t, ƒë√∫ng nh∆∞ d·ª± ƒëo√°n c·ªßa ta khi ph√¢n t√≠ch ·ªü tr√™n v·ªÅ m·ªëi t∆∞∆°ng quan.\n\n\nCode\n## visualise the variable importance \nrft_model %&gt;% \n  h2o.varimp_plot()\n\n\n\n\n\n\n\nCode\ninvisible(capture.output({\npred&lt;- h2o.predict(rft_model, \n                   newdata = as.h2o(train_data)) %&gt;% \n      as_tibble() %&gt;% \n  mutate(actual = train_data$Order_Demand,\n         date = train_data$order_date)\n}))\n\nlibrary(plotly)\npred %&gt;% \n  plot_ly() %&gt;% \n    add_lines(x = ~ date, y = ~ actual, name = 'Actual') %&gt;% \n    add_lines(x = ~ date, y = ~ predict, name = 'Random Forest', \n              line = list(dash = 'dot'))\n\n\n\n\n\n\nKhi d√πng d·ªØ li·ªáu c·ªßa b·ªô Training data, ML d·ª± ƒëo√°n l·∫°i g·∫ßn nh∆∞ s√°t v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø. Nh∆∞ng khi c√≥ d·ªØ li·ªáu m·ªõi v√†o Machine Learning kh√¥ng d·ª± ƒëo√°n t·ªët ƒë∆∞·ª£c. V√≠ d·ª• nh∆∞ d∆∞·ªõi ƒë√¢y.\n\n\nCode\nplot_f(rft_model)\n\n\n\n\n\n\n\n\n2.3.2 M√¥ h√¨nh GLM:\nCh√∫ng ta th·ª≠ th√™m 1 s·ªë m√¥ h√¨nh kh√°c c·ªßa ML. ·ªû d∆∞·ªõi ƒë√¢y l√† m√¥ h√¨nh Geleralised linear model s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p OSL ƒë·ªÉ t√≠nh to√°n.\n\n\nCode\n# geleralised linear model:\nglm_model &lt;- \n  h2o.glm(\n    x = x, \n    y = y, \n    training_frame = as.h2o(train_data),\n    nfolds = 10,\n    family = \"gaussian\",\n    seed = 1975\n  )\n\n\n\n\nCode\nplot_f(glm_model)\n\n\n\n\n\n\n\n\n2.3.3 M√¥ h√¨nh Auto ML:\nTrong g√≥i package {h2o} c·ªßa R c√≥ m√¥ h√¨nh ‚ÄúAuto Machine Learning‚Äù (AutoML) c√≥ th·ªÉ t·ª± ƒë·ªông h√≥a quy tr√¨nh ƒë√†o t·∫°o m√¥ h√¨nh h·ªçc m√°y ƒë∆∞·ª£c gi√°m s√°t (supervised ML). AutoML t√¨m th·∫•y m√¥ h√¨nh t·ªët nh·∫•t, ƒë∆∞a ra khung ƒë√†o t·∫°o v√† ph·∫£n h·ªìi, ƒë·ªìng th·ªùi tr·∫£ v·ªÅ ƒë·ªëi t∆∞·ª£ng H2OAutoML, ch·ª©a b·∫£ng x·∫øp h·∫°ng g·ªìm t·∫•t c·∫£ c√°c m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c ƒë√†o t·∫°o trong quy tr√¨nh, ƒë∆∞·ª£c x·∫øp h·∫°ng theo ch·ªâ s·ªë hi·ªáu su·∫•t m√¥ h√¨nh m·∫∑c ƒë·ªãnh.\n\n\nCode\nautoml_model &lt;-\n  h2o.automl(\n    x = x,\n    y = y,\n    training_frame     = as.h2o(train_data),\n    nfolds             = 5,\n    stopping_metric    = \"RMSE\",\n    stopping_rounds    = 10,\n    stopping_tolerance = 0.005,\n    max_runtime_secs   = 60,\n    seed               = 1975\n )\n\n\n\n\nCode\nplot_f(automl_model)\n\n\n\n\n\n\n\n\n2.3.4 M√¥ h√¨nh Boosting:\nTi·∫øp ƒë√≥, ch√∫ng ta s·∫Ω th·ª≠ v·ªõi thu·∫≠t to√°n boosting kh√° ph·ªï bi·∫øn l√†: Stochastic Gradient Boosting.\nStochastic Gradient Boosting: L√† m·ªôt bi·∫øn th·ªÉ c·ªßa gradient boosting, k·∫øt h·ª£p c√°c y·∫øu t·ªë ng·∫´u nhi√™n trong qu√° tr√¨nh hu·∫•n luy·ªán ƒë·ªÉ c·∫£i thi·ªán t√≠nh ch√≠nh x√°c v√† kh·∫£ nƒÉng t·ªïng qu√°t c·ªßa m√¥ h√¨nh. Thay v√¨ s·ª≠ d·ª•ng to√†n b·ªô d·ªØ li·ªáu hu·∫•n luy·ªán ƒë·ªÉ x√¢y d·ª±ng m·ªói m√¥ h√¨nh trong chu·ªói, Stochastic Gradient Boosting ch·ªâ s·ª≠ d·ª•ng m·ªôt m·∫´u ng·∫´u nhi√™n (subsample) c·ªßa d·ªØ li·ªáu. M·ªói m√¥ h√¨nh m·ªõi ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ s·ª≠a ch·ªØa c√°c sai s·ªë c·ªßa c√°c m√¥ h√¨nh tr∆∞·ªõc ƒë√≥.\nM·ª•c ti√™u l√† gi·∫£m thi·ªÉu h√†m m·∫•t m√°t (loss function) b·∫±ng c√°ch s·ª≠ d·ª•ng gradient descent.\n\n\nCode\nlibrary(caret)\n# TaÃ£o m√¥Ã£t ƒë√¥ÃÅi t∆∞∆°Ã£ng control cho cross-validation\nfitControl &lt;- trainControl(method=\"repeatedcv\", \n                        number=10, \n                        repeats=10)\n# Trong ƒë√≥\n# method = 'repeatedcv': s·ª≠ d·ª•ng cross-validation v·ªõi c√°c tham s·ªë sau:\n# number = 10 coÃÅ nhiÃÉa laÃÄ quaÃÅ triÃÄnh cross-validation c√¢ÃÄn chia d∆∞ÃÉ li√™Ã£u g√¥ÃÅc thaÃÄnh 10 ph√¢ÃÄn bƒÉÃÄng nhau\n# repeats = 10 c√≥ nghƒ©a l√† qu√° tr√¨nh cross-validation c·∫ßn l·∫∑p l·∫°i 10 l·∫ßn\n\n# Stochastic Gradient Boosting\nset.seed(825)\ngbmFit1 &lt;- train(Order_Demand~., \n                 data = train_data %&gt;% \n                   select(-c(order_date,class)), \n                 method = \"gbm\",\n                 trControl = fitControl,\n                 ## This last option is actually one\n                 ## for gbm() that passes through\n                 verbose = FALSE)\n\n\nSau khi ƒë√£ training model, ta s·∫Ω d√πng m√¥ h√¨nh ƒë√≥ ƒë·ªÉ d·ª± ƒëo√°n v√† so s√°nh v·ªõi gi√° tr·ªã th·ª±c t·∫ø ·ªü testing data. Ta s·∫Ω c√≥ k·∫øt qu·∫£ nh∆∞ d∆∞·ªõi ƒë√¢y:\nK·∫øt qu·∫£ c√≥ v·∫ª ·ªïn h∆°n Random Forest nh∆∞ng v·∫´n c√≥ 2 outliears v√¨ ƒë·ªô ch√™nh l·ªách l√™n ƒë·∫øn 10-20%.\n\n\nCode\npredict&lt;-data.frame(\n  Period = test_data$order_date,\n  Predicted = predict(gbmFit1, \n                      newdata = test_data %&gt;% \n                        select(-c(order_date,class))),\n  Observed = test_data$Order_Demand) %&gt;% \n  mutate(Diff = round((Observed - Predicted)/Observed*100,2),\n         Check = ifelse(Diff &lt;= 5 & Diff &gt;= -5, \"Passed\",\"Failed\"))\n\nlibrary(gt)\nlibrary(gtExtras)\ngt(predict %&gt;% \n     count(Check) %&gt;% \n     mutate(Per = round(n/nrow(predict),3))) %&gt;% \n  cols_label(\n    Check = md(\"**Status**\"),\n    n = md(\"**Count**\"),\n    Per = md(\"**Percentage**\")) %&gt;%\n  tab_header(\n    title = md(\"**Evaluating the model's accuracy**\"),\n    subtitle = glue::glue(\"Forecasting from {min(test_data$order_date)} to {max(test_data$order_date)}\")) %&gt;%\n   tab_source_note(\n    source_note = str_glue(\"Smaller 5% means passed\")) %&gt;% \n  gt_theme_538() %&gt;% \n  data_color(columns = c(\"Check\"),\n             method = \"factor\",\n             palette = c(\"red\",\"blue\"))\nggplot(data = predict,\n       aes(x = Period, \n           y = Diff)) + \n  geom_point() +\n  geom_smooth(method = \"lm\")+\n  geom_abline(intercept = 1, \n              slope = 0, color=\"red\", \n              linetype=\"dashed\", \n              size=1)+\n  xlab('Time') +\n  ylab('Difference (%)') +\n  theme_bw()+\n  labs(title = \"Evaluating model builded by GBM method\",\n       subtitle = \"Observed vs Predicted value\",\n       caption = \"The red line is abline Y = 0 means accuracry prediction and the blue line is the linear lines between observed and predicted value.\")\n\n\n\n\n\n\n\n\n  \n    \n      Evaluating the model‚Äôs accuracy\n\n    \n    \n      Forecasting from 2014-06-16 to 2015-05-25\n    \n    \n      Status\n\n      Count\n\n      Percentage\n\n    \n  \n  \n    Failed\n27\n0.587\n    Passed\n19\n0.413\n  \n  \n    \n      Smaller 5% means passed"
  },
  {
    "objectID": "EnsembleML.html#tuning-parameters",
    "href": "EnsembleML.html#tuning-parameters",
    "title": "Machine Learning",
    "section": "3 Tuning parameters:",
    "text": "3 Tuning parameters:\nTi√™u ƒë·ªÅ c·ªßa m·ª•c n√†y l√† keyword m√† b·∫°n c·∫ßn n·∫Øm v·ªÅ Machine Learning. Theo nghi√™n c·ª©u c·ªßa (D≈©ng, Nguy·ªÖn Ch√≠, n.d.), c√°c thu·∫≠t to√°n ML c√≥ c√°c tham s·ªë m√† vi·ªác ƒëi·ªÅu ch·ªânh tham s·ªë s·∫Ω ·∫£nh h∆∞·ªüng ƒë·∫øn k·∫øt qu·∫£ d·ª± ƒëo√°n. V·∫≠y chuy√™n ƒë·ªÅ t√¨m ra tham s·ªë t·ªëi ∆∞u nh·∫•t l√† m·ª•c quan tr·ªçng khi b·∫°n s·ª≠ d·ª•ng ML.\nV·ªÅ m·∫∑t l√Ω thuy·∫øt, c√≥ nhi·ªÅu c√°ch ƒë·ªÉ t√¨m ra, ·ªü b√†i n√†y m√¨nh s·∫Ω s·ª≠ d·ª•ng 3 c√°ch l√†:\n\nFull Grid Search.\nRandom Search.\nDefault Search.\n\nV√† h·∫ßu nh∆∞ kh√¥ng c√≥ c√°ch n√†o t√¨m ra tham s·ªë t·ªëi ∆∞u nh·∫•t b·∫±ng c√°ch th·ª±c nghi·ªám tr√™n m·ªôt b·ªô d·ªØ li·ªáu th·ª±c t·∫ø. Do ƒë√≥, ·ªü b√†i n√†y, ch√∫ng ta s·∫Ω l∆∞·ª£c qua c·∫£ 3 c√°ch ƒë√£ n√™u tr√™n v√† so s√°nh ch√∫ng ƒë·ªÉ ch·ªçn ra c√°c t·ªëi ∆∞u nh·∫•t.\nV·∫≠y c√≥ qu√° nhi·ªÅu thu·∫≠t to√°n ML v·∫≠y, l√†m sao ta bi·∫øt ƒë∆∞·ª£c thu·∫≠t to√°n n√†o c·∫ßn ch·ªânh tham s·ªë n√†o? Trong R c√≥ h√†m ƒë·ªÉ ch√∫ng ta t·ª± t√¨m hi·ªÉu, ƒë√≥ l√† getModelInfo. D∆∞·ªõi ƒë√¢y l√† 1 v√≠ d·ª• v·ªÅ thu·∫≠t to√°n m√† ta ƒë√£ d√πng ·ªü tr√™n:\n\n\nCode\ngetModelInfo(\"gbm\")$gbm$parameters\n\n\n          parameter   class                   label\n1           n.trees numeric   # Boosting Iterations\n2 interaction.depth numeric          Max Tree Depth\n3         shrinkage numeric               Shrinkage\n4    n.minobsinnode numeric Min. Terminal Node Size\n\n\nV·∫≠y ti·∫øp theo ch√∫ng ta s·∫Ω ƒëi·ªÅu ch·ªânh tham s·ªë ƒë·ªÉ t·ªëi ∆∞u k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh. Chi ti·∫øt ·ªü d∆∞·ªõi ph·∫ßn code.\n\nnumber of iterations, i.e.¬†trees, (called n.trees in the gbm function).\ncomplexity of the tree, called interaction.depth learning rate: how quickly the algorithm adapts, called shrinkage.\nthe minimum number of training set samples in a node to commence splitting (n.minobsinnode)\n\nD·ª±a tr√™n h∆∞·ªõng d·∫´n c·ªßa (Jason Brownlee 2020), ta s·∫Ω th·ª±c h√†nh qua c·∫£ 3 ph∆∞∆°ng ph√°p. Code chi ti·∫øt d∆∞·ªõi ƒë√¢y.\n\n3.0.1 Ph∆∞∆°ng ph√°p Random Search:\n\n\n\n\n\n\nRandom Search\n\n\n\ncontrol &lt;- trainControl(method=‚Äúrepeatedcv‚Äù, number=10, repeats=3, search=‚Äúrandom‚Äù)\nmtry &lt;- sqrt(ncol(train_data))\ngbm_random &lt;- train(Order_Demand~., data = train_data %&gt;% select(-c(order_date,class)), method=‚Äúgbm‚Äù, tuneLength = 5, trControl = control)\nplot(gbm_random)\n\n\n\n\n3.0.2 Ph∆∞∆°ng ph√°p Grid Search:\nV·ªõi ph∆∞∆°ng ph√°p Grid Search, ta ch·ªâ c·∫ßn ƒë·ªïi ƒë·ªëi s·ªë search = \"grid\" v√† th√™m ƒë·ªëi s·ªë tuneGrid.\n\n\n\n\n\n\nGrid Search\n\n\n\ncontrol &lt;- trainControl(method=‚Äúrepeatedcv‚Äù, number=10, repeats=3, search=‚Äúgrid‚Äù)\ntunegrid &lt;- expand.grid(.mtry=c(1:5))\ngbm_gridsearch&lt;-train(Order_Demand~., data = train_data %&gt;% select(-c(order_date,class)), method=‚Äúgbm‚Äù, tuneGrid=tunegrid, trControl = control)\nplot(gbm_gridsearch)\n\n\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ gh√© thƒÉm v√† ƒë·ªçc b√†i vi·∫øt c·ªßa m√¨nh!!!"
  },
  {
    "objectID": "index.html#ƒë·ªãnh-nghƒ©a",
    "href": "index.html#ƒë·ªãnh-nghƒ©a",
    "title": "Gi·ªõi thi·ªáu",
    "section": "",
    "text": "Trong qu·∫£n l√≠ chu·ªói cung ·ª©ng, thu·∫≠t ng·ªØ Demand Planning l√† m·ªôt trong nh·ªØng ho·∫°t ƒë·ªông quan tr·ªçng m√† c√°c nh√† qu·∫£n l√≠ v√† doanh nghi·ªáp c·∫ßn quan t√¢m s√¢u s·∫Øc. V·ªÅ ƒë·ªãnh nghƒ©a, theo (Vilas, n.d.) ‚ÄúDemand Planning l√† m·ªôt qu√° tr√¨nh qu·∫£n l√Ω chu·ªói cung ·ª©ng nh·∫±m d·ª± b√°o nhu c·∫ßu v·ªÅ s·∫£n ph·∫©m ƒë·ªÉ ƒë·∫£m b·∫£o ch√∫ng c√≥ th·ªÉ ƒë∆∞·ª£c cung c·∫•p v√† l√†m h√†i l√≤ng kh√°ch h√†ng. M·ª•c ti√™u c·ªßa Demand planning l√† ƒë·∫°t ƒë∆∞·ª£c s·ª± c√¢n b·∫±ng trong vi·ªác c√≥ ƒë·ªß l∆∞·ª£ng h√†ng t·ªìn kho ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu c·ªßa kh√°ch h√†ng m√† kh√¥ng b·ªã thi·∫øu ho·∫∑c th·ª´a. ƒê·ªÉ c√≥ th·ªÉ d·ª± b√°o ƒë∆∞·ª£c nhu c·∫ßu mua h√†ng, nh√† Ho·∫°ch ƒë·ªãnh nhu c·∫ßu c·∫ßn thu th·∫≠p v√† ph√¢n t√≠ch d·ªØ li·ªáu t·ª´ nhi·ªÅu ngu·ªìn kh√°c nhau nh∆∞: h√†ng t·ªìn kho, nh√† cung ·ª©ng, kho, kh√°ch h√†ng,‚Ä¶‚Äù.\n\n\n\nH√¨nh 1: ƒê·ªãnh nghƒ©a v·ªÅ Demand Planning"
  },
  {
    "objectID": "index.html#l·ª£i-√≠ch-c·ªßa-demand-planning",
    "href": "index.html#l·ª£i-√≠ch-c·ªßa-demand-planning",
    "title": "Gi·ªõi thi·ªáu",
    "section": "",
    "text": "Vi·ªác d·ª± ƒëo√°n tr∆∞·ªõc nhu c·∫ßu c·ªßa kh√°ch h√†ng s·∫Ω gi√∫p doanh nghi·ªáp chu·∫©n b·ªã t·ªët h∆°n v·ªÅ h√†ng h√≥a, d·ªãch v·ª• v√† chi·∫øm ƒë∆∞·ª£c l√≤ng tin c·ªßa kh√°ch h√†ng. Ngo√†i ra, vi·ªác chu·∫©n b·ªã s·ªõm c≈©ng tr√°nh c√°c hi·ªán t∆∞·ª£ng nh∆∞ out-stock, tranh ch·∫•p ho·∫∑c t·ªá h∆°n ƒë·ª©t g√£y chu·ªói cung ·ª©ng v√† ·∫£nh h∆∞·ªüng n·∫∑ng n·ªÅ t·ªõi k·∫øt qu·∫£ kinh doanh c·ªßa c√¥ng ty.\n·ªû v·ªã tr√≠ nh√¢n vi√™n, b·∫°n c√≥ th·ªÉ ·ª©ng tuy·ªÉn v·ªã tr√≠ Demand Planner ƒë·ªÉ c√≥ th·ªÉ l√†m vi·ªác v·ªÅ Demand Planning. C√≤n ·ªü v·ªã tr√≠ c·∫•p cao h∆°n s·∫Ω l√† Supply Chain Planner - l√† ng∆∞·ªùi c√≥ th·ªÉ x·ª≠ l√≠ lu√¥n c·∫£ 4 v·∫•n ƒë·ªÅ nh∆∞ sau:\n\nDemand planning: D·ª± ƒëo√°n nhu c·∫ßu kh√°ch h√†ng bao nhi√™u.\nCapacity planning: L√™n k·∫ø ho·∫°ch ph√¢n ph·ªëi, t·ªìn kho.\nProdcution planning: Chu·∫©n b·ªã nguy√™n v·∫≠t li·ªáu ƒë·ªÉ s·∫£n xu·∫•t ·ªü nh√† m√°y. Th√¥ng th∆∞·ªùng ho·∫°t ƒë·ªông n√†y ch·ªâ x·∫£y ra ·ªü c√¥ng ti l·ªõn c√≥ c·∫£ chu·ªói cung ·ª©ng t·ª´ nh√† m√°y ƒë·∫øn nh√† kho v√† c√≥ th·ªÉ c·∫£ c·ª≠a h√†ng.\nInvetory management v√† Sales and Opertion planning: hai ch·ª©c nƒÉng n√†y c√≥ th·ªÉ g·ªôp l·∫°i th√†nh Fulfillment planning - l√† ho·∫°t ƒë·ªông nh·∫±m th·ªèa m√£n c√°c nhu c·∫ßu kh√°c nhau c·ªßa kh√°ch h√†ng nh∆∞: qu·∫£n l√≠ h√†ng t·ªìn kho tr√°nh b·ªã outstock, h√†ng h√≥a ƒë∆∞·ª£c v·∫≠n chuy·ªÉn ƒë√∫ng s·ªë l∆∞·ª£ng, ƒë√∫ng s·∫£n ph·∫©m v√† nh·∫≠n h√†ng v·ªõi th·ªùi gian ng·∫Øn nh·∫•t.\n\n\n\n\nH√¨nh 2: C√°c ch·ª©c nƒÉng ch√≠nh c·ªßa Supply Chain Planner"
  },
  {
    "objectID": "SARIMA.html",
    "href": "SARIMA.html",
    "title": "M√¥ h√¨nh SARIMA",
    "section": "",
    "text": "Theo nghi√™n c·ª©u c·ªßa (JOHN A. MILLER, MOHAMMED ALDOSARI, and NASID HABIB BARNA 2024),h·ªç nh·∫Øc ƒë·∫øn m√¥ h√¨nh SARIMAX c√≥ performance t·ªët h∆°n ARIMA. V·∫≠y SARIMAX l√† g√¨:\n\nƒê·ªãnh nghƒ©a: ARIMA ƒë√≥ng vai tr√≤ l√† n·ªÅn t·∫£ng ƒë·ªÉ l·∫≠p m√¥ h√¨nh d·ªØ li·ªáu kh√¥ng theo m√πa (non-seasonal), trong khi SARIMA m·ªü r·ªông kh·∫£ nƒÉng x·ª≠ l√Ω c√°c m·∫´u theo m√πa.\nTh√†nh ph·∫ßn: SARIMAX c≈©ng x√¢y d·ª±ng d·ª±a tr√™n l√Ω thuy·∫øt nh∆∞ ARIMA nh∆∞ng th√™m 2 y·∫øu t·ªë m·ªõi l√† Seasonal v√† Exogenous variables. C√≤n m√¥ h√¨nh SARMA th√¨ ch·ªâ c√≥ th√™m y·∫øu t·ªë Seasonal.\n\nTh·ª±c t·∫ø, m√¥ h√¨nh m√† R ƒë·ªÅ xu·∫•t tr√™n b·∫±ng h√†m auto.arima() c≈©ng ƒë√£ bao g·ªìm th√†nh ph·∫ßn seasonal n√™n ta c√≥ th·ªÉ xem m√¥ h√¨nh tr√™n SARIMA.\n\n\n\nH√¨nh 7: SARIMA VS ARIMA\n\n\nD∆∞·ªõi ƒë√¢y l√† v√≠ d·ª• v·ªÅ m√¥ h√¨nh SARIMA v√† c√°ch ƒë·ªÉ code trong R.\nGi·∫£i th√≠ch l·∫°i c√°c th√¥ng s·ªë ta s·ª≠ d·ª•ng s·∫Ω l√†:\n\n(p,d,q) l√† b·∫≠c AR, m·ª©c ƒë·ªô kh√°c bi·ªát - Difference v√† b·∫≠c MA.\n(P,D,Q) l√† b·∫≠c seasonal c·ªßa m√¥ h√¨nh.\n[s] (period arguments) l√† th√¥ng s·ªë cho pattern. V√≠ d·ª• trong d·ªØ li·ªáu n√†y l√† d·ªØ li·ªáu c·ªßa 12 th√°ng n√™n period = 12. B·∫°n c√≥ th·ªÉ g·∫∑p d·ªØ li·ªáu theo qu√Ω th√¨ period = 3, d·ªØ li·ªáu theo nƒÉm th√¨ period = 1.\n\nV·∫≠y th√¨ c√≤n m√¥ h√¨nh SARIMAX th√¨ kh√°c g√¨ v·ªõi SARIMA.\n\n\n\nSARIMAX nghƒ©a l√† Seasonal Autoregressive Integrated Moving Average with eXogenous regressors l√† m·ªôt s·ª± m·ªü r·ªông c·ªßa m√¥ h√¨nh ARIMA, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ph√¢n t√≠ch v√† d·ª± ƒëo√°n c√°c chu·ªói th·ªùi gian c√≥ t√≠nh m√πa v·ª• v√† c√≥ th·ªÉ c√≥ th√™m c√°c bi·∫øn ƒë·ªôc l·∫≠p b√™n ngo√†i. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë ƒëi·ªÉm ch√≠nh v·ªÅ m√¥ h√¨nh n√†y. V·∫≠y so v·ªõi m√¥ h√¨nh SARIMA, n√≥ ch·ªâ kh√°c l√† c√≥ th√™m bi·∫øn kh√°c kh√¥ng ph·∫£i l√† bi·∫øn qu√° kh·ª© c·ªßa d·ªØ li·ªáu.\nNh·∫Øc l·∫°i, c·∫•u tr√∫c m√¥ h√¨nh SARIMAX v·∫´n bao g·ªìm c√°c th√†nh ph·∫ßn sau:\n\nAR (Autoregressive): Ph·∫ßn n√†y m√¥ t·∫£ m·ªëi quan h·ªá gi·ªØa gi√° tr·ªã hi·ªán t·∫°i v√† c√°c gi√° tr·ªã tr∆∞·ªõc ƒë√≥ trong chu·ªói th·ªùi gian.\nI (Integrated): Ph·∫ßn n√†y ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác l√†m cho chu·ªói th·ªùi gian tr·ªü n√™n ·ªïn ƒë·ªãnh b·∫±ng c√°ch l·∫•y sai ph√¢n c·ªßa n√≥.\nMA (Moving Average): Ph·∫ßn n√†y m√¥ t·∫£ m·ªëi quan h·ªá gi·ªØa gi√° tr·ªã hi·ªán t·∫°i v√† c√°c sai s·ªë d·ª± ƒëo√°n trong qu√° kh·ª©.\nSeasonal: SARIMAX c√≥ th·ªÉ x·ª≠ l√Ω c√°c y·∫øu t·ªë m√πa v·ª• b·∫±ng c√°ch th√™m c√°c tham s·ªë m√πa v·ª• v√†o m√¥ h√¨nh.\n\nV√† th√™m v√†o ƒë√≥ l√† tham s·ªë m·ªõi l√† ph·∫ßn Exogenous l√† c√°c bi·∫øn ƒë·ªôc l·∫≠p b√™n ngo√†i (exogenous variables) ƒë·ªÉ c·∫£i thi·ªán kh·∫£ nƒÉng d·ª± ƒëo√°n.\nNh∆∞ v·∫≠y, m√¥ h√¨nh SARIMAX mang l·∫°i nhi·ªÅu l·ª£i √≠ch, bao g·ªìm kh·∫£ nƒÉng d·ª± ƒëo√°n ch√≠nh x√°c h∆°n nh·ªù v√†o vi·ªác x·ª≠ l√Ω hi·ªáu qu·∫£ c√°c y·∫øu t·ªë m√πa v·ª• v√† c√°c bi·∫øn ƒë·ªôc l·∫≠p. Ngo√†i ra, m√¥ h√¨nh n√†y c√≤n cho ph√©p ƒëi·ªÅu ch·ªânh c√°c tham s·ªë linh ho·∫°t ƒë·ªÉ ph√π h·ª£p v·ªõi ƒë·∫∑c ƒëi·ªÉm c·ªßa d·ªØ li·ªáu. Tuy nhi√™n, SARIMAX c≈©ng c√≥ m·ªôt s·ªë nh∆∞·ª£c ƒëi·ªÉm, nh∆∞ t√≠nh ph·ª©c t·∫°p khi c·∫ßn t·ªëi ∆∞u h√≥a nhi·ªÅu tham s·ªë v√† y√™u c·∫ßu v·ªÅ d·ªØ li·ªáu l·ªõn, v√¨ ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c k·∫øt qu·∫£ t·ªët, m√¥ h√¨nh c·∫ßn c√≥ m·ªôt l∆∞·ª£ng d·ªØ li·ªáu l·ªãch s·ª≠ ƒë√°ng k·ªÉ.\n\n\n\nƒê·ªÉ ki·ªÉm ch·ª©ng n√≥, ta s·∫Ω gi·∫£ s·ª≠ c√≥ th√™m 1 bi·∫øn l√† bi·∫øn Income (Thu nh·∫≠p) v√†o m√¥ h√¨nh\nB·∫°n c√≥ th·ªÉ quay l·∫°i trang ƒë·∫ßu ti√™n ƒë·ªÉ l·∫•y d·ªØ li·ªáu g·ªëc v√† c√°c b∆∞·ªõc ƒë·ªÉ ch·ªânh s·ª≠a d·ªØ li·ªáu ·ªü Gi·ªõi thi·ªáu.\n\n\nCode\n# T·∫°o bi·∫øn m·ªõi thu nh·∫≠p b√¨nh qu√¢n:\nincome&lt;-ts(data = runif(nrow(month_df),100,500),\n           frequency = 12,\n           start = c(2012,1))\n\nlibrary(forecast)\nggtsdisplay(income,\n            main = \"Time-series plot of median income\")\n\n\n\n\n\nSau ƒë√≥ ta x√¢y d·ª±ng m√¥ h√¨nh nh∆∞ c√°c b∆∞·ªõc c≈©:\n\n\nCode\n#Forecast by training model:\nmodel_training2&lt;-Arima(demand_training,\n             xreg = income[1:length(demand_training)],\n             order = c(3,1,3),\n             seasonal = list(order = c(1,1,0),\n                             period = 12),\n             lambda = NULL,\n             include.constant = TRUE)\n\ncheckresiduals(model_training2,\n               theme = theme_bw())\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(3,1,3)(1,1,0)[12] errors\nQ* = 3.6946, df = 3, p-value = 0.2964\n\nModel df: 7.   Total lags used: 10\n\n\n\n\nCode\ntraining_forecast2&lt;-forecast(model_training2,\n                             xreg = income[39:nrow(month_df)],\n                             h = 21)\n\n#Use chart for presenting the differents:\nplot(training_forecast2,\n      main = str_glue(\"Model ARIMA(2,0,0)\"),\n      xlab = \"Time\",\n      ylab = \"Order Demand\")\nlines(demand_testing, \n      col = \"red\",\n      lwd = \"2\")\nlegend(\"topleft\",\n       legend = c(\"Actual\",\"Forecast\"),\n       col = c(\"red\",\"blue\"),\n       box.lty = 0,\n       lty = 1,\n       cex = 1,\n       lwd = 2)\n\n\n\n\n\nV√† sau ƒë√≥, ta s·∫Ω s·ª≠ d·ª•ng model ƒë√≥ ƒë·ªÉ d·ª± ƒëo√°n cho t∆∞∆°ng lai. Nh√¨n bi·ªÉu ƒë·ªì ta d·ªÖ d√†ng k·∫øt lu·∫≠n m√¥ h√¨nh kh√¥ng t·ªët. Nguy√™n do l√† t∆∞∆°ng quan gi·ªØa bi·∫øn income v√† demand_training qu√° th·∫•p, ch·ªâ s·ªë t∆∞∆°ng quan ch·ªâ c√≥ -0.139."
  },
  {
    "objectID": "SARIMA.html#chu·∫©n-b·ªã-d·ªØ-li·ªáu",
    "href": "SARIMA.html#chu·∫©n-b·ªã-d·ªØ-li·ªáu",
    "title": "M√¥ h√¨nh SARIMA",
    "section": "",
    "text": "ƒê·ªÉ ki·ªÉm ch·ª©ng n√≥, ta s·∫Ω gi·∫£ s·ª≠ c√≥ th√™m 1 bi·∫øn l√† bi·∫øn Income (Thu nh·∫≠p) v√†o m√¥ h√¨nh\nB·∫°n c√≥ th·ªÉ quay l·∫°i trang ƒë·∫ßu ti√™n ƒë·ªÉ l·∫•y d·ªØ li·ªáu g·ªëc v√† c√°c b∆∞·ªõc ƒë·ªÉ ch·ªânh s·ª≠a d·ªØ li·ªáu ·ªü Gi·ªõi thi·ªáu.\n\n\nCode\n# T·∫°o bi·∫øn m·ªõi thu nh·∫≠p b√¨nh qu√¢n:\nincome&lt;-ts(data = runif(nrow(month_df),100,500),\n           frequency = 12,\n           start = c(2012,1))\n\nlibrary(forecast)\nggtsdisplay(income,\n            main = \"Time-series plot of median income\")\n\n\n\n\n\nSau ƒë√≥ ta x√¢y d·ª±ng m√¥ h√¨nh nh∆∞ c√°c b∆∞·ªõc c≈©:\n\n\nCode\n#Forecast by training model:\nmodel_training2&lt;-Arima(demand_training,\n             xreg = income[1:length(demand_training)],\n             order = c(3,1,3),\n             seasonal = list(order = c(1,1,0),\n                             period = 12),\n             lambda = NULL,\n             include.constant = TRUE)\n\ncheckresiduals(model_training2,\n               theme = theme_bw())\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(3,1,3)(1,1,0)[12] errors\nQ* = 3.6946, df = 3, p-value = 0.2964\n\nModel df: 7.   Total lags used: 10\n\n\n\n\nCode\ntraining_forecast2&lt;-forecast(model_training2,\n                             xreg = income[39:nrow(month_df)],\n                             h = 21)\n\n#Use chart for presenting the differents:\nplot(training_forecast2,\n      main = str_glue(\"Model ARIMA(2,0,0)\"),\n      xlab = \"Time\",\n      ylab = \"Order Demand\")\nlines(demand_testing, \n      col = \"red\",\n      lwd = \"2\")\nlegend(\"topleft\",\n       legend = c(\"Actual\",\"Forecast\"),\n       col = c(\"red\",\"blue\"),\n       box.lty = 0,\n       lty = 1,\n       cex = 1,\n       lwd = 2)\n\n\n\n\n\nV√† sau ƒë√≥, ta s·∫Ω s·ª≠ d·ª•ng model ƒë√≥ ƒë·ªÉ d·ª± ƒëo√°n cho t∆∞∆°ng lai. Nh√¨n bi·ªÉu ƒë·ªì ta d·ªÖ d√†ng k·∫øt lu·∫≠n m√¥ h√¨nh kh√¥ng t·ªët. Nguy√™n do l√† t∆∞∆°ng quan gi·ªØa bi·∫øn income v√† demand_training qu√° th·∫•p, ch·ªâ s·ªë t∆∞∆°ng quan ch·ªâ c√≥ -0.139."
  },
  {
    "objectID": "SARIMA.html#th·ª±c-h√†nh-trong-r",
    "href": "SARIMA.html#th·ª±c-h√†nh-trong-r",
    "title": "M√¥ h√¨nh SARIMA",
    "section": "",
    "text": "Th·ª±c t·∫ø, ta th·∫•y m√¥ h√¨nh do R ƒë·ªÅ xu·∫•t b·∫±ng h√†m auto.arima c√≥ v·∫ª ‚Äúoverfitting‚Äù - nghƒ©a l√† m√¥ h√¨nh t·ªët qu√°, cover h·∫øt c√°c tr∆∞·ªùng h·ª£p nh∆∞ng c√≥ nguy c∆° kh√¥ng cho d·ª± ƒëo√°n t·ªët v√¨ d·ªØ li·ªáu trong t∆∞∆°ng lai bi·∫øn ƒë·ªông.\nV√¨ v·∫≠y, ta c·∫ßn x√¢y d·ª±ng c√°ch l·ª±a ch·ªçn m√¥ h√¨nh theo c√°ch kh√°c. M√¨nh c√≥ kham kh·∫£o c√°ch n√†y tr√™n How can I select the best SARIMA model.\n\n\nCode\n## List all parameters can be appeared:\nqQ=list()\nfor(i in 1:14) qQ[[i]]=c(i-1,0)\nqQ[[15]]=c(0,1)\nqQ[[16]]=c(1,1)\npP=qQ\n \ndt_params=c()\nfor(i in 1:16){\n  for(j in 1:16){\n     temp=c(pP[[i]][1],1,qQ[[j]][1],pP[[i]][2],1,\n            qQ[[j]][2],12)\n     dt_params=rbind(temp,dt_params)\n   }\n }\ncolnames(dt_params)=c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"T\")\nrownames(dt_params)=1:256\n\n# Build all the models:\nmodels=vector(\"list\",256)\nfor(i in 1:256){\n   try(models[[i]]&lt;-Arima(diff(demand_training,lag = 1),\n                          order = dt_params[i,1:3],\n                          seasonal = list(order=dt_params[i,4:6],\n                                          period=12),\n                     lambda = NULL,\n                     method=\"ML\"))  ## use MLE (maximum likelihood estimation)\n}\n\n\nSau khi ƒë√£ x√¢y d·ª±ng h·∫øt c√°c m√¥ h√¨nh b·∫±ng 256 th√¥ng s·ªë. Ta s·∫Ω ki·ªÉm tra gi·∫£ thuy·∫øt v·ªÅ t√≠nh ƒë·ªôc l·∫≠p trong m·ªôt chu·ªói th·ªùi gian nh·∫•t ƒë·ªãnh (White noise) - nghƒ©a l√† ki·ªÉm tra ph·∫ßn d∆∞ (residuals) c·ªßa m√¥ h√¨nh c√≥ ph·∫£i l√† random noise kh√¥ng ?\n\n\nCode\n## Applied Ljung-Box Tests:\naa=rep(NA,256)\nfor(i in 1:256){\n   if(length(models[[i]]$residuals)&gt;1){\n     a=Box.test(x = models[[i]]$residuals,\n                lag = 10,\n                type = \"Box-Pierce\")\n     z=prod(1-(a[[\"p.value\"]]&lt;.05))\n     if(z==1) aa[i]=\"Passed\"\n     else aa[i]=\"Failed\"\n   }\n}\n\n## Transfers all these information into 1 table:\ndt_params2=data.frame(dt_params)\ndt_params2$residuals=aa\n\naic=rep(NA,256)\nmodel_names=rep(NA,256)\nfor(i in 1:256){\n   if(length(models[[i]]$aic)&gt;0){\n     aic[i]=models[[i]]$aic\n     model_names[i]=as.character(models[[i]])\n   }\n}\ndt_params2$aic=aic\ndt_params2$model=model_names\n\n\nCu·ªëi c√πng tr√¨nh b√†y b·∫£ng 10 model t·ªët nh·∫•t v·ªõi 2 ƒëi·ªÅu ki·ªán:\n\nCh·ªâ s·ªë AIC th·∫•p trong top 10.\nCh·ªâ s·ªë p c·ªßa Ljung-Box Test &lt; 0.05.\n\nV√† m√¥ h√¨nh cu·ªëi c√πng ƒë∆∞·ª£c ch·ªçn l√† ARIMA(2,1,0)(0,1,0)[12] v·ªõi ch·ªâ s·ªë AIC l√† 189.8917.\n\n\nCode\n## Finally plot the table and compared the AIC and BIC value among models:\ngt&lt;-dt_params2[order(dt_params2$aic,decreasing = FALSE),][1:10,] %&gt;%\n     filter(residuals == \"Passed\") %&gt;% ### Just select the models with p &lt; 0.05\n     relocate(model)\n## Just select 10 best models:\n\n\nlibrary(gt)\nlibrary(gtExtras)\n\n\nWarning: package 'gtExtras' was built under R version 4.2.3\n\n\nCode\ngt(gt) %&gt;% \n  cols_align(\n    align = \"left\",\n    columns = \"model\"\n  ) %&gt;% \n    cols_label(\n    model = md(\"**Model**\"),\n    aic = md(\"**AIC value**\")) %&gt;%\n   tab_header(\n    title = md(\"**Ljung‚ÄìBox test**\"),\n    subtitle = glue::glue(\"Time from {min(training_df$datetime)} to {max(training_df$datetime)}\")) %&gt;%\n   tab_source_note(\n    source_note = \"Null hypothesis: a given time series is independence\") %&gt;% \n  gt_theme_538() %&gt;% \n  gt_highlight_rows(rows = 1, \n                    font_weight = \"normal\")\n\n\n\n\n\n\n  \n    \n      Ljung‚ÄìBox test\n\n    \n    \n      Time from 2012-01-01 to 2015-03-01\n    \n    \n      Model\n\n      p\n      d\n      q\n      P\n      D\n      Q\n      T\n      residuals\n      AIC value\n\n    \n  \n  \n    ARIMA(2,1,1)(0,1,0)[12]\n2\n1\n1\n0\n1\n0\n12\nPassed\n190.2729\n    ARIMA(2,1,2)(0,1,0)[12]\n2\n1\n2\n0\n1\n0\n12\nPassed\n191.1681\n    ARIMA(3,1,1)(0,1,0)[12]\n3\n1\n1\n0\n1\n0\n12\nPassed\n191.2535\n    ARIMA(2,1,1)(0,1,1)[12]\n2\n1\n1\n0\n1\n1\n12\nPassed\n191.6419\n    ARIMA(3,1,1)(0,1,1)[12]\n3\n1\n1\n0\n1\n1\n12\nPassed\n192.6654\n    ARIMA(4,1,1)(0,1,0)[12]\n4\n1\n1\n0\n1\n0\n12\nPassed\n193.1045\n    ARIMA(2,1,3)(0,1,0)[12]\n2\n1\n3\n0\n1\n0\n12\nPassed\n193.1531\n    ARIMA(3,1,2)(0,1,0)[12]\n3\n1\n2\n0\n1\n0\n12\nPassed\n193.1566\n    ARIMA(2,1,5)(0,1,0)[12]\n2\n1\n5\n0\n1\n0\n12\nPassed\n194.1552\n    ARIMA(2,1,0)(0,1,0)[12]\n2\n1\n0\n0\n1\n0\n12\nPassed\n194.2871\n  \n  \n    \n      Null hypothesis: a given time series is independence\n    \n  \n  \n\n\n\n\n\n\n\nV√† cu·ªëi c√πng l√† ƒë√°nh gi√° m√¥ h√¨nh v·ª´a ƒë∆∞·ª£c ch·ªçn ARIMA(2,1,0)(0,1,0)[12] v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ ƒë·ªëi t∆∞·ª£ng demand_testing.\n\n\nCode\n#Forecast by training model:\nmodel_training3&lt;-Arima(diff(demand_training,lag = 1),\n                       order = c(2,1,1),\n                       seasonal = list(order = c(0,1,0),\n                                       period = 12),\n             lambda = NULL)\n\ntraining_forecast3&lt;-forecast(model_training3,\n                             h = 21)\n\n#Use chart for presenting the differents:\nplot(training_forecast3,\n      main = glue::glue(\"Model {gt[['model']][1]}\"),\n      xlab = \"Time\",\n      ylab = \"Order Demand\")\nlines(diff(demand_testing,lag = 1), \n      col = \"red\",\n      lwd = \"2\")\nlegend(\"topleft\",\n       legend = c(\"Actual\",\"Forecast\"),\n       col = c(\"red\",\"blue\"),\n       box.lty = 0,\n       lty = 1,\n       cex = 1,\n       lwd = 2)\n\n\n\n\n\n\n\n\nSau khi ƒë√£ x√¢y d·ª±ng m√¥ h√¨nh, ta c·∫ßn ki·ªÉm tra l·∫°i c√°c gi·∫£ thuy·∫øt nh∆∞:\n\nPh·∫ßn d∆∞ kh√¥ng t∆∞∆°ng quan.\nPh·∫ßn d∆∞ c√≥ trung b√¨nh l√† 0.\nph∆∞∆°ng sai kh√¥ng ƒë·ªïi\nPh·∫ßn d∆∞ c√≥ ph√¢n ph·ªëi chu·∫©n.\n\n\n\nCode\n## Diagnostics the ARRIMA model in a short command:\ncheckresiduals(model_training3,\n               theme = theme_bw())\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,1,1)(0,1,0)[12]\nQ* = 6.3324, df = 5, p-value = 0.2752\n\nModel df: 3.   Total lags used: 8\n\n\nN·∫øu so s√°nh v·ªõi m√¥ h√¨nh ban ƒë·∫ßu theo c√°ch auto.arima th√¨ c√≥ v·∫ª m√¥ h√¨nh n√†y t·ªá h∆°n. Nh∆∞ng c√≥ th·ªÉ ·ªü trong t∆∞∆°ng lai, m√¥ h√¨nh n√†y c√≥ th·ªÉ s·∫Ω t·ªët h∆°n chƒÉng.\n\n\nCode\n## Calculating MAE metric:\nsum = 0\nfor (i in 1:21){ \n  sum = abs(diff(demand_testing,lag = 1)[i]-training_forecast3$mean[i])+sum\n} \n\nMAE = sum/21\n\n## Calculating RMSE metric:\nRMSE = sqrt(mean((diff(demand_testing,lag = 1) - training_forecast3$mean)^2))\n\n## Plot the compared results:\ngt(data.frame(Metric = c(\"MAE\",\"RMSE\"),\n              Manual = c(MAE,RMSE),\n              Auto.Arima = c(6.428828,7.534382))) %&gt;% \n  cols_label(\n    Manual = md(\"**Manual method**\"),\n    Auto.Arima = md(\"**Auto.Arima method**\")) %&gt;%\n  cols_align(\n    align = \"center\",\n    columns = \"Manual\"\n  ) %&gt;% \n  cols_align(\n    align = \"center\",\n    columns = \"Auto.Arima\"\n  ) %&gt;% \n  tab_header(\n    title = md(\"**Comparing the accuracy of forecasting**\"),\n    subtitle = glue::glue(\"Forecasting from {min(testing_df$datetime)} to {max(testing_df$datetime)}\")) %&gt;%\n   tab_source_note(\n    source_note = str_glue(\"Between Manual and Auto ARIMA Method\")) %&gt;% \n  gt_theme_538() %&gt;% \n  gt_highlight_cols(Auto.Arima, \n                    fill = \"blue\", \n                    alpha = 0.5)\n\n\n\n\n\n\n  \n    \n      Comparing the accuracy of forecasting\n\n    \n    \n      Forecasting from 2015-03-01 to 2016-12-01\n    \n    \n      Metric\n      Manual method\n\n      Auto.Arima method\n\n    \n  \n  \n    MAE\n8.652821\n6.428828\n    RMSE\n10.476431\n7.534382\n  \n  \n    \n      Between Manual and Auto ARIMA Method"
  },
  {
    "objectID": "SARIMA.html#d·ª±-ƒëo√°n-s·ªë-ƒë∆°n-h√†ng-trong-18-th√°ng-·ªü-t∆∞∆°ng-lai",
    "href": "SARIMA.html#d·ª±-ƒëo√°n-s·ªë-ƒë∆°n-h√†ng-trong-18-th√°ng-·ªü-t∆∞∆°ng-lai",
    "title": "M√¥ h√¨nh SARIMA",
    "section": "",
    "text": "D∆∞·ªõi ƒë√¢y l√† k·∫øt qu·∫£ d·ª± ƒëo√°n t·ª´ m√¥ h√¨nh trong 3 nƒÉm ti·∫øp theo ~ 18 th√°ng.\n\n\nCode\ndemand_full&lt;-ts(month_df$month_demand,\n                      frequency = 12,\n                      start = c(2012,1))\n\n#Predicting for 18 months with 99.5% range:\npredict_fit&lt;-forecast:::forecast.Arima(model_training3,\n                                       h = 18, \n                                       level = c(99.5)) \n\n#Transform to data.frame object:\ndf&lt;-predict_fit %&gt;% \n  as.data.frame() %&gt;% \n  mutate(Period = seq(max(month_df$datetime),\n                    max(month_df$datetime)+months(18), \n                    by= \"1 month\")[-1]) %&gt;% \n  relocate(Period)\n\n\n\n\nCode\ngt(df[1:9,]) %&gt;% \n  tab_header(\n    title = md(\"**Forecasting Order Demand**\"),\n    subtitle = glue::glue(\"Time from {max(month_df$datetime)} to {max(month_df$datetime)+months(9)}\")) %&gt;%\n   tab_source_note(\n    source_note = glue::glue(\"Method: Model {gt[['model']][1]}\")) %&gt;% \n  gt_theme_538() \ngt(df[10:18,]) %&gt;% \n  tab_header(\n    title = md(\"**Forecasting Order Demand**\"),\n    subtitle = glue::glue(\"Time from {max(month_df$datetime)+months(9)} to {max(month_df$datetime)+months(18)}\")) %&gt;%\n  gt_theme_538() \n#Plot the forecast value\nforecast:::plot.forecast(predict_fit, \n     xlab =\"Time\",\n     ylab = \"Order demand\")\n\n\n\n\n\n\n\n\n  \n    \n      Forecasting Order Demand\n\n    \n    \n      Time from 2016-12-01 to 2017-09-01\n    \n    \n      Period\n      Point Forecast\n      Lo 99.5\n      Hi 99.5\n    \n  \n  \n    2017-01-01\n-0.3025843\n-25.51830\n24.913133\n    2017-02-01\n-9.4633515\n-36.62171\n17.695007\n    2017-03-01\n6.7844395\n-22.34186\n35.910740\n    2017-04-01\n4.8964391\n-26.63581\n36.428686\n    2017-05-01\n-24.2754428\n-55.88982\n7.338937\n    2017-06-01\n18.5468600\n-13.98819\n51.081910\n    2017-07-01\n8.3588213\n-24.30408\n41.021726\n    2017-08-01\n-5.8293675\n-38.81299\n27.154252\n    2017-09-01\n3.9261880\n-29.17795\n37.030330\n  \n  \n    \n      Method: Model ARIMA(2,1,1)(0,1,0)[12]\n    \n  \n  \n\n\n\n\n\n\n\n\n  \n    \n      Forecasting Order Demand\n\n    \n    \n      Time from 2017-09-01 to 2018-06-01\n    \n    \n      Period\n      Point Forecast\n      Lo 99.5\n      Hi 99.5\n    \n  \n  \n    2017-10-01\n10.1401433\n-22.96736\n43.24765\n    2017-11-01\n-13.8715418\n-47.12279\n19.37971\n    2017-12-01\n16.1556198\n-17.09157\n49.40281\n    2018-01-01\n-0.2720208\n-41.40027\n40.85623\n    2018-02-01\n-8.8038655\n-50.82244\n33.21471\n    2018-03-01\n7.2730026\n-35.80101\n50.34702\n    2018-04-01\n5.0611881\n-39.57847\n49.70085\n    2018-05-01\n-23.8592527\n-68.57801\n20.85951\n    2018-06-01\n19.0576303\n-26.14966\n64.26492\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\nV·∫≠y ti·∫øp theo ta s·∫Ω v√†o ph·∫ßn ph√¢n t√≠ch ·ªü trang Machine Learning."
  },
  {
    "objectID": "Forecasting.html",
    "href": "Forecasting.html",
    "title": "M√¥ h√¨nh ARIMA",
    "section": "",
    "text": "D·ªØ li·ªáu th·ªùi gian (time series data) l√† m·ªôt t·∫≠p h·ª£p c√°c quan s√°t ƒë∆∞·ª£c ghi l·∫°i theo th·ªùi gian, ƒë∆∞·ª£c s·∫Øp x·∫øp theo m·ªôt th·ª© t·ª± nh·∫•t ƒë·ªãnh (th∆∞·ªùng theo ng√†y th√°ng). D·ªØ li·ªáu ki·ªÉu n√†y th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n cho t∆∞∆°ng lai v·ªõi √Ω t∆∞·ªüng l√† d·ª±a v√†o c√°c gi√° tr·ªã qu√° kh·ª© ƒë·ªÉ d·ª± ƒëo√°n cho 1 hi·ªán t∆∞·ª£ng, v·∫•n ƒë·ªÅ trong t∆∞∆°ng lai. V√≠ d·ª• b·∫°n c√≥ th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c r·∫±ng: Gi√° c·ªï phi·∫øu ng√†y mai, nhi·ªát ƒë·ªô trung b√¨nh trong tu·∫ßn sau ho·∫∑c th·∫≠m ch√≠ c·∫£ l∆∞·ª£ng m∆∞a t·ª´ng th√°ng trong m·ªôt nƒÉm sau.\nTr∆∞·ªõc ƒë√¢y, d·ªØ li·ªáu th·ªùi gian ch·ªâ g√≥i g·ªçn 2 c·ªôt d·ªØ li·ªáu l√†:\n\nTh·ªùi gian: Th·ªùi ƒëi·ªÉm m√† m·ªói quan s√°t ƒë∆∞·ª£c th·ª±c hi·ªán.\nGi√° tr·ªã: Gi√° tr·ªã ƒëo ƒë∆∞·ª£c t·∫°i th·ªùi ƒëi·ªÉm ƒë√≥.\n\nNh∆∞ng g·∫ßn ƒë√¢y, v·ªõi s·ª± ph√°t tri·ªÉn c·ªßa Machine Learning, d·ªØ li·ªáu th·ªùi gian c√≥ th·ªÉ bao g·ªìm c·∫£ h√¨nh ·∫£nh, th∆∞·ªõc phim,‚Ä¶ V√≠ d·ª• nh∆∞ ·∫£nh ch·ª•p t·ª´ v·ªá tinh Nasa cho th·∫•y s·ª± thay ƒë·ªïi kh√≠ h·∫≠u v√† m√¥i tr∆∞·ªùng.\n\n\n\nH√¨nh 4: ·∫¢nh ch·ª•p t·ª´ Nasa\n\n\nHay v·ªõi 1 th∆∞·ªõc phim v·ªÅ v·∫≠n ƒë·ªông vi√™n b∆°i v·ªõi t·ªëc ƒë·ªô khung h√¨nh FPS 60 nghƒ©a l√† 1s s·∫Ω c√≥ 60 khung h√¨nh th√¨ ta s·∫Ω c√≥ 60 h√¨nh ·∫£nh kh√°c nhau v·ªÅ chuy·ªÉn ƒë·ªông c·ªßa v·∫≠n ƒë·ªông vi√™n trong kho·∫£ng th·ªùi gian 1s. Do ƒë√≥, d·ª±a v√†o th√¥ng tin tr√™n, ta c√≥ th·ªÉ x√¢y d·ª±ng m√¥ h√¨nh v√† d·ª± ƒëo√°n r·∫±ng ti·∫øp theo, v·∫≠n ƒë·ªông vi√™n ƒë√≥ s·∫Ω c·ª≠ ƒë·ªông, v·∫≠n chuy·ªÉn nh∆∞ th·∫ø n√†o.\nNghe r·∫•t tuy·ªát ph·∫£i kh√¥ng !!! ƒêi·ªÅu n√†y ƒë√≤i h·ªèi ph·∫£i c√≥ ki·∫øn th·ª©c n·ªÅn m·∫°nh v·ªÅ Machine Learning n√≥i chung v√† Deep Learning n√≥i ri√™ng. ·ªû b√†i post n√†y, m√¨nh s·∫Ω ch·ªâ t·∫≠p ·ªü vi·ªác ph√¢n t√≠ch d·ªØ li·ªáu v·ªÅ nhu c·∫ßu.\n\n\n\nPh√¢n t√≠ch d·ªØ li·ªáu th·ªùi gian c√≥ th·ªÉ gi√∫p nh·∫≠n di·ªán c√°c xu h∆∞·ªõng, m√πa v·ª• v√† chu k·ª≥, t·ª´ ƒë√≥ h·ªó tr·ª£ ra quy·∫øt ƒë·ªãnh trong nhi·ªÅu lƒ©nh v·ª±c nh∆∞ t√†i ch√≠nh, kinh t·∫ø, kh√≠ t∆∞·ª£ng v√† nhi·ªÅu lƒ©nh v·ª±c kh√°c. V·∫≠y xu h∆∞·ªõng, m√πa v·ª• v√† chu k·ª≥ l√† g√¨:\n\nTrend (Xu h∆∞·ªõng): nghƒ©a l√† ƒë·ªô tƒÉng, gi·∫£m d√†i h·∫°n ho·∫∑c chuy·ªÉn ƒë·ªông ƒë·ª©ng y√™n.\nSeasonal (M√πa v·ª•): l√† m·ªôt pattern trong kho·∫£ng th·ªùi gian nh·∫•t ƒë·ªãnh, th√¥ng th∆∞·ªùng l√† theo nƒÉm ho·∫∑c theo qu√Ω.\nCycle (chu k·ª≥): l√† bi·∫øn ƒë·ªông ƒë∆∞·ª£c l·∫∑p ƒëi l·∫∑p l·∫°i.\nNoise (Sai s·ªë): Sai s·ªë c√≤n s√≥t l·∫°i kh√¥ng gi·∫£i th√≠ch ƒë∆∞·ª£c.\n\nNghe gi·∫£i th√≠ch c√≥ th·ªÉ s·∫Ω l√†m b·∫°n kh√≥ hi·ªÉu, v·∫≠y m√¨nh s·∫Ω minh h·ªça trong R nh∆∞ d∆∞·ªõi ƒë√¢y v·ªõi h√†m decompose():\n\n\nCode\nlibrary(TSstudio)\nDemand&lt;-ts(month_df$month_demand,\n                      frequency = 12,\n                      start = c(2012,1))\n\nts_decompose(Demand, \n             type = \"both\")\n\n\n\n\nKhi m·ª©c ƒë·ªô bi·∫øn ƒë·ªông c·ªßa seasonal ho·∫∑c s·ª± bi·∫øn ƒë·ªïi xung quanh trend-cycle kh√¥ng thay ƒë·ªïi theo m·ª©c ƒë·ªô c·ªßa chu·ªói th·ªùi gian, m√¥ h√¨nh Additive s·∫Ω ph√π h·ª£p h∆°n m√¥ h√¨nh Multiplicative.\n\n\nV·∫≠y m·ª•c ti√™u c·ªßa vi·ªác ph√¢n t√≠ch time series ch√≠nh l√† t√¨m ra th√†nh ph·∫ßn seasonal trong v√¨ n√≥ c√≥ t√≠nh l·∫∑p l·∫°i v√† c√≥ th·ªÉ d√πng ƒë·ªÉ d·ª± ƒëo√°n cho t∆∞∆°ng lai. Ngo√†i ra, th√†nh ph·∫ßn trend c≈©ng c·∫ßn ƒë∆∞·ª£c quan t√¢m v√¨ n√≥ th·ªÉ hi·ªán xu h∆∞·ªõng c·ªßa d·ªØ li·ªáu trong t∆∞∆°ng lai.\nNh√¨n s∆° b·ªô, ta c√≥ th·ªÉ th·∫•y xu h∆∞·ªõng tƒÉng (trend) c·ªßa s·ªë l∆∞·ª£ng ƒë∆°n ƒë·∫∑t h√†ng. V·ªÅ ph·∫ßn random th√¨ s·∫Ω c√≥ 1 kho·∫£ng t·ª´ (-10,5) s·ªë ƒë∆°n l√† t·ª± nhi√™n x·∫£y ra, nghƒ©a l√† gi√° tr·ªã d·ª± ƒëo√°n c√≥ th·ªÉ l·ªách t·ª´ -10 ƒë·∫øn 5 ƒë∆°n h√†ng v√† sai l·ªách n√†y l√† do t·ª± nhi√™n.\n\n\n\n\n\n\nH√†m Decompose()\n\n\n\nV·ªÅ c√¥ng th·ª©c t√≠nh, h√†m decompose() d·ª±a v√†o kƒ© thu·∫≠t Moving Averages ƒë·ªÉ t√≠nh trung b√¨nh gi√° tr·ªã theo 1 kho·∫£ng th·ªùi gian (Vd: 3 th√°ng 6 th√°ng ho·∫∑c 1 nƒÉm).\n\n\nNgo√†i ra, vi·ªác ph√¢n t√°ch chu·ªói d·ªØ li·ªáu tr√™n trong R d·ª±a v√†o c√¥ng th·ª©c t·ª´ 2 m√¥ h√¨nh l√† Additive v√† Multiplicative. ·ªû m·∫∑c ƒë·ªãnh, h√†m decompose() t√≠nh theo m√¥ h√¨nh Additive, c√≤n b·∫°n mu·ªën t√≠nh theo m√¥ h√¨nh Multiplicative th√¨ ph·∫£i th√™m ƒë·ªëi s·ªë type = \"multiplicative\". Vi·ªác l·ª±a ch·ªçn m√¥ h√¨nh s·∫Ω t√πy v√†o nhu c·∫ßu c·ªßa b·∫°n, v√¨ m·ª•c ƒë√≠ch h·ªçc t·∫≠p n√™n m√¨nh tr√¨nh b√†y k·∫øt qu·∫£ t√≠nh to√°n ƒë∆∞·ª£c t·ª´ c·∫£ hai m√¥ h√¨nh.\n\n\n\nH√¨nh 5: Additive and multiplicative model\n\n\n\n\n\nTr√™n th·ª±c t·∫ø, ph·∫ßn ph√¢n t√≠ch c√°c th√†nh ph·∫ßn c·ªßa time series ch·ªâ ƒë∆∞a ra d·ª± ƒëo√°n ƒë·ªãnh t√≠nh, kh√¥ng th·ªÉ d·ª± ƒëo√°n b·∫±ng c√°c d·ªØ li·ªáu tr√™n m√† ph·∫£i c·∫ßn th√¥ng qua m√¥ h√¨nh c·ª• th·ªÉ. V√† d∆∞·ªõi ƒë√¢y l√† gi·ªõi thi·ªáu v·ªÅ m√¥ h√¨nh ARIMA - m·ªôt trong nh·ªØng m√¥ h√¨nh ph·ªï bi·∫øn ƒë∆∞·ª£c s·ª≠ d·ª•ng khi ph√¢n t√≠ch d·ªØ li·ªáu chu·ªói th·ªùi gian.\n\n\nV√†o nƒÉm 1970, hai nh√† khoa h·ªçc George E.P. Box v√† Gwilym M. Jenkins ƒë√£ c√¥ng b·ªë cu·ªën s√°ch ‚ÄúTime Series Analysis: Forecasting and Control‚Äù. Trong cu·ªën s√°ch n√†y, h·ªç gi·ªõi thi·ªáu ph∆∞∆°ng ph√°p ARIMA v√† ph∆∞∆°ng ph√°p ti·∫øp c·∫≠n t·ª´ng b∆∞·ªõc ƒë·ªÉ ph√°t tri·ªÉn m√¥ h√¨nh. Kh√°i ni·ªám ARIMA ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a r√µ r√†ng v√† tr·ªü th√†nh m·ªôt trong nh·ªØng c√¥ng c·ª• ph√¢n t√≠ch chu·ªói th·ªùi gian ch·ªß y·∫øu.\nSau n√†y, nhi·ªÅu nghi√™n c·ª©u ƒë√£ m·ªü r·ªông v√† c·∫£i thi·ªán ph∆∞∆°ng ph√°p n√†y, d·∫´n ƒë·∫øn s·ª± ph√°t tri·ªÉn c·ªßa c√°c bi·∫øn th·ªÉ nh∆∞ SARIMA (Seasonal ARIMA) ƒë·ªÉ x·ª≠ l√Ω c√°c chu·ªói th·ªùi gian c√≥ y·∫øu t·ªë m√πa v·ª•. V√† cho ƒë·∫øn hi·ªán nay, xu h∆∞·ªõng k·∫øt h·ª£p m√¥ h√¨nh ARIMA v·ªõi c√°c ph∆∞∆°ng ph√°p h·ªçc m√°y ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c trong d·ª± ƒëo√°n chu·ªói th·ªùi gian, m·ªü r·ªông kh·∫£ nƒÉng c·ªßa m√¥ h√¨nh n√†y trong vi·ªác x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn v√† ph·ª©c t·∫°p.\n\n\n\nTheo (phamdinhkhanh 2019), M√¥ h√¨nh ARIMA ‚Äús·ª≠ d·ª•ng ƒë·∫ßu v√†o ch√≠nh l√† nh·ªØng t√≠n hi·ªáu qu√° kh·ª© c·ªßa chu·ªói ƒë∆∞·ª£c d·ª± b√°o ƒë·ªÉ d·ª± b√°o n√≥. C√°c t√≠n hi·ªáu ƒë√≥ bao g·ªìm: Chu·ªói t·ª± h·ªìi qui AR (auto regression) v√† chu·ªói trung b√¨nh tr∆∞·ª£t MA (moving average).\nH·∫ßu h·∫øt c√°c chu·ªói th·ªùi gian s·∫Ω c√≥ xu h∆∞·ªõng tƒÉng ho·∫∑c gi·∫£m theo th·ªùi gian, do ƒë√≥ y·∫øu t·ªë chu·ªói d·ª´ng th∆∞·ªùng kh√¥ng ƒë·∫°t ƒë∆∞·ª£c. Trong tr∆∞·ªùng h·ª£p chu·ªói kh√¥ng d·ª´ng th√¨ ta s·∫Ω c·∫ßn bi·∫øn ƒë·ªïi sang chu·ªói d·ª´ng b·∫±ng sai ph√¢n. Khi ƒë√≥ tham s·ªë ƒë·∫∑c tr∆∞ng c·ªßa m√¥ h√¨nh s·∫Ω c√≥ th√™m th√†nh ph·∫ßn b·∫≠c c·ªßa sai ph√¢n d v√† m√¥ h√¨nh ƒë∆∞·ª£c ƒë·∫∑c t·∫£ b·ªüi 3 tham s·ªë ARIMA(p, d, q)‚Äú.\nM√¥ h√¨nh ƒë∆∞·ª£c x√¢y d·ª±ng ‚Äúd·ª±a tr√™n gi·∫£ thuy·∫øt: Stationary series (Chu·ªói d·ª´ng) ƒë√≤i h·ªèi Ph∆∞∆°ng sai sai s·ªë kh√¥ng ƒë·ªïi v√† Nhi·ªÖu tr·∫Øng (White noise), c·ª• th·ªÉ trong ƒë√≥:\n\nStationary series: ƒëi·ªÅu ki·ªán l√† trung b√¨nh c·ªßa chu·ªói l√† constant (b·∫•t bi·∫øn), ph∆∞∆°ng sai (variance) c·ªßa chu·ªói ph·∫£i c√≥ t√≠nh ƒë·ªìng nh·∫•t (homoscedasticity) v√† hi·ªáp ph∆∞∆°ng sai (covariance) gi·ªØa gi√° tr·ªã t v√† t+1 ph·∫£i kh√¥ng li√™n quan t·ªõi nhau.\n\n\n\n\n\n\nL∆∞u √Ω\n\n\n\nN·∫øu chu·ªói d·ªØ li·ªáu kh√¥ng ph·∫£i l√† chu·ªói d√πng th√¨ b·∫°n s·∫Ω kh√¥ng x√¢y d·ª±ng ƒë∆∞·ª£c m√¥ h√¨nh chu·ªói th·ªùi gian (time-series model)\n\n\nNhi·ªÖu tr·∫Øng l√†: m·ªôt th√†nh ph·∫ßn ng·∫´u nhi√™n th·ªÉ hi·ªán cho y·∫øu t·ªë kh√¥ng th·ªÉ d·ª± b√°o c·ªßa model v√† kh√¥ng c√≥ t√≠nh qui lu·∫≠t.\n\n\n\n\nH√¨nh 6: Stationary and non-stationary series"
  },
  {
    "objectID": "Forecasting.html#ph√¢n-t√≠ch-th√†nh-ph·∫ßn-trong-time-series-d·ªØ-li·ªáu",
    "href": "Forecasting.html#ph√¢n-t√≠ch-th√†nh-ph·∫ßn-trong-time-series-d·ªØ-li·ªáu",
    "title": "M√¥ h√¨nh ARIMA",
    "section": "",
    "text": "V·ªÅ th√¥ng tin c·ªßa d·ªØ li·ªáu, ƒë√¢y l√† d·ªØ li·ªáu thu·ªôc d·∫°ng time-series nghƒ©a l√† chu·ªói d·ªØ li·ªáu theo th·ªùi gian n√™n n√≥ s·∫Ω c√≥ c√°c ƒë·∫∑t t√≠nh chung nh∆∞:\n\nTrend: TƒÉng, gi·∫£m d√†i h·∫°n ho·∫∑c chuy·ªÉn ƒë·ªông ƒë·ª©ng y√™n.\nSeasonal: C√°c m√¥ h√¨nh c√≥ th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c ·ªü nh·ªØng kho·∫£ng th·ªùi gian c·ªë ƒë·ªãnh.\nCycle: Bi·∫øn ƒë·ªông kh√¥ng c√≥ chu k·ª≥ nh·∫•t qu√°n.\nNoise: Sai s·ªë c√≤n s√≥t l·∫°i kh√¥ng gi·∫£i th√≠ch ƒë∆∞·ª£c.\n\nV·∫≠y m·ª•c ti√™u c·ªßa vi·ªác ph√¢n t√≠ch time series l√† ƒë·ªÉ t√¨m ra th√†nh ph·∫ßn seasonal trong v√¨ n√≥ c√≥ t√≠nh l·∫∑p l·∫°i v√† c√≥ th·ªÉ d√πng ƒë·ªÉ d·ª± ƒëo√°n cho t∆∞∆°ng lai. Ngo√†i ra, th√†nh ph·∫ßn trend c≈©ng c·∫ßn ƒë∆∞·ª£c quan t√¢m v√¨ n√≥ th·ªÉ hi·ªán xu h∆∞·ªõng c·ªßa d·ªØ li·ªáu trong t∆∞∆°ng lai.\nTrong R, ta c√≥ th·ªÉ ph√¢n t√≠ch d·ªÖ d√†ng v·ªõi h√†m decompose() nh∆∞ code d∆∞·ªõi ƒë√¢y.\nV·ªÅ c√¥ng th·ª©c t√≠nh, h√†m decompose() d·ª±a v√†o kƒ© thu·∫≠t Moving Averages ƒë·ªÉ t√≠nh trung b√¨nh gi√° tr·ªã theo 1 kho·∫£ng th·ªùi gian (Vd: 3 th√°ng 6 th√°ng ho·∫∑c 1 nƒÉm).\n\n\n\nH√¨nh 3: Additive and multiplicative model\n\n\nC√≥ 2 m√¥ h√¨nh g·ªìm Additive v√† Multiplicative c√≥ th·ªÉ s·ª≠ d·ª•ng. ·ªû m·∫∑c ƒë·ªãnh, h√†m decompose() t√≠nh theo m√¥ h√¨nh Additive, c√≤n b·∫°n mu·ªën t√≠nh theo m√¥ h√¨nh Multiplicative th√¨ ph·∫£i th√™m ƒë·ªëi s·ªë type = \"multiplicative\".\n\n\nCode\nlibrary(TSstudio)\nts_decompose(demand_training, \n             type = \"both\")\n\n\n\n\nKhi m·ª©c ƒë·ªô bi·∫øn ƒë·ªông c·ªßa seasonal ho·∫∑c s·ª± bi·∫øn ƒë·ªïi xung quanh trend-cycle kh√¥ng thay ƒë·ªïi theo m·ª©c ƒë·ªô c·ªßa chu·ªói th·ªùi gian, m√¥ h√¨nh Additive s·∫Ω ph√π h·ª£p h∆°n m√¥ h√¨nh Multiplicative.\n\n\nNh√¨n s∆° b·ªô, ta c√≥ th·ªÉ th·∫•y xu h∆∞·ªõng tƒÉng (trend) c·ªßa s·ªë l∆∞·ª£ng ƒë∆°n ƒë·∫∑t h√†ng. V·ªÅ ph·∫ßn random th√¨ s·∫Ω c√≥ 1 kho·∫£ng t·ª´ (-10,5) s·ªë ƒë∆°n l√† t·ª± nhi√™n x·∫£y ra, nghƒ©a l√† gi√° tr·ªã d·ª± ƒëo√°n c√≥ th·ªÉ l·ªách t·ª´ -10 ƒë·∫øn 5 ƒë∆°n h√†ng v√† sai l·ªách n√†y l√† do t·ª± nhi√™n."
  },
  {
    "objectID": "Forecasting.html#d·ª±-ƒëo√°n-b·∫±ng-m√¥-h√¨nh-arima",
    "href": "Forecasting.html#d·ª±-ƒëo√°n-b·∫±ng-m√¥-h√¨nh-arima",
    "title": "M√¥ h√¨nh ARIMA",
    "section": "",
    "text": "Tr√™n th·ª±c t·∫ø, ph·∫ßn ph√¢n t√≠ch th√†nh c√°c th√†nh ph·∫ßn c·ªßa time series ch·ªâ ƒë∆∞a ra d·ª± ƒëo√°n ƒë·ªãnh t√≠nh, kh√¥ng th·ªÉ d·ª± ƒëo√°n b·∫±ng c√°c d·ªØ li·ªáu tr√™n m√† ph·∫£i c·∫ßn th√¥ng qua m√¥ h√¨nh c·ª• th·ªÉ. D∆∞·ªõi ƒë√¢y l√† gi·ªõi thi·ªáu v·ªÅ m√¥ h√¨nh ARIMA.\n\n\nTheo (phamdinhkhanh 2019), M√¥ h√¨nh ARIMA ‚Äús·ª≠ d·ª•ng ƒë·∫ßu v√†o ch√≠nh l√† nh·ªØng t√≠n hi·ªáu qu√° kh·ª© c·ªßa chu·ªói ƒë∆∞·ª£c d·ª± b√°o ƒë·ªÉ d·ª± b√°o n√≥. C√°c t√≠n hi·ªáu ƒë√≥ bao g·ªìm: Chu·ªói t·ª± h·ªìi qui AR (auto regression) v√† chu·ªói trung b√¨nh tr∆∞·ª£t MA (moving average).\nH·∫ßu h·∫øt c√°c chu·ªói th·ªùi gian s·∫Ω c√≥ xu h∆∞·ªõng tƒÉng ho·∫∑c gi·∫£m theo th·ªùi gian, do ƒë√≥ y·∫øu t·ªë chu·ªói d·ª´ng th∆∞·ªùng kh√¥ng ƒë·∫°t ƒë∆∞·ª£c. Trong tr∆∞·ªùng h·ª£p chu·ªói kh√¥ng d·ª´ng th√¨ ta s·∫Ω c·∫ßn bi·∫øn ƒë·ªïi sang chu·ªói d·ª´ng b·∫±ng sai ph√¢n. Khi ƒë√≥ tham s·ªë ƒë·∫∑c tr∆∞ng c·ªßa m√¥ h√¨nh s·∫Ω c√≥ th√™m th√†nh ph·∫ßn b·∫≠c c·ªßa sai ph√¢n d v√† m√¥ h√¨nh ƒë∆∞·ª£c ƒë·∫∑c t·∫£ b·ªüi 3 tham s·ªë ARIMA(p, d, q)‚Äú.\nM√¥ h√¨nh ƒë∆∞·ª£c x√¢y d·ª±ng ‚Äúd·ª±a tr√™n gi·∫£ thuy·∫øt: Stationary series (Chu·ªói d·ª´ng) ƒë√≤i h·ªèi Ph∆∞∆°ng sai sai s·ªë kh√¥ng ƒë·ªïi v√† Nhi·ªÖu tr·∫Øng (White noise), c·ª• th·ªÉ trong ƒë√≥:\n\nStationary series: ƒëi·ªÅu ki·ªán l√† trung b√¨nh c·ªßa chu·ªói l√† constant (b·∫•t bi·∫øn), ph∆∞∆°ng sai (variance) c·ªßa chu·ªói ph·∫£i c√≥ t√≠nh ƒë·ªìng nh·∫•t (homoscedasticity) v√† hi·ªáp ph∆∞∆°ng sai (covariance) gi·ªØa gi√° tr·ªã t v√† t+1 ph·∫£i kh√¥ng li√™n quan t·ªõi nhau.\n\n\n\n\n\n\nL∆∞u √Ω\n\n\n\nN·∫øu chu·ªói d·ªØ li·ªáu kh√¥ng ph·∫£i l√† chu·ªói d√πng th√¨ b·∫°n s·∫Ω kh√¥ng x√¢y d·ª±ng ƒë∆∞·ª£c m√¥ h√¨nh chu·ªói th·ªùi gian (time-series model)\n\n\nNhi·ªÖu tr·∫Øng l√†: m·ªôt th√†nh ph·∫ßn ng·∫´u nhi√™n th·ªÉ hi·ªán cho y·∫øu t·ªë kh√¥ng th·ªÉ d·ª± b√°o c·ªßa model v√† kh√¥ng c√≥ t√≠nh qui lu·∫≠t.\n\n\n\n\nH√¨nh 4: Stationary and non-stationary series\n\n\n\n\n\n\n\nV√† ƒë·ªÉ th·ªèa m√£n gi·∫£ ƒë·ªãnh n√†y, c·∫ßn t√≠nh to√°n c√°c ch·ªâ s·ªë tr√™n v√† ƒë√°nh gi√° v√† ƒëi·ªÅu n√†y kh√° ph·ª©c t·∫°p. Trong R, ta c√≥ h√†m adf.test() c√≥ th·ªÉ ki·ªÉm tra v·∫•n ƒë·ªÅ n√†y nhanh h∆°n.\n\n\nCode\nlibrary(tseries)\nadf.test(demand_training)    ## p-value = 0.3779 &gt; 0.05 means this series is not stationary\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  demand_training\nDickey-Fuller = -2.4991, Lag order = 3, p-value = 0.3779\nalternative hypothesis: stationary\n\n\nNh∆∞ v·∫≠y, ta th·∫•y chu·ªói d·ªØ li·ªáu n√†y kh√¥ng ph·∫£i chu·ªói d·ª´ng v√¨ gi√° tr·ªã p = 0.3779 &gt; 0.05 nghƒ©a l√† ch·∫•p nh·∫≠n gi·∫£ thuy·∫øt H0: Chu·ªói n√†y l√† chu·ªói kh√¥ng d·ª´ng.\nTrong time-series analyst, ta s·∫Ω c√≥ c√°ch ƒë·ªÉ x·ª≠ l√≠ chu·ªói th√†nh chu·ªói d·ª´ng. ƒê√≥ l√† t√≠nh s·ª± kh√°c nhau (Difference) gi·ªØa gi√° tr·ªã t v√† gi√° tr·ªã c·ªßa n√≥ ·ªü qu√° kh·ª© t-1,t-2,‚Ä¶\nTrong R, b·∫°n c√≥ th·ªÉ t√≠nh b·∫±ng c√°ch:\n\ndiff(series, lag = n): t√≠nh s·ª± kh√°c nhau gi·ªØa c√°c th·ªùi ƒëi·ªÉm t v√† t-n.\nlog(series): chuy·ªÉn time-series sang d·∫°ng log.\n\nN√†y t√πy thu·ªôc v√†o c√¥ng th·ª©c to√°n h·ªçc b·∫°n mu·ªën ƒë·ªãnh nghƒ©a, mi·ªÖn sao b·∫°n c√≥ th·ªÉ x√°c ƒë·ªãnh ƒë∆∞·ª£c chu·ªói d·ª´ng l√† ƒë·∫°t.\n\n\nCode\n#First we will calculate the different in demand product monthly:\n#Check stationary assumption:\ntest&lt;-lapply(1:3, function(x) {\n         a&lt;-diff(demand_training, lag = x)\n         adf.test(a)$p.value}\n       ) #p&lt;0,05 is accepted\n\n## Second transform it to dataframe object:\ntest&lt;-data.frame(test)\ncolnames(test)&lt;-c(\"Lag 1\",\"Lag 2\",\"Lag 3\")\n\n## Finally plot the result:\nlibrary(gt)\nlibrary(gtExtras)\ngt(test) %&gt;% \n  cols_align(\n    align = \"left\",\n    columns = \"Lag 1\"\n  ) %&gt;% \n  cols_align(\n    align = \"center\",\n    columns = \"Lag 2\"\n  ) %&gt;%\n   tab_header(\n    title = md(\"**Checking stationary assumption**\"),\n    subtitle = glue::glue(\"Time from {min(month_df$datetime)} to 01-03-2015\")) %&gt;%\n   tab_source_note(\n    source_note = \"Alternative hypothesis: stationary\") %&gt;% \n  gt_theme_538()\n\n\n\n\n\n\n  \n    \n      Checking stationary assumption\n\n    \n    \n      Time from 2012-01-01 to 01-03-2015\n    \n    \n      Lag 1\n      Lag 2\n      Lag 3\n    \n  \n  \n    0.01\n0.01\n0.152641\n  \n  \n    \n      Alternative hypothesis: stationary\n    \n  \n  \n\n\n\n\nK·∫øt qu·∫£ testing cho th·∫•y ch·ªâ c√≥ chu·ªói 1 v√† 2 ƒë·∫°t y√™u c·∫ßu, chu·ªói 3 kh√¥ng ph·∫£i chu·ªói d·ª´ng v√¨ p-value = 0.107 &gt; 0.05.\n\n\n\n\n\nPACF (Partial Autocorrelation Function) v√† ACF (Autocorrelation Function) l√† 2 c√¥ng th·ª©c t√≠nh thu·ªôc Autocorrelation Analyst - 1 b∆∞·ªõc quan tr·ªçng trong vi·ªác ph√¢n t√≠ch chu·ªói d·ªØ li·ªáu th·ªùi gian. M·ª•c ti√™u c·ªßa Autocorrelation analyst l√† t√¨m ra c√°c m·∫´u (pattern) gi·ªØa nhi·ªÅu chu·ªói th·ªùi gian v√† ki·ªÉm tra t√≠nh ng·∫´u nhi√™n.\n\n\n\nSau khi ƒë√£ x√°c ƒë·ªãnh ƒë∆∞·ª£c chu·ªói d·ª´ng, b∆∞·ªõc ti·∫øp theo l√† x√°c ƒë·ªãnh c√°c tham s·ªë (p, d, q) cho m√¥ h√¨nh ARIMA.\nTrong R c√≥ h√†m ggtsdisplay c·ªßa package forecast s·∫Ω hi·ªÉn th·ªã c·∫£ ACF, PACF v√† Time series plot c·ªßa ƒë·ªëi t∆∞·ª£ng m√† b·∫°n g√°n. C√≤n n·∫øu b·∫°n mu·ªën hi·ªÉn th·ªã ri√™ng gi√° tr·ªã ACF ho·∫∑c PACF th√¨ d√πng h√†m Acf ho·∫∑c Pacf ƒë·ªÉ t√≠nh v√† d√πng h√†m autoplot() ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì.\n\n\nCode\n#Rename of two time series:\nts1&lt;-diff(demand_training, lag = 1)\nts2&lt;-diff(demand_training, lag = 2)\n#Plot value ACF for 2 series:\nlibrary(forecast)\nggtsdisplay(ts1,\n            main = \"Time series lag 1\",\n            theme=theme_bw())\nggtsdisplay(ts2,\n            main = \"Time series lag 2\",\n            theme=theme_bw())\n\n\n\n\n\n\n\n\n\n\n\n\nD·ª±a v√†o tricks t·ª´ (Tavish Srivastava 2023), ta s·∫Ω d·ª±a v√†o gi√° tr·ªã PACF ƒë·ªÉ x√°c ƒë·ªãnh b·∫≠c c·ªßa AR v√† ACF ƒë·ªÉ x√°c ƒë·ªãnh b·∫≠c c·ªßa MA.\nV√≠ d·ª• ·ªü tr√™n, ƒë·ªëi v·ªõi chu·ªói lag 1, gi√° tr·ªã PACF c√≥ s·ª± ƒë·ª©t g√£y (cut off) ·ªü b·∫≠c 2 ƒë·∫øn b·∫≠c 3 n√™n c√≥ th·ªÉ thu·ªôc AR(3). C√≤n gi√° tr·ªã ACF th√¨ c√≥ th·ªÉ thu·ªôc MA(2) ho·∫∑c r√µ r√†ng h∆°n l√† MA(3). C√≤n l·∫°i, ƒë·ªëi v·ªõi chu·ªói lag 2, c√°c b·∫°n c√≥ th·ªÉ l√†m t∆∞∆°ng t·ª±.\nV·∫≠y m√¥ h√¨nh t·ª± ch·ªçn cu·ªëi c√πng l√† ARIMA(3,0,2).\n\n\n\n\nTh·ª±c t·∫ø, trong R c√≥ h√†m auto.arimaƒë·ªÉ ch√∫ng ta l·ª±a ch·ªçn v√† so s√°nh nhi·ªÅu m√¥ h√¨nh ARIMA m·ªôt c√°ch t·ª± ƒë·ªông v√† kh√¥ng n·∫∑ng v·ªÅ code nh∆∞ d∆∞·ªõi ƒë√¢y. N√≥ s·∫Ω t·ª± li·ªát k√™ ra c√°c m√¥ h√¨nh ph√π h·ª£p v√† ch·ªçn ra m√¥ h√¨nh t·ªët nh·∫•t.\nNgo√†i ra, n·∫øu b·∫°n mu·ªën t√¨m hi·ªÉu s√¢u v·ªÅ c√°ch x√¢y d·ª±ng m√¥ h√¨nh ARIMA, b·∫°n c√≥ th·ªÉ tham kh·∫£o th√™m b√†i blog (D≈©ng, n.d.). Anh Ch√≠ D≈©ng c√≥ kh√° nhi·ªÅu b√†i vi·∫øt hay v·ªÅ c√°ch s·ª≠ d·ª•ng R trong nghi√™n c·ª©u v√† ph√¢n t√≠ch kinh t·∫ø, b·∫°n c√≥ th·ªÉ tham kh·∫£o trang blog c·ªßa ·∫£nh th√¥ng qua ƒë∆∞·ªùng link chidungkt.\n\n\nCode\n#Select the best model:\nmodel&lt;-auto.arima(ts1,trace = T)\n\n\n\n ARIMA(2,0,2)(1,0,1)[12] with non-zero mean : 279.6301\n ARIMA(0,0,0)            with non-zero mean : 291.5234\n ARIMA(1,0,0)(1,0,0)[12] with non-zero mean : 285.1005\n ARIMA(0,0,1)(0,0,1)[12] with non-zero mean : Inf\n ARIMA(0,0,0)            with zero mean     : 289.5102\n ARIMA(2,0,2)(0,0,1)[12] with non-zero mean : 278.2485\n ARIMA(2,0,2)            with non-zero mean : 276.6431\n ARIMA(2,0,2)(1,0,0)[12] with non-zero mean : 277.2391\n ARIMA(1,0,2)            with non-zero mean : Inf\n ARIMA(2,0,1)            with non-zero mean : 274.6588\n ARIMA(2,0,1)(1,0,0)[12] with non-zero mean : 274.4807\n ARIMA(2,0,1)(1,0,1)[12] with non-zero mean : 276.6914\n ARIMA(2,0,1)(0,0,1)[12] with non-zero mean : 275.6882\n ARIMA(1,0,1)(1,0,0)[12] with non-zero mean : Inf\n ARIMA(2,0,0)(1,0,0)[12] with non-zero mean : 271.6811\n ARIMA(2,0,0)            with non-zero mean : 272.1458\n ARIMA(2,0,0)(1,0,1)[12] with non-zero mean : 273.7323\n ARIMA(2,0,0)(0,0,1)[12] with non-zero mean : 272.8549\n ARIMA(3,0,0)(1,0,0)[12] with non-zero mean : 274.4922\n ARIMA(3,0,1)(1,0,0)[12] with non-zero mean : 277.4715\n ARIMA(2,0,0)(1,0,0)[12] with zero mean     : 269.4654\n ARIMA(2,0,0)            with zero mean     : 270.5103\n ARIMA(2,0,0)(1,0,1)[12] with zero mean     : 271.365\n ARIMA(2,0,0)(0,0,1)[12] with zero mean     : 270.7772\n ARIMA(1,0,0)(1,0,0)[12] with zero mean     : 282.7531\n ARIMA(3,0,0)(1,0,0)[12] with zero mean     : 272.0724\n ARIMA(2,0,1)(1,0,0)[12] with zero mean     : 272.0509\n ARIMA(1,0,1)(1,0,0)[12] with zero mean     : 275.1242\n ARIMA(3,0,1)(1,0,0)[12] with zero mean     : 274.8562\n\n Best model: ARIMA(2,0,0)(1,0,0)[12] with zero mean     \n\n\n\n\n\nSau khi ƒë√£ x√¢y d·ª±ng m√¥ h√¨nh, ta s·∫Ω d√πng n√≥ ƒë·ªÉ d·ª± ƒëo√°n v√† so s√°nh v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ b·ªô d·ªØ li·ªáu testing data.\n\n\nCode\n#Forecast by training model:\ntraining_forecast&lt;-forecast(model,h = 21)\n\n\nB·∫£ng tr√¨nh b√†y c√°c gi√° tr·ªã d·ª± ƒëo√°n theo t·ª´ng th√°ng. Ta th·∫•y ch·ªâ c√≥ 4/21 th·ªùi ƒëi·ªÉm m√† gi√° tr·ªã th·ª±c t·∫ø v∆∞·ª£t ra gi√° tr·ªã d·ª± ƒëo√°n trong kho·∫£ng tin c·∫≠y 80%. C√≤n ƒë·ªëi v·ªõi gi√° tr·ªã d·ª± ƒëo√°n trong kho·∫£ng tin c·∫≠y 95% th√¨ ƒë·ªÅu ƒë·∫°t y√™u c·∫ßu.\n\n\nCode\n#Calculate RMSE:\nactual&lt;- diff(demand_testing,1)\n\naccuracy&lt;-data_frame(Period = paste(month(testing_df$datetime),\n                                    year(testing_df$datetime),\n                                    sep = \"/\")[-1],\n                     Actual = actual %&gt;% as.vector(), \n                     High.80 = training_forecast$upper[,1],\n                     Low.80 = training_forecast$lower[,1],\n                     High.95 = training_forecast$upper[,2],\n                     Low.95 = training_forecast$lower[,2]) %&gt;% \n  mutate(Check.80 = ifelse(Actual &lt;= High.80 & Actual &gt;= Low.80,\"Pass\",\"Fail\"),\n         Check.95 = ifelse(Actual &lt;= High.95 & Actual &gt;= Low.95,\"Pass\",\"Fail\"))\n\n## Finally plot the result\ngt(accuracy) %&gt;% \n   tab_header(\n    title = md(\"**Comparing the accuracy of forecasting**\"),\n    subtitle = glue::glue(\"Forecasting from {min(testing_df$datetime)} to {max(testing_df$datetime)}\")) %&gt;%\n   tab_source_note(\n    source_note = str_glue(\"Method: Model {training_forecast$method}\")) %&gt;% \n  gt_theme_538() %&gt;% \n   data_color(\n    columns = Check.80,\n    method = \"factor\",\n    palette = c(\"red\",\"darkgreen\")\n  ) %&gt;% data_color(\n    columns = Check.95,\n    method = \"factor\",\n    palette = c(\"darkgreen\",\"red\")\n  ) \n\n\n\n\n\n\n  \n    \n      Comparing the accuracy of forecasting\n\n    \n    \n      Forecasting from 2015-03-01 to 2016-12-01\n    \n    \n      Period\n      Actual\n      High.80\n      Low.80\n      High.95\n      Low.95\n      Check.80\n      Check.95\n    \n  \n  \n    4/2015\n-11.157\n8.2151971\n-10.812921\n13.251636\n-15.84936\nFail\nPass\n    5/2015\n-12.621\n1.6260371\n-20.888910\n7.585384\n-26.84826\nPass\nPass\n    6/2015\n13.813\n18.5336717\n-4.315841\n24.581572\n-10.36374\nPass\nPass\n    7/2015\n8.293\n14.9318430\n-9.908314\n21.506636\n-16.48311\nPass\nPass\n    8/2015\n-20.715\n-0.7494574\n-25.879586\n5.902086\n-32.53113\nPass\nPass\n    9/2015\n4.671\n21.7271249\n-3.643527\n28.442331\n-10.35873\nPass\nPass\n    10/2015\n1.452\n17.1916812\n-8.576132\n24.012009\n-15.39646\nPass\nPass\n    11/2015\n-8.055\n8.5209607\n-17.257552\n15.344121\n-24.08071\nPass\nPass\n    12/2015\n8.132\n14.8015863\n-11.075451\n21.650824\n-17.92469\nPass\nPass\n    1/2016\n-9.978\n17.8052582\n-8.139698\n24.672473\n-15.00691\nFail\nPass\n    2/2016\n-4.696\n6.4211445\n-19.524421\n13.288521\n-26.39180\nPass\nPass\n    3/2016\n19.274\n19.2007071\n-6.774814\n26.076012\n-13.65012\nFail\nPass\n    4/2016\n-14.336\n13.5655001\n-13.694775\n20.780859\n-20.91013\nFail\nPass\n    5/2016\n0.513\n9.7760700\n-17.849339\n17.088074\n-25.16134\nPass\nPass\n    6/2016\n2.751\n16.5398455\n-11.170685\n23.874380\n-18.50522\nPass\nPass\n    7/2016\n6.377\n15.2198557\n-12.789469\n22.633476\n-20.20309\nPass\nPass\n    8/2016\n-8.324\n8.6649731\n-19.373047\n16.086189\n-26.79426\nPass\nPass\n    9/2016\n-2.439\n17.5484745\n-10.538978\n24.982774\n-17.97328\nPass\nPass\n    10/2016\n6.244\n15.8818767\n-12.264517\n23.331777\n-19.71442\nPass\nPass\n    11/2016\n5.996\n12.3351533\n-15.811609\n19.785151\n-23.26161\nPass\nPass\n    12/2016\n-9.544\n14.7681518\n-13.396724\n22.222944\n-20.85152\nPass\nPass\n  \n  \n    \n      Method: Model ARIMA(2,0,0)(1,0,0)[12] with zero mean\n    \n  \n  \n\n\n\n\nV√† d∆∞·ªõi ƒë√¢y l√† bi·ªÉu ƒë·ªì hi·ªÉn th·ªã gi√° tr·ªã trung b√¨nh (ƒë∆∞·ªùng m√†u xanh d∆∞∆°ng), gi√° tr·ªã d·ª± ƒëo√°n trong kho·∫£ng tin c·∫≠y 80% (ƒë∆∞·ªùng m√†u x√°m ƒë·∫≠m) v√† kho·∫£ng tin c·∫≠y 95% (ƒë∆∞·ªùng m√†u x√°m nh·∫°t).\nNgo√†i ra ta c≈©ng t√≠nh c√°c ch·ªâ s·ªë MAE v√† RMSE c·ªßa m√¥ h√¨nh nh∆∞ sau:\n\n\nCode\n## Calculating MAE metric:\nsum = 0\nfor (i in 1:nrow(accuracy)){ \n  sum = abs(accuracy$Actual[i]-training_forecast$mean[i]) + sum\n} \n\nMAE = sum/nrow(accuracy) \n\n## Calculating RMSE metric:\nRMSE= sqrt(mean((accuracy$Actual - training_forecast$mean)^2))\n\n\n\n\nCode\n#Use chart for presenting the differents:\nplot(training_forecast,\n      main = str_glue(\"Method: Model {training_forecast$method}\"),\n      xlab = \"Time\",\n      ylab = \"Order Demand\")\nlines(actual, \n      col = \"red\",\n      lwd = \"2\")\nlegend(\"topleft\",\n       legend = c(\"Actual\",\"Forecast\"),\n       col = c(\"red\",\"blue\"),\n       box.lty = 0,\n       lty = 1,\n       cex = 1,\n       lwd = 2)\n\n\n\n\n\nTa th·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n c≈©ng ·ªïn nh∆∞ng v·∫´n ch∆∞a b√°m s√°t th·ª±c t·∫ø. V√¨ v·∫≠y ti·∫øp theo ch√∫ng ta s·∫Ω l√†m cho m√¥ h√¨nh t·ªët h∆°n ·ªü trang sau M√¥ h√¨nh SARIMA"
  },
  {
    "objectID": "index.html#v√¨-sao-c·∫ßn-planning",
    "href": "index.html#v√¨-sao-c·∫ßn-planning",
    "title": "Gi·ªõi thi·ªáu",
    "section": "",
    "text": "V·∫≠y l√†m sao ƒë·ªÉ l√†m m·ªôt Planner t·ªët trong qu·∫£n l√Ω chu·ªói cung ·ª©ng ? Gi·∫£ s·ª≠ b·∫°n ƒëang l√† ng∆∞·ªùi qu·∫£n l√Ω c·ª≠a h√†ng v·ªÅ ƒë·ªì ch∆°i tr·∫ª em, b·∫°n s·∫Ω c·∫ßn l√™n k·∫ø ho·∫°ch nh·∫≠p kho t·ª´ng lo·∫°i ƒë·ªì ch∆°i ƒë·ªÉ tr√°nh vi·ªác outstock h√†ng tr√™n kho v√† b·∫°n c·∫ßn ph·∫£i bi·∫øt c√¢n ƒë·ªëi s·ªë l∆∞·ª£ng gi·ªØa c√°c lo·∫°i m·∫∑t h√†ng - m·∫∑t h√†ng n√†o b√°n ch·∫°y th√¨ nh·∫≠p nhi·ªÅu, m·∫∑t h√†ng n√†o c√≤n t·ªìn kho th√¨ c√≥ th·ªÉ t·∫°o ch∆∞∆°ng tr√¨nh gi·∫£m gi√° ho·∫∑c l√†m qu√† t·∫∑ng‚Ä¶). ƒê·ªÉ l√†m ƒë∆∞·ª£c ƒëi·ªÅu n√†y, b·∫°n kh√¥ng th·ªÉ ch·ªâ quy·∫øt ƒë·ªãnh b·∫±ng c·∫£m t√≠nh m√† c·∫ßn c√°c c√¥ng c·ª• ƒëo l∆∞·ªùng hi·ªáu qu·∫£ v√† ph√π h·ª£p v·ªõi c√¥ng ty c·ªßa b·∫°n.\nV√≠ d·ª•, trong th√°ng 10, c·ª≠a h√†ng c·ª≠a b·∫°n v·∫´n c√≤n 10 ƒë·ªì ch∆°i A v√† kh√°ch h√†ng c·∫ßn mua t·ªõi 15 ƒë·ªì ch∆°i v√† th·ªùi gian v·∫≠n chuy·ªÉn nh·∫≠p kho trung b√¨nh l√† 10 ng√†y. V√¨ v·∫≠y, tr∆∞·ªõc th√°ng 10, b·∫°n c·∫ßn l√™n ƒë∆°n ƒë·∫∑t h√†ng cho b√™n supplier ƒë·ªÉ m√¨nh nh·∫≠p kho k·ªãp l√∫c v√† tr∆∞ng b√†y h√†ng tr√™n k·ªá. Nghe vi·ªác n√†y c√≥ v·∫ª d·ªÖ ƒë√∫ng kh√¥ng nh∆∞ng ƒëi·ªÅu ƒë√≥ ch·ªâ d·ªÖ khi b·∫°n bi·∫øt tr∆∞·ªõc ƒë∆∞·ª£c t∆∞∆°ng lai r·∫±ng kh√°ch h√†ng c·ªßa b·∫°n s·∫Ω mua 15 m√≥n ƒë·ªì ch∆°i trong th√°ng 10. V·∫≠y l√†m sao ƒë·ªÉ d·ª± ƒëo√°n ch√≠nh x√°c ƒë∆∞·ª£c th√¨ ƒë√≥ l√† c√¥ng d·ª•ng c·ªßa demand planning.\n\n\nTh·ª±c ch·∫•t demand planning ch·ªâ l√† 1 ph·∫ßn nh·ªè gi·ªØa nhi·ªÅu ho·∫°t ƒë·ªông planning kh√°c nhau trong qu√° tr√¨nh qu·∫£n l√Ω chu·ªói cung ·ª©ng nh∆∞ng l·∫°i ƒë√≥ng vai tr√≤ quan tr·ªçng nh·∫•t. Nh∆∞ nghi√™n c·ª©u d∆∞·ªõi ƒë√¢y c·ªßa (Natalia Szozda and Sylwia Werbi≈Ñska-Wojciechowska2 2013) , n√≥ ƒë∆∞·ª£c xem th√¥ng tin ƒë·∫ßu v√†o cho doanh nghi·ªáp v√† d·ª±a v√†o ƒë√≥, c√°c ph√≤ng ban trong doanh nghi·ªáp nh∆∞ ph√≤ng thu mua s·∫Ω l√™n k·∫ø ho·∫°ch v·ªÅ s·ªë l∆∞·ª£ng nguy√™n v·∫≠t li·ªáu c·∫ßn mua, ph√≤ng s·∫£n xu·∫•t s·∫Ω x√¢y d·ª±ng k·∫ø ho·∫°ch s·∫£n xu·∫•t, ƒë∆°n v·ªã v·∫≠n chuy·ªÉn s·∫Ω l√™n l·ªãch tr√¨nh ph√¢n ph·ªëi h√†ng h√≥a cho t·ª´ng nh√† kho, t·ª´ng c·ª≠a h√†ng kh√°c nhau.\n\n\n\nH√¨nh 3: Vai tr√≤ c·ªßa Demand Planning trong doanh nghi·ªáp\n\n\nDo ƒë√≥, b·∫°n c√≥ th·ªÉ th·∫•y th√¥ng tin ƒë∆∞·ª£c d·ª± ƒëo√°n t·ª´ demand planning s·∫Ω l√†m n·ªÅn t·∫£ng hay d·ªØ li·ªáu ƒë·∫ßu v√†o cho r·∫•t nhi·ªÅu k·∫ø ho·∫°ch ho·∫°t ƒë·ªông trong c√¥ng ty, doanh nghi·ªáp. V√¨ v·∫≠y, ƒë·ªÉ ƒë·∫£m b·∫£o ƒë∆∞·ª£c ƒë·ªô ch√≠nh x√°c, b·∫°n c·∫ßn thu th·∫≠p d·ªØ li·ªáu t·ª´ nhi·ªÅu ngu·ªìn ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n.\nƒê·ªëi v·ªõi d·ªØ li·ªáu chu·ªói th·ªùi gian, c√°c m√¥ h√¨nh d·ª± ƒëo√°n th√¥ng th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng nh∆∞ l√†:\n\nCho th·ªùi gian ng·∫Øn h·∫°n (T·ª´ 1 ƒë·∫øn 3 th√°ng): ETS, MA (Moving Average), AR (Autoregressive).\nCho th·ªùi gian d√†i h·∫°n: ARIMA, SARIMA hay SARIMAX.\nCho th·ªùi gian d√†i h·∫°n v√† d·ªØ li·ªáu ƒëa d·∫°ng ph·ª©c t·∫°p: c√°c m√¥ h√¨nh thu·∫ßn v·ªÅ h·ªçc m√°y nh∆∞ RNN, Deap Learning,‚Ä¶ s·∫Ω l√†m t·ªët h∆°n m√¥ h√¨nh truy·ªÅn th·ªëng.\n\nV·∫≠y th√¨ trong b√†i n√†y ch√∫ng ta s·∫Ω h·ªçc ƒë·∫ßu ti√™n v·ªÅ m√¥ h√¨nh ARIMA."
  },
  {
    "objectID": "Forecasting.html#gi·ªõi-thi·ªáu-d·ªØ-li·ªáu-th·ªùi-gian",
    "href": "Forecasting.html#gi·ªõi-thi·ªáu-d·ªØ-li·ªáu-th·ªùi-gian",
    "title": "M√¥ h√¨nh ARIMA",
    "section": "",
    "text": "D·ªØ li·ªáu th·ªùi gian (time series data) l√† m·ªôt t·∫≠p h·ª£p c√°c quan s√°t ƒë∆∞·ª£c ghi l·∫°i theo th·ªùi gian, ƒë∆∞·ª£c s·∫Øp x·∫øp theo m·ªôt th·ª© t·ª± nh·∫•t ƒë·ªãnh (th∆∞·ªùng theo ng√†y th√°ng). D·ªØ li·ªáu ki·ªÉu n√†y th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n cho t∆∞∆°ng lai v·ªõi √Ω t∆∞·ªüng l√† d·ª±a v√†o c√°c gi√° tr·ªã qu√° kh·ª© ƒë·ªÉ d·ª± ƒëo√°n cho 1 hi·ªán t∆∞·ª£ng, v·∫•n ƒë·ªÅ trong t∆∞∆°ng lai. V√≠ d·ª• b·∫°n c√≥ th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c r·∫±ng: Gi√° c·ªï phi·∫øu ng√†y mai, nhi·ªát ƒë·ªô trung b√¨nh trong tu·∫ßn sau ho·∫∑c th·∫≠m ch√≠ c·∫£ l∆∞·ª£ng m∆∞a t·ª´ng th√°ng trong m·ªôt nƒÉm sau.\nTr∆∞·ªõc ƒë√¢y, d·ªØ li·ªáu th·ªùi gian ch·ªâ g√≥i g·ªçn 2 c·ªôt d·ªØ li·ªáu l√†:\n\nTh·ªùi gian: Th·ªùi ƒëi·ªÉm m√† m·ªói quan s√°t ƒë∆∞·ª£c th·ª±c hi·ªán.\nGi√° tr·ªã: Gi√° tr·ªã ƒëo ƒë∆∞·ª£c t·∫°i th·ªùi ƒëi·ªÉm ƒë√≥.\n\nNh∆∞ng g·∫ßn ƒë√¢y, v·ªõi s·ª± ph√°t tri·ªÉn c·ªßa Machine Learning, d·ªØ li·ªáu th·ªùi gian c√≥ th·ªÉ bao g·ªìm c·∫£ h√¨nh ·∫£nh, th∆∞·ªõc phim,‚Ä¶ V√≠ d·ª• nh∆∞ ·∫£nh ch·ª•p t·ª´ v·ªá tinh Nasa cho th·∫•y s·ª± thay ƒë·ªïi kh√≠ h·∫≠u v√† m√¥i tr∆∞·ªùng.\n\n\n\nH√¨nh 4: ·∫¢nh ch·ª•p t·ª´ Nasa\n\n\nHay v·ªõi 1 th∆∞·ªõc phim v·ªÅ v·∫≠n ƒë·ªông vi√™n b∆°i v·ªõi t·ªëc ƒë·ªô khung h√¨nh FPS 60 nghƒ©a l√† 1s s·∫Ω c√≥ 60 khung h√¨nh th√¨ ta s·∫Ω c√≥ 60 h√¨nh ·∫£nh kh√°c nhau v·ªÅ chuy·ªÉn ƒë·ªông c·ªßa v·∫≠n ƒë·ªông vi√™n trong kho·∫£ng th·ªùi gian 1s. Do ƒë√≥, d·ª±a v√†o th√¥ng tin tr√™n, ta c√≥ th·ªÉ x√¢y d·ª±ng m√¥ h√¨nh v√† d·ª± ƒëo√°n r·∫±ng ti·∫øp theo, v·∫≠n ƒë·ªông vi√™n ƒë√≥ s·∫Ω c·ª≠ ƒë·ªông, v·∫≠n chuy·ªÉn nh∆∞ th·∫ø n√†o.\nNghe r·∫•t tuy·ªát ph·∫£i kh√¥ng !!! ƒêi·ªÅu n√†y ƒë√≤i h·ªèi ph·∫£i c√≥ ki·∫øn th·ª©c n·ªÅn m·∫°nh v·ªÅ Machine Learning n√≥i chung v√† Deep Learning n√≥i ri√™ng. ·ªû b√†i post n√†y, m√¨nh s·∫Ω ch·ªâ t·∫≠p ·ªü vi·ªác ph√¢n t√≠ch d·ªØ li·ªáu v·ªÅ nhu c·∫ßu."
  },
  {
    "objectID": "Forecasting.html#ph√¢n-t√≠ch-d·ªØ-li·ªáu-th·ªùi-gian",
    "href": "Forecasting.html#ph√¢n-t√≠ch-d·ªØ-li·ªáu-th·ªùi-gian",
    "title": "M√¥ h√¨nh ARIMA",
    "section": "",
    "text": "Ph√¢n t√≠ch d·ªØ li·ªáu th·ªùi gian c√≥ th·ªÉ gi√∫p nh·∫≠n di·ªán c√°c xu h∆∞·ªõng, m√πa v·ª• v√† chu k·ª≥, t·ª´ ƒë√≥ h·ªó tr·ª£ ra quy·∫øt ƒë·ªãnh trong nhi·ªÅu lƒ©nh v·ª±c nh∆∞ t√†i ch√≠nh, kinh t·∫ø, kh√≠ t∆∞·ª£ng v√† nhi·ªÅu lƒ©nh v·ª±c kh√°c. V·∫≠y xu h∆∞·ªõng, m√πa v·ª• v√† chu k·ª≥ l√† g√¨:\n\nTrend (Xu h∆∞·ªõng): nghƒ©a l√† ƒë·ªô tƒÉng, gi·∫£m d√†i h·∫°n ho·∫∑c chuy·ªÉn ƒë·ªông ƒë·ª©ng y√™n.\nSeasonal (M√πa v·ª•): l√† m·ªôt pattern trong kho·∫£ng th·ªùi gian nh·∫•t ƒë·ªãnh, th√¥ng th∆∞·ªùng l√† theo nƒÉm ho·∫∑c theo qu√Ω.\nCycle (chu k·ª≥): l√† bi·∫øn ƒë·ªông ƒë∆∞·ª£c l·∫∑p ƒëi l·∫∑p l·∫°i.\nNoise (Sai s·ªë): Sai s·ªë c√≤n s√≥t l·∫°i kh√¥ng gi·∫£i th√≠ch ƒë∆∞·ª£c.\n\nNghe gi·∫£i th√≠ch c√≥ th·ªÉ s·∫Ω l√†m b·∫°n kh√≥ hi·ªÉu, v·∫≠y m√¨nh s·∫Ω minh h·ªça trong R nh∆∞ d∆∞·ªõi ƒë√¢y v·ªõi h√†m decompose():\n\n\nCode\nlibrary(TSstudio)\nDemand&lt;-ts(month_df$month_demand,\n                      frequency = 12,\n                      start = c(2012,1))\n\nts_decompose(Demand, \n             type = \"both\")\n\n\n\n\nKhi m·ª©c ƒë·ªô bi·∫øn ƒë·ªông c·ªßa seasonal ho·∫∑c s·ª± bi·∫øn ƒë·ªïi xung quanh trend-cycle kh√¥ng thay ƒë·ªïi theo m·ª©c ƒë·ªô c·ªßa chu·ªói th·ªùi gian, m√¥ h√¨nh Additive s·∫Ω ph√π h·ª£p h∆°n m√¥ h√¨nh Multiplicative.\n\n\nV·∫≠y m·ª•c ti√™u c·ªßa vi·ªác ph√¢n t√≠ch time series ch√≠nh l√† t√¨m ra th√†nh ph·∫ßn seasonal trong v√¨ n√≥ c√≥ t√≠nh l·∫∑p l·∫°i v√† c√≥ th·ªÉ d√πng ƒë·ªÉ d·ª± ƒëo√°n cho t∆∞∆°ng lai. Ngo√†i ra, th√†nh ph·∫ßn trend c≈©ng c·∫ßn ƒë∆∞·ª£c quan t√¢m v√¨ n√≥ th·ªÉ hi·ªán xu h∆∞·ªõng c·ªßa d·ªØ li·ªáu trong t∆∞∆°ng lai.\nNh√¨n s∆° b·ªô, ta c√≥ th·ªÉ th·∫•y xu h∆∞·ªõng tƒÉng (trend) c·ªßa s·ªë l∆∞·ª£ng ƒë∆°n ƒë·∫∑t h√†ng. V·ªÅ ph·∫ßn random th√¨ s·∫Ω c√≥ 1 kho·∫£ng t·ª´ (-10,5) s·ªë ƒë∆°n l√† t·ª± nhi√™n x·∫£y ra, nghƒ©a l√† gi√° tr·ªã d·ª± ƒëo√°n c√≥ th·ªÉ l·ªách t·ª´ -10 ƒë·∫øn 5 ƒë∆°n h√†ng v√† sai l·ªách n√†y l√† do t·ª± nhi√™n.\n\n\n\n\n\n\nH√†m Decompose()\n\n\n\nV·ªÅ c√¥ng th·ª©c t√≠nh, h√†m decompose() d·ª±a v√†o kƒ© thu·∫≠t Moving Averages ƒë·ªÉ t√≠nh trung b√¨nh gi√° tr·ªã theo 1 kho·∫£ng th·ªùi gian (Vd: 3 th√°ng 6 th√°ng ho·∫∑c 1 nƒÉm).\n\n\nNgo√†i ra, vi·ªác ph√¢n t√°ch chu·ªói d·ªØ li·ªáu tr√™n trong R d·ª±a v√†o c√¥ng th·ª©c t·ª´ 2 m√¥ h√¨nh l√† Additive v√† Multiplicative. ·ªû m·∫∑c ƒë·ªãnh, h√†m decompose() t√≠nh theo m√¥ h√¨nh Additive, c√≤n b·∫°n mu·ªën t√≠nh theo m√¥ h√¨nh Multiplicative th√¨ ph·∫£i th√™m ƒë·ªëi s·ªë type = \"multiplicative\". Vi·ªác l·ª±a ch·ªçn m√¥ h√¨nh s·∫Ω t√πy v√†o nhu c·∫ßu c·ªßa b·∫°n, v√¨ m·ª•c ƒë√≠ch h·ªçc t·∫≠p n√™n m√¨nh tr√¨nh b√†y k·∫øt qu·∫£ t√≠nh to√°n ƒë∆∞·ª£c t·ª´ c·∫£ hai m√¥ h√¨nh.\n\n\n\nH√¨nh 5: Additive and multiplicative model"
  },
  {
    "objectID": "Forecasting.html#m√¥-h√¨nh-arima",
    "href": "Forecasting.html#m√¥-h√¨nh-arima",
    "title": "M√¥ h√¨nh ARIMA",
    "section": "",
    "text": "Tr√™n th·ª±c t·∫ø, ph·∫ßn ph√¢n t√≠ch c√°c th√†nh ph·∫ßn c·ªßa time series ch·ªâ ƒë∆∞a ra d·ª± ƒëo√°n ƒë·ªãnh t√≠nh, kh√¥ng th·ªÉ d·ª± ƒëo√°n b·∫±ng c√°c d·ªØ li·ªáu tr√™n m√† ph·∫£i c·∫ßn th√¥ng qua m√¥ h√¨nh c·ª• th·ªÉ. V√† d∆∞·ªõi ƒë√¢y l√† gi·ªõi thi·ªáu v·ªÅ m√¥ h√¨nh ARIMA - m·ªôt trong nh·ªØng m√¥ h√¨nh ph·ªï bi·∫øn ƒë∆∞·ª£c s·ª≠ d·ª•ng khi ph√¢n t√≠ch d·ªØ li·ªáu chu·ªói th·ªùi gian.\n\n\nV√†o nƒÉm 1970, hai nh√† khoa h·ªçc George E.P. Box v√† Gwilym M. Jenkins ƒë√£ c√¥ng b·ªë cu·ªën s√°ch ‚ÄúTime Series Analysis: Forecasting and Control‚Äù. Trong cu·ªën s√°ch n√†y, h·ªç gi·ªõi thi·ªáu ph∆∞∆°ng ph√°p ARIMA v√† ph∆∞∆°ng ph√°p ti·∫øp c·∫≠n t·ª´ng b∆∞·ªõc ƒë·ªÉ ph√°t tri·ªÉn m√¥ h√¨nh. Kh√°i ni·ªám ARIMA ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a r√µ r√†ng v√† tr·ªü th√†nh m·ªôt trong nh·ªØng c√¥ng c·ª• ph√¢n t√≠ch chu·ªói th·ªùi gian ch·ªß y·∫øu.\nSau n√†y, nhi·ªÅu nghi√™n c·ª©u ƒë√£ m·ªü r·ªông v√† c·∫£i thi·ªán ph∆∞∆°ng ph√°p n√†y, d·∫´n ƒë·∫øn s·ª± ph√°t tri·ªÉn c·ªßa c√°c bi·∫øn th·ªÉ nh∆∞ SARIMA (Seasonal ARIMA) ƒë·ªÉ x·ª≠ l√Ω c√°c chu·ªói th·ªùi gian c√≥ y·∫øu t·ªë m√πa v·ª•. V√† cho ƒë·∫øn hi·ªán nay, xu h∆∞·ªõng k·∫øt h·ª£p m√¥ h√¨nh ARIMA v·ªõi c√°c ph∆∞∆°ng ph√°p h·ªçc m√°y ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c trong d·ª± ƒëo√°n chu·ªói th·ªùi gian, m·ªü r·ªông kh·∫£ nƒÉng c·ªßa m√¥ h√¨nh n√†y trong vi·ªác x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn v√† ph·ª©c t·∫°p.\n\n\n\nTheo (phamdinhkhanh 2019), M√¥ h√¨nh ARIMA ‚Äús·ª≠ d·ª•ng ƒë·∫ßu v√†o ch√≠nh l√† nh·ªØng t√≠n hi·ªáu qu√° kh·ª© c·ªßa chu·ªói ƒë∆∞·ª£c d·ª± b√°o ƒë·ªÉ d·ª± b√°o n√≥. C√°c t√≠n hi·ªáu ƒë√≥ bao g·ªìm: Chu·ªói t·ª± h·ªìi qui AR (auto regression) v√† chu·ªói trung b√¨nh tr∆∞·ª£t MA (moving average).\nH·∫ßu h·∫øt c√°c chu·ªói th·ªùi gian s·∫Ω c√≥ xu h∆∞·ªõng tƒÉng ho·∫∑c gi·∫£m theo th·ªùi gian, do ƒë√≥ y·∫øu t·ªë chu·ªói d·ª´ng th∆∞·ªùng kh√¥ng ƒë·∫°t ƒë∆∞·ª£c. Trong tr∆∞·ªùng h·ª£p chu·ªói kh√¥ng d·ª´ng th√¨ ta s·∫Ω c·∫ßn bi·∫øn ƒë·ªïi sang chu·ªói d·ª´ng b·∫±ng sai ph√¢n. Khi ƒë√≥ tham s·ªë ƒë·∫∑c tr∆∞ng c·ªßa m√¥ h√¨nh s·∫Ω c√≥ th√™m th√†nh ph·∫ßn b·∫≠c c·ªßa sai ph√¢n d v√† m√¥ h√¨nh ƒë∆∞·ª£c ƒë·∫∑c t·∫£ b·ªüi 3 tham s·ªë ARIMA(p, d, q)‚Äú.\nM√¥ h√¨nh ƒë∆∞·ª£c x√¢y d·ª±ng ‚Äúd·ª±a tr√™n gi·∫£ thuy·∫øt: Stationary series (Chu·ªói d·ª´ng) ƒë√≤i h·ªèi Ph∆∞∆°ng sai sai s·ªë kh√¥ng ƒë·ªïi v√† Nhi·ªÖu tr·∫Øng (White noise), c·ª• th·ªÉ trong ƒë√≥:\n\nStationary series: ƒëi·ªÅu ki·ªán l√† trung b√¨nh c·ªßa chu·ªói l√† constant (b·∫•t bi·∫øn), ph∆∞∆°ng sai (variance) c·ªßa chu·ªói ph·∫£i c√≥ t√≠nh ƒë·ªìng nh·∫•t (homoscedasticity) v√† hi·ªáp ph∆∞∆°ng sai (covariance) gi·ªØa gi√° tr·ªã t v√† t+1 ph·∫£i kh√¥ng li√™n quan t·ªõi nhau.\n\n\n\n\n\n\nL∆∞u √Ω\n\n\n\nN·∫øu chu·ªói d·ªØ li·ªáu kh√¥ng ph·∫£i l√† chu·ªói d√πng th√¨ b·∫°n s·∫Ω kh√¥ng x√¢y d·ª±ng ƒë∆∞·ª£c m√¥ h√¨nh chu·ªói th·ªùi gian (time-series model)\n\n\nNhi·ªÖu tr·∫Øng l√†: m·ªôt th√†nh ph·∫ßn ng·∫´u nhi√™n th·ªÉ hi·ªán cho y·∫øu t·ªë kh√¥ng th·ªÉ d·ª± b√°o c·ªßa model v√† kh√¥ng c√≥ t√≠nh qui lu·∫≠t.\n\n\n\n\nH√¨nh 6: Stationary and non-stationary series"
  },
  {
    "objectID": "Forecasting.html#ki·ªÉm-tra-chu·ªói-d·ª´ng",
    "href": "Forecasting.html#ki·ªÉm-tra-chu·ªói-d·ª´ng",
    "title": "M√¥ h√¨nh ARIMA",
    "section": "2.1 Ki·ªÉm tra chu·ªói d·ª´ng:",
    "text": "2.1 Ki·ªÉm tra chu·ªói d·ª´ng:\nTr∆∞·ªõc khi ph√¢n t√≠ch, b·∫°n c·∫ßn ƒë·∫£m b·∫£o chu·ªói d·ªØ li·ªáu th·ªùi gian ph·∫£i th·ªèa m√£n c√°c gi·∫£ ƒë·ªãnh tr√™n. ƒê·ªÉ l√†m ƒë∆∞·ª£c ƒëi·ªÅu ƒë√≥ trong R, ta ch·ªâ c·∫ßn s·ª≠ d·ª•ng h√†m adf.test() c√≥ th·ªÉ ki·ªÉm tra nhanh ch√≥ng.\n\n\nCode\nlibrary(tseries)\nadf.test(demand_training)    ## p-value = 0.3779 &gt; 0.05 means this series is not stationary\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  demand_training\nDickey-Fuller = -2.4991, Lag order = 3, p-value = 0.3779\nalternative hypothesis: stationary\n\n\nNh∆∞ v·∫≠y, ta th·∫•y chu·ªói d·ªØ li·ªáu n√†y kh√¥ng ph·∫£i chu·ªói d·ª´ng v√¨ gi√° tr·ªã p = 0.3779 &gt; 0.05 nghƒ©a l√† ch·∫•p nh·∫≠n gi·∫£ thuy·∫øt H0: Chu·ªói n√†y l√† chu·ªói kh√¥ng d·ª´ng.\nTrong time-series analyst, ta s·∫Ω c√≥ c√°ch ƒë·ªÉ x·ª≠ l√≠ chu·ªói th√†nh chu·ªói d·ª´ng. ƒê√≥ l√† t√≠nh s·ª± kh√°c nhau (Difference) gi·ªØa gi√° tr·ªã t v√† gi√° tr·ªã c·ªßa n√≥ ·ªü qu√° kh·ª© t-1,t-2,‚Ä¶\nTrong R, b·∫°n c√≥ th·ªÉ t√≠nh b·∫±ng c√°ch:\n\ndiff(series, lag = n): t√≠nh s·ª± kh√°c nhau gi·ªØa c√°c th·ªùi ƒëi·ªÉm t v√† t-n.\nlog(series): chuy·ªÉn time-series sang d·∫°ng log.\n\nN√†y t√πy thu·ªôc v√†o c√¥ng th·ª©c to√°n h·ªçc b·∫°n mu·ªën ƒë·ªãnh nghƒ©a, mi·ªÖn sao b·∫°n c√≥ th·ªÉ x√°c ƒë·ªãnh ƒë∆∞·ª£c chu·ªói d·ª´ng l√† ƒë·∫°t.\n\n\nCode\n#First we will calculate the different in demand product monthly:\n#Check stationary assumption:\ntest&lt;-lapply(1:3, function(x) {\n         a&lt;-diff(demand_training, lag = x)\n         adf.test(a)$p.value}\n       ) #p&lt;0,05 is accepted\n\n## Second transform it to dataframe object:\ntest&lt;-data.frame(test)\ncolnames(test)&lt;-c(\"Lag 1\",\"Lag 2\",\"Lag 3\")\n\n## Finally plot the result:\nlibrary(gt)\nlibrary(gtExtras)\ngt(test) %&gt;% \n  cols_align(\n    align = \"left\",\n    columns = \"Lag 1\"\n  ) %&gt;% \n  cols_align(\n    align = \"center\",\n    columns = \"Lag 2\"\n  ) %&gt;%\n   tab_header(\n    title = md(\"**Checking stationary assumption**\"),\n    subtitle = glue::glue(\"Time from {min(month_df$datetime)} to 01-03-2015\")) %&gt;%\n   tab_source_note(\n    source_note = \"Alternative hypothesis: stationary\") %&gt;% \n  gt_theme_538()\n\n\n\n\n\n\n  \n    \n      Checking stationary assumption\n\n    \n    \n      Time from 2012-01-01 to 01-03-2015\n    \n    \n      Lag 1\n      Lag 2\n      Lag 3\n    \n  \n  \n    0.01\n0.01\n0.152641\n  \n  \n    \n      Alternative hypothesis: stationary\n    \n  \n  \n\n\n\n\nK·∫øt qu·∫£ testing cho th·∫•y ch·ªâ c√≥ chu·ªói 1 v√† 2 ƒë·∫°t y√™u c·∫ßu, chu·ªói 3 kh√¥ng ph·∫£i chu·ªói d·ª´ng v√¨ p-value = 0.107 &gt; 0.05."
  },
  {
    "objectID": "Forecasting.html#t√≠nh-to√°n-gi√°-tr·ªã-pacf-v√†-acf",
    "href": "Forecasting.html#t√≠nh-to√°n-gi√°-tr·ªã-pacf-v√†-acf",
    "title": "M√¥ h√¨nh ARIMA",
    "section": "2.2 T√≠nh to√°n gi√° tr·ªã PACF v√† ACF:",
    "text": "2.2 T√≠nh to√°n gi√° tr·ªã PACF v√† ACF:\n\n2.2.1 ƒê·ªãnh nghƒ©a v·ªÅ PACF v√† ACF:\nPACF (Partial Autocorrelation Function) v√† ACF (Autocorrelation Function) l√† 2 c√¥ng th·ª©c t√≠nh thu·ªôc Autocorrelation Analyst - 1 b∆∞·ªõc quan tr·ªçng trong vi·ªác ph√¢n t√≠ch chu·ªói d·ªØ li·ªáu th·ªùi gian. M·ª•c ti√™u c·ªßa Autocorrelation analyst l√† t√¨m ra c√°c m·∫´u (pattern) gi·ªØa nhi·ªÅu chu·ªói th·ªùi gian v√† ki·ªÉm tra t√≠nh ng·∫´u nhi√™n.\n\n\n2.2.2 Ph√¢n t√≠ch trong R:\nSau khi ƒë√£ x√°c ƒë·ªãnh ƒë∆∞·ª£c chu·ªói d·ª´ng, b∆∞·ªõc ti·∫øp theo l√† x√°c ƒë·ªãnh c√°c tham s·ªë (p, d, q) cho m√¥ h√¨nh ARIMA.\nTrong R c√≥ h√†m ggtsdisplay c·ªßa package forecast s·∫Ω hi·ªÉn th·ªã c·∫£ ACF, PACF v√† Time series plot c·ªßa ƒë·ªëi t∆∞·ª£ng m√† b·∫°n g√°n. C√≤n n·∫øu b·∫°n mu·ªën hi·ªÉn th·ªã ri√™ng gi√° tr·ªã ACF ho·∫∑c PACF th√¨ d√πng h√†m Acf ho·∫∑c Pacf ƒë·ªÉ t√≠nh v√† d√πng h√†m autoplot() ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì.\n\n\nCode\n#Rename of two time series:\nts1&lt;-diff(demand_training, lag = 1)\nts2&lt;-diff(demand_training, lag = 2)\n#Plot value ACF for 2 series:\nlibrary(forecast)\nggtsdisplay(ts1,\n            main = \"Time series lag 1\",\n            theme=theme_bw())\nggtsdisplay(ts2,\n            main = \"Time series lag 2\",\n            theme=theme_bw())\n\n\n\n\n\n\n\n\n\n\n\n\nD·ª±a v√†o tricks t·ª´ (Tavish Srivastava 2023), ta s·∫Ω d·ª±a v√†o gi√° tr·ªã PACF ƒë·ªÉ x√°c ƒë·ªãnh b·∫≠c c·ªßa AR v√† ACF ƒë·ªÉ x√°c ƒë·ªãnh b·∫≠c c·ªßa MA.\nV√≠ d·ª• ·ªü tr√™n, ƒë·ªëi v·ªõi chu·ªói lag 1, gi√° tr·ªã PACF c√≥ s·ª± ƒë·ª©t g√£y (cut off) ·ªü b·∫≠c 2 ƒë·∫øn b·∫≠c 3 n√™n c√≥ th·ªÉ thu·ªôc AR(3). C√≤n gi√° tr·ªã ACF th√¨ c√≥ th·ªÉ thu·ªôc MA(2) ho·∫∑c r√µ r√†ng h∆°n l√† MA(3). C√≤n l·∫°i, ƒë·ªëi v·ªõi chu·ªói lag 2, c√°c b·∫°n c√≥ th·ªÉ l√†m t∆∞∆°ng t·ª±.\nV·∫≠y m√¥ h√¨nh t·ª± ch·ªçn cu·ªëi c√πng l√† ARIMA(3,0,2)."
  },
  {
    "objectID": "Forecasting.html#l·ª±a-ch·ªçn-m√¥-h√¨nh-t·ªët-nh·∫•t",
    "href": "Forecasting.html#l·ª±a-ch·ªçn-m√¥-h√¨nh-t·ªët-nh·∫•t",
    "title": "M√¥ h√¨nh ARIMA",
    "section": "2.3 L·ª±a ch·ªçn m√¥ h√¨nh t·ªët nh·∫•t:",
    "text": "2.3 L·ª±a ch·ªçn m√¥ h√¨nh t·ªët nh·∫•t:\nTh·ª±c t·∫ø, trong R c√≥ h√†m auto.arimaƒë·ªÉ ch√∫ng ta l·ª±a ch·ªçn v√† so s√°nh nhi·ªÅu m√¥ h√¨nh ARIMA m·ªôt c√°ch t·ª± ƒë·ªông v√† kh√¥ng n·∫∑ng v·ªÅ code nh∆∞ d∆∞·ªõi ƒë√¢y. N√≥ s·∫Ω t·ª± li·ªát k√™ ra c√°c m√¥ h√¨nh ph√π h·ª£p v√† ch·ªçn ra m√¥ h√¨nh t·ªët nh·∫•t.\nNgo√†i ra, n·∫øu b·∫°n mu·ªën t√¨m hi·ªÉu s√¢u v·ªÅ c√°ch x√¢y d·ª±ng m√¥ h√¨nh ARIMA, b·∫°n c√≥ th·ªÉ tham kh·∫£o th√™m b√†i blog (D≈©ng, n.d.). Anh Ch√≠ D≈©ng c√≥ kh√° nhi·ªÅu b√†i vi·∫øt hay v·ªÅ c√°ch s·ª≠ d·ª•ng R trong nghi√™n c·ª©u v√† ph√¢n t√≠ch kinh t·∫ø, b·∫°n c√≥ th·ªÉ tham kh·∫£o trang blog c·ªßa ·∫£nh th√¥ng qua ƒë∆∞·ªùng link chidungkt.\n\n\nCode\n#Select the best model:\nmodel&lt;-auto.arima(ts1,trace = T)\n\n\n\n ARIMA(2,0,2)(1,0,1)[12] with non-zero mean : 279.6301\n ARIMA(0,0,0)            with non-zero mean : 291.5234\n ARIMA(1,0,0)(1,0,0)[12] with non-zero mean : 285.1005\n ARIMA(0,0,1)(0,0,1)[12] with non-zero mean : Inf\n ARIMA(0,0,0)            with zero mean     : 289.5102\n ARIMA(2,0,2)(0,0,1)[12] with non-zero mean : 278.2485\n ARIMA(2,0,2)            with non-zero mean : 276.6431\n ARIMA(2,0,2)(1,0,0)[12] with non-zero mean : 277.2391\n ARIMA(1,0,2)            with non-zero mean : Inf\n ARIMA(2,0,1)            with non-zero mean : 274.6588\n ARIMA(2,0,1)(1,0,0)[12] with non-zero mean : 274.4807\n ARIMA(2,0,1)(1,0,1)[12] with non-zero mean : 276.6914\n ARIMA(2,0,1)(0,0,1)[12] with non-zero mean : 275.6882\n ARIMA(1,0,1)(1,0,0)[12] with non-zero mean : Inf\n ARIMA(2,0,0)(1,0,0)[12] with non-zero mean : 271.6811\n ARIMA(2,0,0)            with non-zero mean : 272.1458\n ARIMA(2,0,0)(1,0,1)[12] with non-zero mean : 273.7323\n ARIMA(2,0,0)(0,0,1)[12] with non-zero mean : 272.8549\n ARIMA(3,0,0)(1,0,0)[12] with non-zero mean : 274.4922\n ARIMA(3,0,1)(1,0,0)[12] with non-zero mean : 277.4715\n ARIMA(2,0,0)(1,0,0)[12] with zero mean     : 269.4654\n ARIMA(2,0,0)            with zero mean     : 270.5103\n ARIMA(2,0,0)(1,0,1)[12] with zero mean     : 271.365\n ARIMA(2,0,0)(0,0,1)[12] with zero mean     : 270.7772\n ARIMA(1,0,0)(1,0,0)[12] with zero mean     : 282.7531\n ARIMA(3,0,0)(1,0,0)[12] with zero mean     : 272.0724\n ARIMA(2,0,1)(1,0,0)[12] with zero mean     : 272.0509\n ARIMA(1,0,1)(1,0,0)[12] with zero mean     : 275.1242\n ARIMA(3,0,1)(1,0,0)[12] with zero mean     : 274.8562\n\n Best model: ARIMA(2,0,0)(1,0,0)[12] with zero mean"
  },
  {
    "objectID": "Forecasting.html#ƒë√°nh-gi√°-m√¥-h√¨nh",
    "href": "Forecasting.html#ƒë√°nh-gi√°-m√¥-h√¨nh",
    "title": "M√¥ h√¨nh ARIMA",
    "section": "2.4 ƒê√°nh gi√° m√¥ h√¨nh:",
    "text": "2.4 ƒê√°nh gi√° m√¥ h√¨nh:\nSau khi ƒë√£ x√¢y d·ª±ng m√¥ h√¨nh, ta s·∫Ω so s√°nh gi√° tr·ªã d·ª± ƒëo√°n t·ª´ training data v·ªõi testing data ƒë·ªÉ ƒë√°nh gi√° ƒë·ªô t·ªët c·ªßa m√¥ h√¨nh.\n\n\nCode\n#Forecast by training model:\ntraining_forecast&lt;-forecast(model,h = 21)\n\n\nB·∫£ng tr√¨nh b√†y c√°c gi√° tr·ªã d·ª± ƒëo√°n theo t·ª´ng th√°ng. Ta th·∫•y ch·ªâ c√≥ 4/21 th·ªùi ƒëi·ªÉm m√† gi√° tr·ªã th·ª±c t·∫ø v∆∞·ª£t ra gi√° tr·ªã d·ª± ƒëo√°n trong kho·∫£ng tin c·∫≠y 80%. C√≤n ƒë·ªëi v·ªõi gi√° tr·ªã d·ª± ƒëo√°n trong kho·∫£ng tin c·∫≠y 95% th√¨ ƒë·ªÅu ƒë·∫°t y√™u c·∫ßu.\n\n\nCode\n#Calculate RMSE:\nactual&lt;- diff(demand_testing,1)\n\naccuracy&lt;-data_frame(Period = paste(month(testing_df$datetime),\n                                    year(testing_df$datetime),\n                                    sep = \"/\")[-1],\n                     Actual = actual %&gt;% as.vector(), \n                     High.80 = training_forecast$upper[,1],\n                     Low.80 = training_forecast$lower[,1],\n                     High.95 = training_forecast$upper[,2],\n                     Low.95 = training_forecast$lower[,2]) %&gt;% \n  mutate(Check.80 = ifelse(Actual &lt;= High.80 & Actual &gt;= Low.80,\"Pass\",\"Fail\"),\n         Check.95 = ifelse(Actual &lt;= High.95 & Actual &gt;= Low.95,\"Pass\",\"Fail\"))\n\n## Finally plot the result\ngt(accuracy) %&gt;% \n   tab_header(\n    title = md(\"**Comparing the accuracy of forecasting**\"),\n    subtitle = glue::glue(\"Forecasting from {min(testing_df$datetime)} to {max(testing_df$datetime)}\")) %&gt;%\n   tab_source_note(\n    source_note = str_glue(\"Method: Model {training_forecast$method}\")) %&gt;% \n  gt_theme_538() %&gt;% \n   data_color(\n    columns = Check.80,\n    method = \"factor\",\n    palette = c(\"red\",\"darkgreen\")\n  ) %&gt;% data_color(\n    columns = Check.95,\n    method = \"factor\",\n    palette = c(\"darkgreen\",\"red\")\n  ) \n\n\n\n\n\n\n  \n    \n      Comparing the accuracy of forecasting\n\n    \n    \n      Forecasting from 2015-03-01 to 2016-12-01\n    \n    \n      Period\n      Actual\n      High.80\n      Low.80\n      High.95\n      Low.95\n      Check.80\n      Check.95\n    \n  \n  \n    4/2015\n-11.157\n8.2151971\n-10.812921\n13.251636\n-15.84936\nFail\nPass\n    5/2015\n-12.621\n1.6260371\n-20.888910\n7.585384\n-26.84826\nPass\nPass\n    6/2015\n13.813\n18.5336717\n-4.315841\n24.581572\n-10.36374\nPass\nPass\n    7/2015\n8.293\n14.9318430\n-9.908314\n21.506636\n-16.48311\nPass\nPass\n    8/2015\n-20.715\n-0.7494574\n-25.879586\n5.902086\n-32.53113\nPass\nPass\n    9/2015\n4.671\n21.7271249\n-3.643527\n28.442331\n-10.35873\nPass\nPass\n    10/2015\n1.452\n17.1916812\n-8.576132\n24.012009\n-15.39646\nPass\nPass\n    11/2015\n-8.055\n8.5209607\n-17.257552\n15.344121\n-24.08071\nPass\nPass\n    12/2015\n8.132\n14.8015863\n-11.075451\n21.650824\n-17.92469\nPass\nPass\n    1/2016\n-9.978\n17.8052582\n-8.139698\n24.672473\n-15.00691\nFail\nPass\n    2/2016\n-4.696\n6.4211445\n-19.524421\n13.288521\n-26.39180\nPass\nPass\n    3/2016\n19.274\n19.2007071\n-6.774814\n26.076012\n-13.65012\nFail\nPass\n    4/2016\n-14.336\n13.5655001\n-13.694775\n20.780859\n-20.91013\nFail\nPass\n    5/2016\n0.513\n9.7760700\n-17.849339\n17.088074\n-25.16134\nPass\nPass\n    6/2016\n2.751\n16.5398455\n-11.170685\n23.874380\n-18.50522\nPass\nPass\n    7/2016\n6.377\n15.2198557\n-12.789469\n22.633476\n-20.20309\nPass\nPass\n    8/2016\n-8.324\n8.6649731\n-19.373047\n16.086189\n-26.79426\nPass\nPass\n    9/2016\n-2.439\n17.5484745\n-10.538978\n24.982774\n-17.97328\nPass\nPass\n    10/2016\n6.244\n15.8818767\n-12.264517\n23.331777\n-19.71442\nPass\nPass\n    11/2016\n5.996\n12.3351533\n-15.811609\n19.785151\n-23.26161\nPass\nPass\n    12/2016\n-9.544\n14.7681518\n-13.396724\n22.222944\n-20.85152\nPass\nPass\n  \n  \n    \n      Method: Model ARIMA(2,0,0)(1,0,0)[12] with zero mean\n    \n  \n  \n\n\n\n\nV√† d∆∞·ªõi ƒë√¢y l√† bi·ªÉu ƒë·ªì hi·ªÉn th·ªã gi√° tr·ªã trung b√¨nh (ƒë∆∞·ªùng m√†u xanh d∆∞∆°ng), gi√° tr·ªã d·ª± ƒëo√°n trong kho·∫£ng tin c·∫≠y 80% (ƒë∆∞·ªùng m√†u x√°m ƒë·∫≠m) v√† kho·∫£ng tin c·∫≠y 95% (ƒë∆∞·ªùng m√†u x√°m nh·∫°t).\nNgo√†i ra ta c≈©ng t√≠nh c√°c ch·ªâ s·ªë MAE v√† RMSE c·ªßa m√¥ h√¨nh nh∆∞ sau:\n\n\nCode\n## Calculating MAE metric:\nsum = 0\nfor (i in 1:nrow(accuracy)){ \n  sum = abs(accuracy$Actual[i]-training_forecast$mean[i]) + sum\n} \n\nMAE = sum/nrow(accuracy) \n\n## Calculating RMSE metric:\nRMSE= sqrt(mean((accuracy$Actual - training_forecast$mean)^2))\n\n\n\n\nCode\n#Use chart for presenting the differents:\nplot(training_forecast,\n      main = str_glue(\"Method: Model {training_forecast$method}\"),\n      xlab = \"Time\",\n      ylab = \"Order Demand\")\nlines(actual, \n      col = \"red\",\n      lwd = \"2\")\nlegend(\"topleft\",\n       legend = c(\"Actual\",\"Forecast\"),\n       col = c(\"red\",\"blue\"),\n       box.lty = 0,\n       lty = 1,\n       cex = 1,\n       lwd = 2)\n\n\n\n\n\nTa th·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n c≈©ng ·ªïn nh∆∞ng v·∫´n ch∆∞a s√°t v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø. V√¨ v·∫≠y ti·∫øp theo ch√∫ng ta s·∫Ω l√†m cho m√¥ h√¨nh t·ªët h∆°n ·ªü trang sau M√¥ h√¨nh SARIMA"
  },
  {
    "objectID": "SARIMA.html#l·ª±a-ch·ªçn-m√¥-h√¨nh-th·ªß-c√¥ng",
    "href": "SARIMA.html#l·ª±a-ch·ªçn-m√¥-h√¨nh-th·ªß-c√¥ng",
    "title": "M√¥ h√¨nh SARIMA",
    "section": "2.1 L·ª±a ch·ªçn m√¥ h√¨nh th·ªß c√¥ng:",
    "text": "2.1 L·ª±a ch·ªçn m√¥ h√¨nh th·ªß c√¥ng:\nTh·ª±c t·∫ø, ta th·∫•y m√¥ h√¨nh do R ƒë·ªÅ xu·∫•t b·∫±ng h√†m auto.arima c√≥ v·∫ª ‚Äúoverfitting‚Äù - nghƒ©a l√† m√¥ h√¨nh t·ªët qu√°, cover h·∫øt c√°c tr∆∞·ªùng h·ª£p nh∆∞ng c√≥ nguy c∆° kh√¥ng cho d·ª± ƒëo√°n t·ªët v√¨ d·ªØ li·ªáu trong t∆∞∆°ng lai bi·∫øn ƒë·ªông.\nV√¨ v·∫≠y, ta c√≥ th·ªÉ x√¢y d·ª±ng c√°ch l·ª±a ch·ªçn m√¥ h√¨nh theo c√°ch kh√°c. M√¨nh c√≥ kham kh·∫£o c√°ch n√†y tr√™n How can I select the best SARIMA model.\n\n\nCode\n## List all parameters can be appeared:\nqQ=list()\nfor(i in 1:14) qQ[[i]]=c(i-1,0)\nqQ[[15]]=c(0,1)\nqQ[[16]]=c(1,1)\npP=qQ\n \ndt_params=c()\nfor(i in 1:16){\n  for(j in 1:16){\n     temp=c(pP[[i]][1],1,qQ[[j]][1],pP[[i]][2],1,\n            qQ[[j]][2],12)\n     dt_params=rbind(temp,dt_params)\n   }\n }\ncolnames(dt_params)=c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"T\")\nrownames(dt_params)=1:256\n\n# Build all the models:\nmodels=vector(\"list\",256)\nfor(i in 1:256){\n   try(models[[i]]&lt;-Arima(diff(demand_training,lag = 1),\n                          order = dt_params[i,1:3],\n                          seasonal = list(order=dt_params[i,4:6],\n                                          period=12),\n                     lambda = NULL,\n                     method=\"ML\"))  ## use MLE (maximum likelihood estimation)\n}\n\n\nSau khi ƒë√£ x√¢y d·ª±ng h·∫øt c√°c m√¥ h√¨nh b·∫±ng 256 th√¥ng s·ªë. Ta s·∫Ω ki·ªÉm tra gi·∫£ thuy·∫øt v·ªÅ t√≠nh ƒë·ªôc l·∫≠p trong m·ªôt chu·ªói th·ªùi gian nh·∫•t ƒë·ªãnh (White noise) - nghƒ©a l√† ki·ªÉm tra ph·∫ßn d∆∞ (residuals) c·ªßa m√¥ h√¨nh c√≥ ph·∫£i l√† random noise kh√¥ng ?\n\n\nCode\n## Applied Ljung-Box Tests:\naa=rep(NA,256)\nfor(i in 1:256){\n   if(length(models[[i]]$residuals)&gt;1){\n     a=Box.test(x = models[[i]]$residuals,\n                lag = 10,\n                type = \"Box-Pierce\")\n     z=prod(1-(a[[\"p.value\"]]&lt;.05))\n     if(z==1) aa[i]=\"Passed\"\n     else aa[i]=\"Failed\"\n   }\n}\n\n## Transfers all these information into 1 table:\ndt_params2=data.frame(dt_params)\ndt_params2$residuals=aa\n\naic=rep(NA,256)\nmodel_names=rep(NA,256)\nfor(i in 1:256){\n   if(length(models[[i]]$aic)&gt;0){\n     aic[i]=models[[i]]$aic\n     model_names[i]=as.character(models[[i]])\n   }\n}\ndt_params2$aic=aic\ndt_params2$model=model_names\n\n\nCu·ªëi c√πng tr√¨nh b√†y b·∫£ng 10 model t·ªët nh·∫•t v·ªõi 2 ƒëi·ªÅu ki·ªán:\n\nCh·ªâ s·ªë AIC th·∫•p trong top 10.\nCh·ªâ s·ªë p c·ªßa Ljung-Box Test &lt; 0.05.\n\nV√† m√¥ h√¨nh cu·ªëi c√πng ƒë∆∞·ª£c ch·ªçn l√† ARIMA(2,1,0)(0,1,0)[12] v·ªõi ch·ªâ s·ªë AIC l√† 189.8917.\n\n\nCode\n## Finally plot the table and compared the AIC and BIC value among models:\ngt&lt;-dt_params2[order(dt_params2$aic,decreasing = FALSE),][1:10,] %&gt;%\n     filter(residuals == \"Passed\") %&gt;% ### Just select the models with p &lt; 0.05\n     relocate(model)\n## Just select 10 best models:\n\n\nlibrary(gt)\nlibrary(gtExtras)\n\n\nWarning: package 'gtExtras' was built under R version 4.2.3\n\n\nCode\ngt(gt) %&gt;% \n  cols_align(\n    align = \"left\",\n    columns = \"model\"\n  ) %&gt;% \n    cols_label(\n    model = md(\"**Model**\"),\n    aic = md(\"**AIC value**\")) %&gt;%\n   tab_header(\n    title = md(\"**Ljung‚ÄìBox test**\"),\n    subtitle = glue::glue(\"Time from {min(training_df$datetime)} to {max(training_df$datetime)}\")) %&gt;%\n   tab_source_note(\n    source_note = \"Null hypothesis: a given time series is independence\") %&gt;% \n  gt_theme_538() %&gt;% \n  gt_highlight_rows(rows = 1, \n                    font_weight = \"normal\")\n\n\n\n\n\n\n  \n    \n      Ljung‚ÄìBox test\n\n    \n    \n      Time from 2012-01-01 to 2015-03-01\n    \n    \n      Model\n\n      p\n      d\n      q\n      P\n      D\n      Q\n      T\n      residuals\n      AIC value\n\n    \n  \n  \n    ARIMA(2,1,1)(0,1,0)[12]\n2\n1\n1\n0\n1\n0\n12\nPassed\n190.2729\n    ARIMA(2,1,2)(0,1,0)[12]\n2\n1\n2\n0\n1\n0\n12\nPassed\n191.1681\n    ARIMA(3,1,1)(0,1,0)[12]\n3\n1\n1\n0\n1\n0\n12\nPassed\n191.2535\n    ARIMA(2,1,1)(0,1,1)[12]\n2\n1\n1\n0\n1\n1\n12\nPassed\n191.6419\n    ARIMA(3,1,1)(0,1,1)[12]\n3\n1\n1\n0\n1\n1\n12\nPassed\n192.6654\n    ARIMA(4,1,1)(0,1,0)[12]\n4\n1\n1\n0\n1\n0\n12\nPassed\n193.1045\n    ARIMA(2,1,3)(0,1,0)[12]\n2\n1\n3\n0\n1\n0\n12\nPassed\n193.1531\n    ARIMA(3,1,2)(0,1,0)[12]\n3\n1\n2\n0\n1\n0\n12\nPassed\n193.1566\n    ARIMA(2,1,5)(0,1,0)[12]\n2\n1\n5\n0\n1\n0\n12\nPassed\n194.1552\n    ARIMA(2,1,0)(0,1,0)[12]\n2\n1\n0\n0\n1\n0\n12\nPassed\n194.2871\n  \n  \n    \n      Null hypothesis: a given time series is independence"
  },
  {
    "objectID": "SARIMA.html#ƒë√°nh-gi√°-m√¥-h√¨nh",
    "href": "SARIMA.html#ƒë√°nh-gi√°-m√¥-h√¨nh",
    "title": "M√¥ h√¨nh SARIMA",
    "section": "2.2 ƒê√°nh gi√° m√¥ h√¨nh:",
    "text": "2.2 ƒê√°nh gi√° m√¥ h√¨nh:\nV√† cu·ªëi c√πng l√† ƒë√°nh gi√° m√¥ h√¨nh v·ª´a ƒë∆∞·ª£c ch·ªçn ARIMA(2,1,0)(0,1,0)[12] v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ ƒë·ªëi t∆∞·ª£ng demand_testing.\n\n\nCode\n#Forecast by training model:\nmodel_training3&lt;-Arima(diff(demand_training,lag = 1),\n                       order = c(2,1,1),\n                       seasonal = list(order = c(0,1,0),\n                                       period = 12),\n             lambda = NULL)\n\ntraining_forecast3&lt;-forecast(model_training3,\n                             h = 21)\n\n#Use chart for presenting the differents:\nplot(training_forecast3,\n      main = glue::glue(\"Model {gt[['model']][1]}\"),\n      xlab = \"Time\",\n      ylab = \"Order Demand\")\nlines(diff(demand_testing,lag = 1), \n      col = \"red\",\n      lwd = \"2\")\nlegend(\"topleft\",\n       legend = c(\"Actual\",\"Forecast\"),\n       col = c(\"red\",\"blue\"),\n       box.lty = 0,\n       lty = 1,\n       cex = 1,\n       lwd = 2)"
  },
  {
    "objectID": "SARIMA.html#ki·ªÉm-ƒë·ªãnh-gi·∫£-thuy·∫øt-c·ªßa-m√¥-h√¨nh",
    "href": "SARIMA.html#ki·ªÉm-ƒë·ªãnh-gi·∫£-thuy·∫øt-c·ªßa-m√¥-h√¨nh",
    "title": "M√¥ h√¨nh SARIMA",
    "section": "2.3 Ki·ªÉm ƒë·ªãnh gi·∫£ thuy·∫øt c·ªßa m√¥ h√¨nh:",
    "text": "2.3 Ki·ªÉm ƒë·ªãnh gi·∫£ thuy·∫øt c·ªßa m√¥ h√¨nh:\nSau khi ƒë√£ x√¢y d·ª±ng m√¥ h√¨nh, ta c·∫ßn ki·ªÉm tra l·∫°i c√°c gi·∫£ thuy·∫øt nh∆∞:\n\nPh·∫ßn d∆∞ kh√¥ng t∆∞∆°ng quan.\nPh·∫ßn d∆∞ c√≥ trung b√¨nh l√† 0.\nph∆∞∆°ng sai kh√¥ng ƒë·ªïi\nPh·∫ßn d∆∞ c√≥ ph√¢n ph·ªëi chu·∫©n.\n\n\n\nCode\n## Diagnostics the ARRIMA model in a short command:\ncheckresiduals(model_training3,\n               theme = theme_bw())\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,1,1)(0,1,0)[12]\nQ* = 6.3324, df = 5, p-value = 0.2752\n\nModel df: 3.   Total lags used: 8\n\n\nN·∫øu so s√°nh v·ªõi m√¥ h√¨nh ban ƒë·∫ßu theo c√°ch auto.arima th√¨ c√≥ v·∫ª m√¥ h√¨nh n√†y t·ªá h∆°n. Nh∆∞ng c√≥ th·ªÉ ·ªü trong t∆∞∆°ng lai, m√¥ h√¨nh n√†y c√≥ th·ªÉ s·∫Ω t·ªët h∆°n chƒÉng.\n\n\nCode\n## Calculating MAE metric:\nsum = 0\nfor (i in 1:21){ \n  sum = abs(diff(demand_testing,lag = 1)[i]-training_forecast3$mean[i])+sum\n} \n\nMAE = sum/21\n\n## Calculating RMSE metric:\nRMSE = sqrt(mean((diff(demand_testing,lag = 1) - training_forecast3$mean)^2))\n\n## Plot the compared results:\ngt(data.frame(Metric = c(\"MAE\",\"RMSE\"),\n              Manual = c(MAE,RMSE),\n              Auto.Arima = c(6.428828,7.534382))) %&gt;% \n  cols_label(\n    Manual = md(\"**Manual method**\"),\n    Auto.Arima = md(\"**Auto.Arima method**\")) %&gt;%\n  cols_align(\n    align = \"center\",\n    columns = \"Manual\"\n  ) %&gt;% \n  cols_align(\n    align = \"center\",\n    columns = \"Auto.Arima\"\n  ) %&gt;% \n  tab_header(\n    title = md(\"**Comparing the accuracy of forecasting**\"),\n    subtitle = glue::glue(\"Forecasting from {min(testing_df$datetime)} to {max(testing_df$datetime)}\")) %&gt;%\n   tab_source_note(\n    source_note = str_glue(\"Between Manual and Auto ARIMA Method\")) %&gt;% \n  gt_theme_538() %&gt;% \n  gt_highlight_cols(Auto.Arima, \n                    fill = \"blue\", \n                    alpha = 0.5)\n\n\n\n\n\n\n  \n    \n      Comparing the accuracy of forecasting\n\n    \n    \n      Forecasting from 2015-03-01 to 2016-12-01\n    \n    \n      Metric\n      Manual method\n\n      Auto.Arima method\n\n    \n  \n  \n    MAE\n8.652821\n6.428828\n    RMSE\n10.476431\n7.534382\n  \n  \n    \n      Between Manual and Auto ARIMA Method"
  },
  {
    "objectID": "SARIMA.html#m√¥-h√¨nh-sarima",
    "href": "SARIMA.html#m√¥-h√¨nh-sarima",
    "title": "M√¥ h√¨nh SARIMA",
    "section": "",
    "text": "Theo nghi√™n c·ª©u c·ªßa (JOHN A. MILLER, MOHAMMED ALDOSARI, and NASID HABIB BARNA 2024),h·ªç nh·∫Øc ƒë·∫øn m√¥ h√¨nh SARIMAX c√≥ performance t·ªët h∆°n ARIMA. V·∫≠y SARIMAX l√† g√¨:\n\nƒê·ªãnh nghƒ©a: ARIMA ƒë√≥ng vai tr√≤ l√† n·ªÅn t·∫£ng ƒë·ªÉ l·∫≠p m√¥ h√¨nh d·ªØ li·ªáu kh√¥ng theo m√πa (non-seasonal), trong khi SARIMA m·ªü r·ªông kh·∫£ nƒÉng x·ª≠ l√Ω c√°c m·∫´u theo m√πa.\nTh√†nh ph·∫ßn: SARIMAX c≈©ng x√¢y d·ª±ng d·ª±a tr√™n l√Ω thuy·∫øt nh∆∞ ARIMA nh∆∞ng th√™m 2 y·∫øu t·ªë m·ªõi l√† Seasonal v√† Exogenous variables. C√≤n m√¥ h√¨nh SARMA th√¨ ch·ªâ c√≥ th√™m y·∫øu t·ªë Seasonal.\n\nTh·ª±c t·∫ø, m√¥ h√¨nh m√† R ƒë·ªÅ xu·∫•t tr√™n b·∫±ng h√†m auto.arima() c≈©ng ƒë√£ bao g·ªìm th√†nh ph·∫ßn seasonal n√™n ta c√≥ th·ªÉ xem m√¥ h√¨nh tr√™n SARIMA.\n\n\n\nH√¨nh 7: SARIMA VS ARIMA\n\n\nD∆∞·ªõi ƒë√¢y l√† v√≠ d·ª• v·ªÅ m√¥ h√¨nh SARIMA v√† c√°ch ƒë·ªÉ code trong R.\nGi·∫£i th√≠ch l·∫°i c√°c th√¥ng s·ªë ta s·ª≠ d·ª•ng s·∫Ω l√†:\n\n(p,d,q) l√† b·∫≠c AR, m·ª©c ƒë·ªô kh√°c bi·ªát - Difference v√† b·∫≠c MA.\n(P,D,Q) l√† b·∫≠c seasonal c·ªßa m√¥ h√¨nh.\n[s] (period arguments) l√† th√¥ng s·ªë cho pattern. V√≠ d·ª• trong d·ªØ li·ªáu n√†y l√† d·ªØ li·ªáu c·ªßa 12 th√°ng n√™n period = 12. B·∫°n c√≥ th·ªÉ g·∫∑p d·ªØ li·ªáu theo qu√Ω th√¨ period = 3, d·ªØ li·ªáu theo nƒÉm th√¨ period = 1.\n\nV·∫≠y th√¨ c√≤n m√¥ h√¨nh SARIMAX th√¨ kh√°c g√¨ v·ªõi SARIMA."
  },
  {
    "objectID": "SARIMA.html#m√¥-h√¨nh-sarimax",
    "href": "SARIMA.html#m√¥-h√¨nh-sarimax",
    "title": "M√¥ h√¨nh SARIMA",
    "section": "",
    "text": "SARIMAX nghƒ©a l√† Seasonal Autoregressive Integrated Moving Average with eXogenous regressors l√† m·ªôt s·ª± m·ªü r·ªông c·ªßa m√¥ h√¨nh ARIMA, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ph√¢n t√≠ch v√† d·ª± ƒëo√°n c√°c chu·ªói th·ªùi gian c√≥ t√≠nh m√πa v·ª• v√† c√≥ th·ªÉ c√≥ th√™m c√°c bi·∫øn ƒë·ªôc l·∫≠p b√™n ngo√†i. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë ƒëi·ªÉm ch√≠nh v·ªÅ m√¥ h√¨nh n√†y. V·∫≠y so v·ªõi m√¥ h√¨nh SARIMA, n√≥ ch·ªâ kh√°c l√† c√≥ th√™m bi·∫øn kh√°c kh√¥ng ph·∫£i l√† bi·∫øn qu√° kh·ª© c·ªßa d·ªØ li·ªáu.\nNh·∫Øc l·∫°i, c·∫•u tr√∫c m√¥ h√¨nh SARIMAX v·∫´n bao g·ªìm c√°c th√†nh ph·∫ßn sau:\n\nAR (Autoregressive): Ph·∫ßn n√†y m√¥ t·∫£ m·ªëi quan h·ªá gi·ªØa gi√° tr·ªã hi·ªán t·∫°i v√† c√°c gi√° tr·ªã tr∆∞·ªõc ƒë√≥ trong chu·ªói th·ªùi gian.\nI (Integrated): Ph·∫ßn n√†y ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác l√†m cho chu·ªói th·ªùi gian tr·ªü n√™n ·ªïn ƒë·ªãnh b·∫±ng c√°ch l·∫•y sai ph√¢n c·ªßa n√≥.\nMA (Moving Average): Ph·∫ßn n√†y m√¥ t·∫£ m·ªëi quan h·ªá gi·ªØa gi√° tr·ªã hi·ªán t·∫°i v√† c√°c sai s·ªë d·ª± ƒëo√°n trong qu√° kh·ª©.\nSeasonal: SARIMAX c√≥ th·ªÉ x·ª≠ l√Ω c√°c y·∫øu t·ªë m√πa v·ª• b·∫±ng c√°ch th√™m c√°c tham s·ªë m√πa v·ª• v√†o m√¥ h√¨nh.\n\nV√† th√™m v√†o ƒë√≥ l√† tham s·ªë m·ªõi l√† ph·∫ßn Exogenous l√† c√°c bi·∫øn ƒë·ªôc l·∫≠p b√™n ngo√†i (exogenous variables) ƒë·ªÉ c·∫£i thi·ªán kh·∫£ nƒÉng d·ª± ƒëo√°n.\nNh∆∞ v·∫≠y, m√¥ h√¨nh SARIMAX mang l·∫°i nhi·ªÅu l·ª£i √≠ch, bao g·ªìm kh·∫£ nƒÉng d·ª± ƒëo√°n ch√≠nh x√°c h∆°n nh·ªù v√†o vi·ªác x·ª≠ l√Ω hi·ªáu qu·∫£ c√°c y·∫øu t·ªë m√πa v·ª• v√† c√°c bi·∫øn ƒë·ªôc l·∫≠p. Ngo√†i ra, m√¥ h√¨nh n√†y c√≤n cho ph√©p ƒëi·ªÅu ch·ªânh c√°c tham s·ªë linh ho·∫°t ƒë·ªÉ ph√π h·ª£p v·ªõi ƒë·∫∑c ƒëi·ªÉm c·ªßa d·ªØ li·ªáu. Tuy nhi√™n, SARIMAX c≈©ng c√≥ m·ªôt s·ªë nh∆∞·ª£c ƒëi·ªÉm, nh∆∞ t√≠nh ph·ª©c t·∫°p khi c·∫ßn t·ªëi ∆∞u h√≥a nhi·ªÅu tham s·ªë v√† y√™u c·∫ßu v·ªÅ d·ªØ li·ªáu l·ªõn, v√¨ ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c k·∫øt qu·∫£ t·ªët, m√¥ h√¨nh c·∫ßn c√≥ m·ªôt l∆∞·ª£ng d·ªØ li·ªáu l·ªãch s·ª≠ ƒë√°ng k·ªÉ."
  },
  {
    "objectID": "timeseries.html",
    "href": "timeseries.html",
    "title": "Gi·ªõi thi·ªáu",
    "section": "",
    "text": "Trong qu·∫£n l√≠ chu·ªói cung ·ª©ng, thu·∫≠t ng·ªØ Demand Planning l√† m·ªôt trong nh·ªØng ho·∫°t ƒë·ªông quan tr·ªçng m√† c√°c nh√† qu·∫£n l√≠ v√† doanh nghi·ªáp c·∫ßn quan t√¢m s√¢u s·∫Øc. V·ªÅ ƒë·ªãnh nghƒ©a, theo (Vilas, n.d.) ‚ÄúDemand Planning l√† m·ªôt qu√° tr√¨nh qu·∫£n l√Ω chu·ªói cung ·ª©ng nh·∫±m d·ª± b√°o nhu c·∫ßu v·ªÅ s·∫£n ph·∫©m ƒë·ªÉ ƒë·∫£m b·∫£o ch√∫ng c√≥ th·ªÉ ƒë∆∞·ª£c cung c·∫•p v√† l√†m h√†i l√≤ng kh√°ch h√†ng. M·ª•c ti√™u c·ªßa Demand planning l√† ƒë·∫°t ƒë∆∞·ª£c s·ª± c√¢n b·∫±ng trong vi·ªác c√≥ ƒë·ªß l∆∞·ª£ng h√†ng t·ªìn kho ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu c·ªßa kh√°ch h√†ng m√† kh√¥ng b·ªã thi·∫øu ho·∫∑c th·ª´a. ƒê·ªÉ c√≥ th·ªÉ d·ª± b√°o ƒë∆∞·ª£c nhu c·∫ßu mua h√†ng, nh√† Ho·∫°ch ƒë·ªãnh nhu c·∫ßu c·∫ßn thu th·∫≠p v√† ph√¢n t√≠ch d·ªØ li·ªáu t·ª´ nhi·ªÅu ngu·ªìn kh√°c nhau nh∆∞: h√†ng t·ªìn kho, nh√† cung ·ª©ng, kho, kh√°ch h√†ng,‚Ä¶‚Äù.\n\n\n\nH√¨nh 1: ƒê·ªãnh nghƒ©a v·ªÅ Demand Planning\n\n\n\n\n\nVi·ªác d·ª± ƒëo√°n tr∆∞·ªõc nhu c·∫ßu c·ªßa kh√°ch h√†ng s·∫Ω gi√∫p doanh nghi·ªáp chu·∫©n b·ªã t·ªët h∆°n v·ªÅ h√†ng h√≥a, d·ªãch v·ª• v√† chi·∫øm ƒë∆∞·ª£c l√≤ng tin c·ªßa kh√°ch h√†ng. Ngo√†i ra, vi·ªác chu·∫©n b·ªã s·ªõm c≈©ng tr√°nh c√°c hi·ªán t∆∞·ª£ng nh∆∞ out-stock, tranh ch·∫•p ho·∫∑c t·ªá h∆°n ƒë·ª©t g√£y chu·ªói cung ·ª©ng v√† ·∫£nh h∆∞·ªüng n·∫∑ng n·ªÅ t·ªõi k·∫øt qu·∫£ kinh doanh c·ªßa c√¥ng ty.\n·ªû v·ªã tr√≠ nh√¢n vi√™n, b·∫°n c√≥ th·ªÉ ·ª©ng tuy·ªÉn v·ªã tr√≠ Demand Planner ƒë·ªÉ c√≥ th·ªÉ l√†m vi·ªác v·ªÅ Demand Planning. C√≤n ·ªü v·ªã tr√≠ c·∫•p cao h∆°n s·∫Ω l√† Supply Chain Planner - l√† ng∆∞·ªùi c√≥ th·ªÉ x·ª≠ l√≠ lu√¥n c·∫£ 4 v·∫•n ƒë·ªÅ nh∆∞ sau:\n\nDemand planning: D·ª± ƒëo√°n nhu c·∫ßu kh√°ch h√†ng bao nhi√™u.\nCapacity planning: L√™n k·∫ø ho·∫°ch ph√¢n ph·ªëi, t·ªìn kho.\nProdcution planning: Chu·∫©n b·ªã nguy√™n v·∫≠t li·ªáu ƒë·ªÉ s·∫£n xu·∫•t ·ªü nh√† m√°y. Th√¥ng th∆∞·ªùng ho·∫°t ƒë·ªông n√†y ch·ªâ x·∫£y ra ·ªü c√¥ng ti l·ªõn c√≥ c·∫£ chu·ªói cung ·ª©ng t·ª´ nh√† m√°y ƒë·∫øn nh√† kho v√† c√≥ th·ªÉ c·∫£ c·ª≠a h√†ng.\nInvetory management v√† Sales and Opertion planning: hai ch·ª©c nƒÉng n√†y c√≥ th·ªÉ g·ªôp l·∫°i th√†nh Fulfillment planning - l√† ho·∫°t ƒë·ªông nh·∫±m th·ªèa m√£n c√°c nhu c·∫ßu kh√°c nhau c·ªßa kh√°ch h√†ng nh∆∞: qu·∫£n l√≠ h√†ng t·ªìn kho tr√°nh b·ªã outstock, h√†ng h√≥a ƒë∆∞·ª£c v·∫≠n chuy·ªÉn ƒë√∫ng s·ªë l∆∞·ª£ng, ƒë√∫ng s·∫£n ph·∫©m v√† nh·∫≠n h√†ng v·ªõi th·ªùi gian ng·∫Øn nh·∫•t.\n\n\n\n\nH√¨nh 2: C√°c ch·ª©c nƒÉng ch√≠nh c·ªßa Supply Chain Planner\n\n\n\n\n\nV·∫≠y l√†m sao ƒë·ªÉ l√†m m·ªôt Planner t·ªët trong qu·∫£n l√Ω chu·ªói cung ·ª©ng ? Gi·∫£ s·ª≠ b·∫°n ƒëang l√† ng∆∞·ªùi qu·∫£n l√Ω c·ª≠a h√†ng v·ªÅ ƒë·ªì ch∆°i tr·∫ª em, b·∫°n s·∫Ω c·∫ßn l√™n k·∫ø ho·∫°ch nh·∫≠p kho t·ª´ng lo·∫°i ƒë·ªì ch∆°i ƒë·ªÉ tr√°nh vi·ªác outstock h√†ng tr√™n kho v√† b·∫°n c·∫ßn ph·∫£i bi·∫øt c√¢n ƒë·ªëi s·ªë l∆∞·ª£ng gi·ªØa c√°c lo·∫°i m·∫∑t h√†ng - m·∫∑t h√†ng n√†o b√°n ch·∫°y th√¨ nh·∫≠p nhi·ªÅu, m·∫∑t h√†ng n√†o c√≤n t·ªìn kho th√¨ c√≥ th·ªÉ t·∫°o ch∆∞∆°ng tr√¨nh gi·∫£m gi√° ho·∫∑c l√†m qu√† t·∫∑ng‚Ä¶). ƒê·ªÉ l√†m ƒë∆∞·ª£c ƒëi·ªÅu n√†y, b·∫°n kh√¥ng th·ªÉ ch·ªâ quy·∫øt ƒë·ªãnh b·∫±ng c·∫£m t√≠nh m√† c·∫ßn c√°c c√¥ng c·ª• ƒëo l∆∞·ªùng hi·ªáu qu·∫£ v√† ph√π h·ª£p v·ªõi c√¥ng ty c·ªßa b·∫°n.\nV√≠ d·ª•, trong th√°ng 10, c·ª≠a h√†ng c·ª≠a b·∫°n v·∫´n c√≤n 10 ƒë·ªì ch∆°i A v√† kh√°ch h√†ng c·∫ßn mua t·ªõi 15 ƒë·ªì ch∆°i v√† th·ªùi gian v·∫≠n chuy·ªÉn nh·∫≠p kho trung b√¨nh l√† 10 ng√†y. V√¨ v·∫≠y, tr∆∞·ªõc th√°ng 10, b·∫°n c·∫ßn l√™n ƒë∆°n ƒë·∫∑t h√†ng cho b√™n supplier ƒë·ªÉ m√¨nh nh·∫≠p kho k·ªãp l√∫c v√† tr∆∞ng b√†y h√†ng tr√™n k·ªá. Nghe vi·ªác n√†y c√≥ v·∫ª d·ªÖ ƒë√∫ng kh√¥ng nh∆∞ng ƒëi·ªÅu ƒë√≥ ch·ªâ d·ªÖ khi b·∫°n bi·∫øt tr∆∞·ªõc ƒë∆∞·ª£c t∆∞∆°ng lai r·∫±ng kh√°ch h√†ng c·ªßa b·∫°n s·∫Ω mua 15 m√≥n ƒë·ªì ch∆°i trong th√°ng 10. V·∫≠y l√†m sao ƒë·ªÉ d·ª± ƒëo√°n ch√≠nh x√°c ƒë∆∞·ª£c th√¨ ƒë√≥ l√† c√¥ng d·ª•ng c·ªßa demand planning.\n\n\nTh·ª±c ch·∫•t demand planning ch·ªâ l√† 1 ph·∫ßn nh·ªè gi·ªØa nhi·ªÅu ho·∫°t ƒë·ªông planning kh√°c nhau trong qu√° tr√¨nh qu·∫£n l√Ω chu·ªói cung ·ª©ng nh∆∞ng l·∫°i ƒë√≥ng vai tr√≤ quan tr·ªçng nh·∫•t. Nh∆∞ nghi√™n c·ª©u d∆∞·ªõi ƒë√¢y c·ªßa (Natalia Szozda and Sylwia Werbi≈Ñska-Wojciechowska2 2013) , n√≥ ƒë∆∞·ª£c xem th√¥ng tin ƒë·∫ßu v√†o cho doanh nghi·ªáp v√† d·ª±a v√†o ƒë√≥, c√°c ph√≤ng ban trong doanh nghi·ªáp nh∆∞ ph√≤ng thu mua s·∫Ω l√™n k·∫ø ho·∫°ch v·ªÅ s·ªë l∆∞·ª£ng nguy√™n v·∫≠t li·ªáu c·∫ßn mua, ph√≤ng s·∫£n xu·∫•t s·∫Ω x√¢y d·ª±ng k·∫ø ho·∫°ch s·∫£n xu·∫•t, ƒë∆°n v·ªã v·∫≠n chuy·ªÉn s·∫Ω l√™n l·ªãch tr√¨nh ph√¢n ph·ªëi h√†ng h√≥a cho t·ª´ng nh√† kho, t·ª´ng c·ª≠a h√†ng kh√°c nhau.\n\n\n\nH√¨nh 3: Vai tr√≤ c·ªßa Demand Planning trong doanh nghi·ªáp\n\n\nDo ƒë√≥, b·∫°n c√≥ th·ªÉ th·∫•y th√¥ng tin ƒë∆∞·ª£c d·ª± ƒëo√°n t·ª´ demand planning s·∫Ω l√†m n·ªÅn t·∫£ng hay d·ªØ li·ªáu ƒë·∫ßu v√†o cho r·∫•t nhi·ªÅu k·∫ø ho·∫°ch ho·∫°t ƒë·ªông trong c√¥ng ty, doanh nghi·ªáp. V√¨ v·∫≠y, ƒë·ªÉ ƒë·∫£m b·∫£o ƒë∆∞·ª£c ƒë·ªô ch√≠nh x√°c, b·∫°n c·∫ßn thu th·∫≠p d·ªØ li·ªáu t·ª´ nhi·ªÅu ngu·ªìn ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n.\nƒê·ªëi v·ªõi d·ªØ li·ªáu chu·ªói th·ªùi gian, c√°c m√¥ h√¨nh d·ª± ƒëo√°n th√¥ng th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng nh∆∞ l√†:\n\nCho th·ªùi gian ng·∫Øn h·∫°n (T·ª´ 1 ƒë·∫øn 3 th√°ng): ETS, MA (Moving Average), AR (Autoregressive).\nCho th·ªùi gian d√†i h·∫°n: ARIMA, SARIMA hay SARIMAX.\nCho th·ªùi gian d√†i h·∫°n v√† d·ªØ li·ªáu ƒëa d·∫°ng ph·ª©c t·∫°p: c√°c m√¥ h√¨nh thu·∫ßn v·ªÅ h·ªçc m√°y nh∆∞ RNN, Deap Learning,‚Ä¶ s·∫Ω l√†m t·ªët h∆°n m√¥ h√¨nh truy·ªÅn th·ªëng.\n\nV·∫≠y th√¨ trong b√†i n√†y ch√∫ng ta s·∫Ω h·ªçc ƒë·∫ßu ti√™n v·ªÅ m√¥ h√¨nh ARIMA."
  },
  {
    "objectID": "timeseries.html#ƒë·ªãnh-nghƒ©a",
    "href": "timeseries.html#ƒë·ªãnh-nghƒ©a",
    "title": "Gi·ªõi thi·ªáu",
    "section": "",
    "text": "Trong qu·∫£n l√≠ chu·ªói cung ·ª©ng, thu·∫≠t ng·ªØ Demand Planning l√† m·ªôt trong nh·ªØng ho·∫°t ƒë·ªông quan tr·ªçng m√† c√°c nh√† qu·∫£n l√≠ v√† doanh nghi·ªáp c·∫ßn quan t√¢m s√¢u s·∫Øc. V·ªÅ ƒë·ªãnh nghƒ©a, theo (Vilas, n.d.) ‚ÄúDemand Planning l√† m·ªôt qu√° tr√¨nh qu·∫£n l√Ω chu·ªói cung ·ª©ng nh·∫±m d·ª± b√°o nhu c·∫ßu v·ªÅ s·∫£n ph·∫©m ƒë·ªÉ ƒë·∫£m b·∫£o ch√∫ng c√≥ th·ªÉ ƒë∆∞·ª£c cung c·∫•p v√† l√†m h√†i l√≤ng kh√°ch h√†ng. M·ª•c ti√™u c·ªßa Demand planning l√† ƒë·∫°t ƒë∆∞·ª£c s·ª± c√¢n b·∫±ng trong vi·ªác c√≥ ƒë·ªß l∆∞·ª£ng h√†ng t·ªìn kho ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu c·ªßa kh√°ch h√†ng m√† kh√¥ng b·ªã thi·∫øu ho·∫∑c th·ª´a. ƒê·ªÉ c√≥ th·ªÉ d·ª± b√°o ƒë∆∞·ª£c nhu c·∫ßu mua h√†ng, nh√† Ho·∫°ch ƒë·ªãnh nhu c·∫ßu c·∫ßn thu th·∫≠p v√† ph√¢n t√≠ch d·ªØ li·ªáu t·ª´ nhi·ªÅu ngu·ªìn kh√°c nhau nh∆∞: h√†ng t·ªìn kho, nh√† cung ·ª©ng, kho, kh√°ch h√†ng,‚Ä¶‚Äù.\n\n\n\nH√¨nh 1: ƒê·ªãnh nghƒ©a v·ªÅ Demand Planning"
  },
  {
    "objectID": "timeseries.html#l·ª£i-√≠ch-c·ªßa-demand-planning",
    "href": "timeseries.html#l·ª£i-√≠ch-c·ªßa-demand-planning",
    "title": "Gi·ªõi thi·ªáu",
    "section": "",
    "text": "Vi·ªác d·ª± ƒëo√°n tr∆∞·ªõc nhu c·∫ßu c·ªßa kh√°ch h√†ng s·∫Ω gi√∫p doanh nghi·ªáp chu·∫©n b·ªã t·ªët h∆°n v·ªÅ h√†ng h√≥a, d·ªãch v·ª• v√† chi·∫øm ƒë∆∞·ª£c l√≤ng tin c·ªßa kh√°ch h√†ng. Ngo√†i ra, vi·ªác chu·∫©n b·ªã s·ªõm c≈©ng tr√°nh c√°c hi·ªán t∆∞·ª£ng nh∆∞ out-stock, tranh ch·∫•p ho·∫∑c t·ªá h∆°n ƒë·ª©t g√£y chu·ªói cung ·ª©ng v√† ·∫£nh h∆∞·ªüng n·∫∑ng n·ªÅ t·ªõi k·∫øt qu·∫£ kinh doanh c·ªßa c√¥ng ty.\n·ªû v·ªã tr√≠ nh√¢n vi√™n, b·∫°n c√≥ th·ªÉ ·ª©ng tuy·ªÉn v·ªã tr√≠ Demand Planner ƒë·ªÉ c√≥ th·ªÉ l√†m vi·ªác v·ªÅ Demand Planning. C√≤n ·ªü v·ªã tr√≠ c·∫•p cao h∆°n s·∫Ω l√† Supply Chain Planner - l√† ng∆∞·ªùi c√≥ th·ªÉ x·ª≠ l√≠ lu√¥n c·∫£ 4 v·∫•n ƒë·ªÅ nh∆∞ sau:\n\nDemand planning: D·ª± ƒëo√°n nhu c·∫ßu kh√°ch h√†ng bao nhi√™u.\nCapacity planning: L√™n k·∫ø ho·∫°ch ph√¢n ph·ªëi, t·ªìn kho.\nProdcution planning: Chu·∫©n b·ªã nguy√™n v·∫≠t li·ªáu ƒë·ªÉ s·∫£n xu·∫•t ·ªü nh√† m√°y. Th√¥ng th∆∞·ªùng ho·∫°t ƒë·ªông n√†y ch·ªâ x·∫£y ra ·ªü c√¥ng ti l·ªõn c√≥ c·∫£ chu·ªói cung ·ª©ng t·ª´ nh√† m√°y ƒë·∫øn nh√† kho v√† c√≥ th·ªÉ c·∫£ c·ª≠a h√†ng.\nInvetory management v√† Sales and Opertion planning: hai ch·ª©c nƒÉng n√†y c√≥ th·ªÉ g·ªôp l·∫°i th√†nh Fulfillment planning - l√† ho·∫°t ƒë·ªông nh·∫±m th·ªèa m√£n c√°c nhu c·∫ßu kh√°c nhau c·ªßa kh√°ch h√†ng nh∆∞: qu·∫£n l√≠ h√†ng t·ªìn kho tr√°nh b·ªã outstock, h√†ng h√≥a ƒë∆∞·ª£c v·∫≠n chuy·ªÉn ƒë√∫ng s·ªë l∆∞·ª£ng, ƒë√∫ng s·∫£n ph·∫©m v√† nh·∫≠n h√†ng v·ªõi th·ªùi gian ng·∫Øn nh·∫•t.\n\n\n\n\nH√¨nh 2: C√°c ch·ª©c nƒÉng ch√≠nh c·ªßa Supply Chain Planner"
  },
  {
    "objectID": "timeseries.html#v√¨-sao-c·∫ßn-planning",
    "href": "timeseries.html#v√¨-sao-c·∫ßn-planning",
    "title": "Gi·ªõi thi·ªáu",
    "section": "",
    "text": "V·∫≠y l√†m sao ƒë·ªÉ l√†m m·ªôt Planner t·ªët trong qu·∫£n l√Ω chu·ªói cung ·ª©ng ? Gi·∫£ s·ª≠ b·∫°n ƒëang l√† ng∆∞·ªùi qu·∫£n l√Ω c·ª≠a h√†ng v·ªÅ ƒë·ªì ch∆°i tr·∫ª em, b·∫°n s·∫Ω c·∫ßn l√™n k·∫ø ho·∫°ch nh·∫≠p kho t·ª´ng lo·∫°i ƒë·ªì ch∆°i ƒë·ªÉ tr√°nh vi·ªác outstock h√†ng tr√™n kho v√† b·∫°n c·∫ßn ph·∫£i bi·∫øt c√¢n ƒë·ªëi s·ªë l∆∞·ª£ng gi·ªØa c√°c lo·∫°i m·∫∑t h√†ng - m·∫∑t h√†ng n√†o b√°n ch·∫°y th√¨ nh·∫≠p nhi·ªÅu, m·∫∑t h√†ng n√†o c√≤n t·ªìn kho th√¨ c√≥ th·ªÉ t·∫°o ch∆∞∆°ng tr√¨nh gi·∫£m gi√° ho·∫∑c l√†m qu√† t·∫∑ng‚Ä¶). ƒê·ªÉ l√†m ƒë∆∞·ª£c ƒëi·ªÅu n√†y, b·∫°n kh√¥ng th·ªÉ ch·ªâ quy·∫øt ƒë·ªãnh b·∫±ng c·∫£m t√≠nh m√† c·∫ßn c√°c c√¥ng c·ª• ƒëo l∆∞·ªùng hi·ªáu qu·∫£ v√† ph√π h·ª£p v·ªõi c√¥ng ty c·ªßa b·∫°n.\nV√≠ d·ª•, trong th√°ng 10, c·ª≠a h√†ng c·ª≠a b·∫°n v·∫´n c√≤n 10 ƒë·ªì ch∆°i A v√† kh√°ch h√†ng c·∫ßn mua t·ªõi 15 ƒë·ªì ch∆°i v√† th·ªùi gian v·∫≠n chuy·ªÉn nh·∫≠p kho trung b√¨nh l√† 10 ng√†y. V√¨ v·∫≠y, tr∆∞·ªõc th√°ng 10, b·∫°n c·∫ßn l√™n ƒë∆°n ƒë·∫∑t h√†ng cho b√™n supplier ƒë·ªÉ m√¨nh nh·∫≠p kho k·ªãp l√∫c v√† tr∆∞ng b√†y h√†ng tr√™n k·ªá. Nghe vi·ªác n√†y c√≥ v·∫ª d·ªÖ ƒë√∫ng kh√¥ng nh∆∞ng ƒëi·ªÅu ƒë√≥ ch·ªâ d·ªÖ khi b·∫°n bi·∫øt tr∆∞·ªõc ƒë∆∞·ª£c t∆∞∆°ng lai r·∫±ng kh√°ch h√†ng c·ªßa b·∫°n s·∫Ω mua 15 m√≥n ƒë·ªì ch∆°i trong th√°ng 10. V·∫≠y l√†m sao ƒë·ªÉ d·ª± ƒëo√°n ch√≠nh x√°c ƒë∆∞·ª£c th√¨ ƒë√≥ l√† c√¥ng d·ª•ng c·ªßa demand planning.\n\n\nTh·ª±c ch·∫•t demand planning ch·ªâ l√† 1 ph·∫ßn nh·ªè gi·ªØa nhi·ªÅu ho·∫°t ƒë·ªông planning kh√°c nhau trong qu√° tr√¨nh qu·∫£n l√Ω chu·ªói cung ·ª©ng nh∆∞ng l·∫°i ƒë√≥ng vai tr√≤ quan tr·ªçng nh·∫•t. Nh∆∞ nghi√™n c·ª©u d∆∞·ªõi ƒë√¢y c·ªßa (Natalia Szozda and Sylwia Werbi≈Ñska-Wojciechowska2 2013) , n√≥ ƒë∆∞·ª£c xem th√¥ng tin ƒë·∫ßu v√†o cho doanh nghi·ªáp v√† d·ª±a v√†o ƒë√≥, c√°c ph√≤ng ban trong doanh nghi·ªáp nh∆∞ ph√≤ng thu mua s·∫Ω l√™n k·∫ø ho·∫°ch v·ªÅ s·ªë l∆∞·ª£ng nguy√™n v·∫≠t li·ªáu c·∫ßn mua, ph√≤ng s·∫£n xu·∫•t s·∫Ω x√¢y d·ª±ng k·∫ø ho·∫°ch s·∫£n xu·∫•t, ƒë∆°n v·ªã v·∫≠n chuy·ªÉn s·∫Ω l√™n l·ªãch tr√¨nh ph√¢n ph·ªëi h√†ng h√≥a cho t·ª´ng nh√† kho, t·ª´ng c·ª≠a h√†ng kh√°c nhau.\n\n\n\nH√¨nh 3: Vai tr√≤ c·ªßa Demand Planning trong doanh nghi·ªáp\n\n\nDo ƒë√≥, b·∫°n c√≥ th·ªÉ th·∫•y th√¥ng tin ƒë∆∞·ª£c d·ª± ƒëo√°n t·ª´ demand planning s·∫Ω l√†m n·ªÅn t·∫£ng hay d·ªØ li·ªáu ƒë·∫ßu v√†o cho r·∫•t nhi·ªÅu k·∫ø ho·∫°ch ho·∫°t ƒë·ªông trong c√¥ng ty, doanh nghi·ªáp. V√¨ v·∫≠y, ƒë·ªÉ ƒë·∫£m b·∫£o ƒë∆∞·ª£c ƒë·ªô ch√≠nh x√°c, b·∫°n c·∫ßn thu th·∫≠p d·ªØ li·ªáu t·ª´ nhi·ªÅu ngu·ªìn ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n.\nƒê·ªëi v·ªõi d·ªØ li·ªáu chu·ªói th·ªùi gian, c√°c m√¥ h√¨nh d·ª± ƒëo√°n th√¥ng th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng nh∆∞ l√†:\n\nCho th·ªùi gian ng·∫Øn h·∫°n (T·ª´ 1 ƒë·∫øn 3 th√°ng): ETS, MA (Moving Average), AR (Autoregressive).\nCho th·ªùi gian d√†i h·∫°n: ARIMA, SARIMA hay SARIMAX.\nCho th·ªùi gian d√†i h·∫°n v√† d·ªØ li·ªáu ƒëa d·∫°ng ph·ª©c t·∫°p: c√°c m√¥ h√¨nh thu·∫ßn v·ªÅ h·ªçc m√°y nh∆∞ RNN, Deap Learning,‚Ä¶ s·∫Ω l√†m t·ªët h∆°n m√¥ h√¨nh truy·ªÅn th·ªëng.\n\nV·∫≠y th√¨ trong b√†i n√†y ch√∫ng ta s·∫Ω h·ªçc ƒë·∫ßu ti√™n v·ªÅ m√¥ h√¨nh ARIMA."
  }
]